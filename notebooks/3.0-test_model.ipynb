{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing and Evaluation\n",
    "\n",
    "This notebook demonstrates testing and evaluating sentiment analysis models for both Vietnamese and English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.config import Config\n",
    "from src.models.model_predictor import SentimentPredictor\n",
    "from src.data.preprocessor import DataPreprocessor\n",
    "from src.features.feature_engineering import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model components for vi\n",
      "No trained model found for en\n"
     ]
    }
   ],
   "source": [
    "def check_model_exists(language, config):\n",
    "    \"\"\"Check if trained model exists for given language\"\"\"\n",
    "    model_path = os.path.join(config.DATA_DIR, \"models\", f\"{language}_sentiment_model.pkl\")\n",
    "    return os.path.exists(model_path)\n",
    "\n",
    "def load_model_components(language):\n",
    "    \"\"\"Load model components if model exists\"\"\"\n",
    "    config = Config()\n",
    "    \n",
    "    if not check_model_exists(language, config):\n",
    "        print(f\"No trained model found for {language}\")\n",
    "        return None, None, None\n",
    "        \n",
    "    try:\n",
    "        predictor = SentimentPredictor(language, config)\n",
    "        preprocessor = DataPreprocessor(language, config)\n",
    "        feature_extractor = FeatureExtractor(language, config)\n",
    "        print(f\"Successfully loaded model components for {language}\")\n",
    "        return predictor, preprocessor, feature_extractor\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model for {language}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Load available models\n",
    "available_models = {}\n",
    "for lang in ['vi', 'en']:\n",
    "    components = load_model_components(lang)\n",
    "    if all(components):\n",
    "        available_models[lang] = {\n",
    "            'predictor': components[0],\n",
    "            'preprocessor': components[1],\n",
    "            'feature_extractor': components[2]\n",
    "        }\n",
    "\n",
    "if not available_models:\n",
    "    print(\"No models available for testing. Please train models first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Individual Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing VI model:\n",
      "--------------------------------------------------\n",
      "2024-11-11 03:28:05,635 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,635 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,635 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,635 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,635 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,635 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,643 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,643 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,643 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,643 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,643 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,643 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "Error in rf prediction: X has 21 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error in svm prediction: X has 21 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error in nb prediction: X has 21 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error processing text: All models failed to predict\n",
      "------------------------------\n",
      "2024-11-11 03:28:05,651 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,651 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,651 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,651 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,651 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,651 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,658 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,658 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,658 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,658 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,658 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,658 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "Error in rf prediction: X has 25 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error in svm prediction: X has 25 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error in nb prediction: X has 25 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error processing text: All models failed to predict\n",
      "------------------------------\n",
      "2024-11-11 03:28:05,665 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,665 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,665 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,665 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,665 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,665 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,672 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,672 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,672 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,672 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,672 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "2024-11-11 03:28:05,672 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "Error in rf prediction: X has 16 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error in svm prediction: X has 16 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error in nb prediction: X has 16 features, but MinMaxScaler is expecting 104 features as input.\n",
      "Error processing text: All models failed to predict\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(text, language='vi'):\n",
    "    \"\"\"Predict sentiment for a single text\"\"\"\n",
    "    if language not in available_models:\n",
    "        print(f\"No model available for {language}\")\n",
    "        return None\n",
    "    \n",
    "    components = available_models[language]\n",
    "    \n",
    "    try:\n",
    "        # Create DataFrame with single text and ensure it's a string\n",
    "        df = pd.DataFrame({'text': [str(text)]})\n",
    "        \n",
    "        # Process text\n",
    "        processed_df = components['preprocessor'].preprocess(df)\n",
    "        if processed_df.empty:\n",
    "            raise ValueError(\"Text preprocessing failed\")\n",
    "            \n",
    "        # Extract features (now handles single documents)\n",
    "        features = components['feature_extractor'].extract_features(processed_df['cleaned_text'])\n",
    "        if features is None or features.size == 0:\n",
    "            raise ValueError(\"Feature extraction failed\")\n",
    "            \n",
    "        # Get predictions\n",
    "        prediction = components['predictor'].predict(features)[0]\n",
    "        probabilities = components['predictor'].predict_proba(features)[0]\n",
    "        \n",
    "        # Map sentiment to text\n",
    "        sentiment_map = {0: 'Negative', 1: 'Neutral', 2: 'Positive'}\n",
    "        print(f\"Text: {text}\")\n",
    "        print(f\"Sentiment: {sentiment_map[prediction]} (confidence: {max(probabilities):.2f})\")\n",
    "        \n",
    "        return prediction, probabilities\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test samples for available languages\n",
    "test_samples = {\n",
    "    'vi': [\n",
    "        \"Sản phẩm tuyệt vời, rất đáng tiền\",\n",
    "        \"Dịch vụ quá tệ, không bao giờ quay lại\",\n",
    "        \"Tạm được, không tốt không xấu\"\n",
    "    ],\n",
    "    'en': [\n",
    "        \"This product is amazing, totally worth it!\",\n",
    "        \"Terrible service, never coming back\",\n",
    "        \"It's okay, nothing special\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "for lang in available_models:\n",
    "    print(f\"\\nTesting {lang.upper()} model:\")\n",
    "    print(\"-\" * 50)\n",
    "    for sample in test_samples[lang]:\n",
    "        predict_sentiment(sample, lang)\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating VI model:\n",
      "--------------------------------------------------\n",
      "2024-11-11 03:28:05,722 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,722 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,722 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,722 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,722 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:05,722 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:08,487 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:08,487 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:08,487 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:08,487 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:08,487 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:08,487 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "Error evaluating model: No samples after preprocessing\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(test_data, language='vi'):\n",
    "    \"\"\"Evaluate model on test dataset\"\"\"\n",
    "    if language not in available_models:\n",
    "        print(f\"No model available for {language}\")\n",
    "        return None, None, None\n",
    "    \n",
    "    components = available_models[language]\n",
    "    \n",
    "    try:\n",
    "        # Validate input data\n",
    "        if test_data.empty:\n",
    "            raise ValueError(\"Empty test data provided\")\n",
    "        \n",
    "        # Ensure required columns\n",
    "        if 'text' not in test_data.columns:\n",
    "            raise ValueError(\"Missing 'text' column\")\n",
    "        \n",
    "        # Clean data\n",
    "        test_data = test_data[test_data['text'].notna()].copy()\n",
    "        test_data['text'] = test_data['text'].astype(str).str.strip()\n",
    "        \n",
    "        # Add default label if missing\n",
    "        if 'label' not in test_data.columns:\n",
    "            test_data['label'] = 1\n",
    "        \n",
    "        if len(test_data) == 0:\n",
    "            raise ValueError(\"No valid samples after cleaning\")\n",
    "            \n",
    "        # Process data\n",
    "        processed_df = components['preprocessor'].preprocess(test_data)\n",
    "        if processed_df.empty:\n",
    "            raise ValueError(\"No samples after preprocessing\")\n",
    "        \n",
    "        # Extract features\n",
    "        features = components['feature_extractor'].extract_features(processed_df['cleaned_text'])\n",
    "        if features is None or len(features) == 0:\n",
    "            raise ValueError(\"Feature extraction failed\")\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = components['predictor'].predict(features)\n",
    "        probabilities = components['predictor'].predict_proba(features)\n",
    "        \n",
    "        # Calculate metrics if we have labels\n",
    "        if 'label' in processed_df.columns:\n",
    "            conf_matrix = confusion_matrix(processed_df['label'], predictions)\n",
    "            class_report = classification_report(processed_df['label'], predictions)\n",
    "            \n",
    "            # Plot confusion matrix\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Confusion Matrix - {language.upper()}')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(class_report)\n",
    "        \n",
    "        return predictions, probabilities, processed_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Evaluate available models\n",
    "for lang in available_models:\n",
    "    print(f\"\\nEvaluating {lang.upper()} model:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        test_data = pd.read_csv(os.path.join(project_root, 'data', 'processed', f'{lang}_processed_data.csv'))\n",
    "        evaluate_model(test_data, lang)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test data for {lang}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vietnamese Error Analysis:\n",
      "2024-11-11 03:28:08,535 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:08,535 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:08,535 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:08,535 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:08,535 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:08,535 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-11-11 03:28:11,214 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:11,214 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:11,214 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:11,214 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:11,214 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "2024-11-11 03:28:11,214 - src.data.preprocessor - ERROR - Preprocessing error: No valid samples after preprocessing\n",
      "Error evaluating model: No samples after preprocessing\n",
      "Missing required data for error analysis\n",
      "\n",
      "English Error Analysis:\n",
      "No model available for en\n",
      "Missing required data for error analysis\n"
     ]
    }
   ],
   "source": [
    "def analyze_errors(test_data, predictions, probabilities, language='vi'):\n",
    "    \"\"\"Analyze prediction errors with better error handling\"\"\"\n",
    "    if any(x is None for x in [test_data, predictions, probabilities]):\n",
    "        print(\"Missing required data for error analysis\")\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        df = test_data.copy()\n",
    "        df['predicted'] = predictions\n",
    "        df['confidence'] = np.max(probabilities, axis=1)\n",
    "        \n",
    "        # Find misclassified samples\n",
    "        errors = df[df['label'] != df['predicted']].copy()\n",
    "        errors['confidence'] = errors['confidence'].round(3)\n",
    "        \n",
    "        print(f\"Total errors: {len(errors)}\")\n",
    "        print(\"\\nSample errors with highest confidence:\")\n",
    "        print(errors.sort_values('confidence', ascending=False)[['text', 'label', 'predicted', 'confidence']].head())\n",
    "        \n",
    "        # Plot confidence distribution\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.hist(errors['confidence'], bins=20)\n",
    "        plt.title('Confidence Distribution of Errors')\n",
    "        plt.xlabel('Confidence')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()\n",
    "        \n",
    "        return errors\n",
    "    except Exception as e:\n",
    "        print(f\"Error during analysis: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Evaluate models and analyze errors for both languages\n",
    "print(\"Vietnamese Error Analysis:\")\n",
    "vi_test_data = pd.read_csv(os.path.join(project_root, 'data', 'processed', 'vi_processed_data.csv'))\n",
    "vi_results = evaluate_model(vi_test_data, 'vi')\n",
    "vi_errors = analyze_errors(vi_test_data, vi_results[0], vi_results[1], 'vi')\n",
    "\n",
    "print(\"\\nEnglish Error Analysis:\")\n",
    "en_test_data = pd.read_csv(os.path.join(project_root, 'data', 'processed', 'en_processed_data.csv'))\n",
    "en_results = evaluate_model(en_test_data, 'en')\n",
    "en_errors = analyze_errors(en_test_data, en_results[0], en_results[1], 'en')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

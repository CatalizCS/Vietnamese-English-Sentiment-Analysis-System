This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-08T05:01:49.376Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
.gitignore
.repomixignore
extension/background.js
extension/content.js
extension/manifest.json
extension/package.json
extension/popup.css
extension/popup.js
extension/src/input.css
extension/style.css
extension/tailwind.config.js
metrics.json
notebooks/0.0-init-environment.ipynb
notebooks/1.0-data_labeling.ipynb
notebooks/continue_training.ipynb
notebooks/sentiment_analysis_pipeline.ipynb
README.md
repomix.config.json
requirements.txt
road-map.md
run_api.py
scripts/data_collection_cli.py
scripts/generate_training_data.py
scripts/train_models.py
setup.py
src/api/__init__.py
src/api/app.py
src/config.py
src/docs/algorithm_overview.py
src/features/feature_engineering.py
src/features/text_cleaner.py
src/main.py
src/models/model_predictor.py
src/models/model_trainer.py
src/utils/augmentation.py
src/utils/evaluation.py
src/utils/logger.py
src/utils/menu.py
src/utils/metrics_store.py
src/utils/report.py
src/utils/server_utils.py
src/utils/templates.py
src/visualization.py
tests/test_model.py
tests/test_preprocessor.py

================================================================
Repository Files
================================================================

================
File: .gitignore
================
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:

# Node.js
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Chrome Extension
*.crx
*.pem
*.pub
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
.python-version

# pipenv
#  According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#  However, in case you do not want to do that, uncomment the following line to ignore it.
# Pipfile.lock

# PEP 582; used by e.g. github.com/David-OConnor/pyflow
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyderworkspace

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

================
File: .repomixignore
================
# Add patterns to ignore here, one per line
# Example:
# *.log
# tmp/

data/
venv/
*.html

================
File: extension/background.js
================
// Initialize service worker globals
let backgroundService = null;
let pollInterval = null;

// Service worker setup
async function initializeServiceWorker() {
    try {
        if (!backgroundService) {
            backgroundService = new BackgroundService();
            await backgroundService.initialize();
        }
    } catch (error) {
        console.error('Service worker initialization failed:', error);
    }
}

// Service worker activation events
chrome.runtime.onInstalled.addListener(initializeServiceWorker);
chrome.runtime.onStartup.addListener(initializeServiceWorker);

// Cleanup on service worker update/unload
self.addEventListener('unload', () => {
    if (pollInterval) {
        clearInterval(pollInterval);
    }
});

class BackgroundService {
    constructor() {
        this.API_URL = 'http://workspace.tamais.me:7270';
        this.stats = {
            analyzed: 0,
            successful: 0
        };
        this.lastApiCheck = null;
        this.retryTimeout = 5000;
        this.maxRetries = 3;
        this.lastStatus = null;
        this.retryDelays = [1000, 2000, 4000];
        this.healthCheckInterval = 30000;
        this.initApiUrl();
        this.popupPorts = new Set();
        this.isInitialized = false;
        this.connectionAttempts = 0;
        this.maxConnectionAttempts = 5;
        this.messageQueue = [];
        this.portConnectionRetries = 0;
        this.maxPortRetries = 3;
        this.pendingRequests = new Map();
        this.failedAttempts = 0;
        this.maxFailedAttempts = 3;
        this.apiTimeout = 3000; // 3 seconds timeout
        this.dataCache = {
            lastUpdate: null,
            stats: null,
            status: null
        };
        this.dataRefreshInterval = 3000; // 3 seconds
    }

    async initialize() {
        if (this.isInitialized) return;
        await this.initApiUrl();
        this.setupMessageHandlers();
        await this.startApiMonitoring();
        this.startDataRefreshCycle();
        this.isInitialized = true;
    }

    startDataRefreshCycle() {
        setInterval(async () => {
            await this.refreshData();
        }, this.dataRefreshInterval);
    }

    async refreshData() {
        try {
            const status = await this.checkApiStatus();
            this.dataCache = {
                lastUpdate: new Date(),
                stats: this.stats,
                status: status,
                models: status.models || { vi: false, en: false },
                errors: status.error ? [status.error] : []
            };
            await this.broadcastUpdate();
            this.pruneDataCache(); // Remove old data
        } catch (error) {
            console.error('Data refresh failed:', error);
            this.dataCache.errors.push(error.message);
        }
    }

    pruneDataCache() {
        // Remove data older than 5 minutes
        const fiveMinutesAgo = Date.now() - (5 * 60 * 1000);
        this.dataCache.errors = this.dataCache.errors.filter(err =>
            err.timestamp > fiveMinutesAgo
        );
    }

    async broadcastUpdate() {
        // Notify all content scripts
        chrome.tabs.query({}, (tabs) => {
            tabs.forEach(tab => {
                chrome.tabs.sendMessage(tab.id, {
                    type: 'DATA_UPDATE',
                    data: this.dataCache
                }).catch(() => { });
            });
        });

        // Notify popup
        await this.updateAll();
    }

    async initApiUrl() {
        const { apiUrl } = await chrome.storage.local.get('apiUrl');
        this.API_URL = apiUrl || 'http://workspace.tamais.me:7270';
    }

    setupMessageHandlers() {
        chrome.runtime.onConnect.addListener((port) => {
            if (port.name === 'popup') {
                const portId = Date.now().toString();
                this.popupPorts.add(port);

                const pingInterval = setInterval(() => {
                    if (this.isValidPort(port)) {
                        try {
                            port.postMessage({ type: 'PING' });
                        } catch (e) {
                            clearInterval(pingInterval);
                        }
                    } else {
                        clearInterval(pingInterval);
                    }
                }, 5000);

                port.onDisconnect.addListener(() => {
                    clearInterval(pingInterval);
                    this.popupPorts.delete(port);
                    console.log('Port disconnected, cleaning up...');
                });

                port.onMessage.addListener((msg, port) => {
                    const handleMessage = async () => {
                        try {
                            if (msg.type === 'GET_INITIAL_STATE') {
                                await this.sendPopupUpdate(port);
                            }
                        } catch (error) {
                            console.error('Message handler error:', error);
                        }
                    };
                    handleMessage();
                });

                // Initial update with retry mechanism
                const attemptInitialUpdate = async (retryCount = 0) => {
                    try {
                        if (!this.isValidPort(port)) return;
                        await this.checkApiStatus(true); // Force fresh check
                        await this.sendPopupUpdate(port);
                    } catch (error) {
                        if (retryCount < this.maxPortRetries) {
                            setTimeout(() => attemptInitialUpdate(retryCount + 1), 1000);
                        }
                    }
                };
                attemptInitialUpdate();
            }
        });

        // Existing message handlers
        chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
            if (request.type === 'UPDATE_STATS') {
                this.stats = request.stats;
                this.updateBadge();
            }
            if (request.type === 'GET_API_STATUS') {
                // Convert Promise to callback for Chrome messaging
                this.checkApiStatus()
                    .then(status => sendResponse(status))
                    .catch(error => sendResponse({ error: error.message }));
                return true; // Keep channel open for async response
            }
            if (request.type === 'API_URL_CHANGED') {
                this.API_URL = request.apiUrl;
                this.checkApiStatus()
                    .then(() => this.startApiMonitoring())
                    .catch(console.error);
            }
        });
    }

    async sendPopupUpdate(port) {
        if (!this.isValidPort(port)) return;

        try {
            const status = await this.checkApiStatus();
            const message = {
                type: 'STATUS_UPDATE',
                data: {
                    api: status,
                    stats: this.stats,
                    timestamp: new Date().toISOString()
                }
            };

            try {
                port.postMessage(message);
            } catch (e) {
                this.popupPorts.delete(port);
                throw e;
            }
        } catch (error) {
            console.error('Error preparing popup update:', error);
            // Don't throw here to prevent cascade failures
        }
    }

    isValidPort(port) {
        if (!port) return false;
        try {
            port.postMessage({ type: 'PING' });
            return true;
        } catch {
            this.popupPorts.delete(port);
            return false;
        }
    }

    async updateAll() {
        const validPorts = Array.from(this.popupPorts).filter(port => this.isValidPort(port));
        this.popupPorts = new Set(validPorts);

        for (const port of validPorts) {
            try {
                await this.sendPopupUpdate(port);
            } catch (error) {
                console.error('Error updating port:', error);
            }
        }
    }

    async updateBadge() {
        try {
            const successRate = this.stats.analyzed > 0
                ? Math.round((this.stats.successful / this.stats.analyzed) * 100)
                : 0;
            await chrome.action.setBadgeText({ text: `${successRate}%` });
            await chrome.action.setBadgeBackgroundColor({
                color: this.getBadgeColor(successRate)
            });
        } catch (error) {
            console.error('Badge update error:', error);
        }
    }

    getBadgeColor(rate) {
        if (rate >= 90) return '#34a853'; // Green
        if (rate >= 70) return '#fbbc05'; // Yellow
        return '#ea4335'; // Red
    }

    async checkApiStatus(forceCheck = false) {
        if (!navigator.onLine) {
            return this.getOfflineStatus();
        }

        try {
            // Log the API URL being checked
            console.log('Checking API status at:', `${this.API_URL}/health`);

            const response = await fetch(`${this.API_URL}/health`, {
                method: 'GET',
                headers: {
                    'Accept': 'application/json',
                    'Cache-Control': 'no-cache',
                },
                mode: 'cors',
                cache: 'no-cache'
            });

            console.log('API Raw Response:', response);

            const data = await response.json();
            console.log('API Response Data:', data);

            // Explicitly check the response status and data
            const isAvailable = response.ok && data.status === "healthy";
            const apiStatus = this.updateApiStatus(isAvailable, {
                ...data,
                models: data.models || { vi: false, en: false }
            });

            // Broadcast the status update immediately
            await this.broadcastStatusUpdate(apiStatus);
            return apiStatus;

        } catch (error) {
            console.error('API check error:', error);
            return this.updateApiStatus(false, {
                error: error.message,
                lastError: Date.now()
            });
        }
    }

    async broadcastStatusUpdate(status) {
        // Update all content scripts
        chrome.tabs.query({}, (tabs) => {
            tabs.forEach(tab => {
                chrome.tabs.sendMessage(tab.id, {
                    type: 'API_STATUS_UPDATE',
                    status: status,
                    timestamp: new Date().toISOString()
                }).catch(() => { });
            });
        });

        // Update all popups
        this.popupPorts.forEach(port => {
            if (this.isValidPort(port)) {
                port.postMessage({
                    type: 'STATUS_UPDATE',
                    data: {
                        api: status,
                        stats: this.stats,
                        timestamp: new Date().toISOString()
                    }
                });
            }
        });
    }

    async updateStatusBadge(isAvailable, modelCount = 0) {
        try {
            const statusText = isAvailable ?
                (modelCount > 0 ? `${modelCount}` : 'ON') :
                'OFF';

            const color = isAvailable ?
                (modelCount > 0 ? '#34a853' : '#fbbc05') :
                '#ea4335';

            await Promise.all([
                chrome.action.setBadgeText({ text: statusText }),
                chrome.action.setBadgeBackgroundColor({ color })
            ]);

        } catch (error) {
            console.error('Badge update error:', error);
        }
    }

    async startApiMonitoring() {
        if (pollInterval) {
            clearInterval(pollInterval);
        }

        // Initial check
        await this.checkApiStatus();

        // Set up polling with error handling
        pollInterval = setInterval(async () => {
            try {
                const status = await this.checkApiStatus();
                if (!status.isAvailable && this.lastStatus?.isAvailable) {
                    // Status changed from available to unavailable
                    console.warn('API became unavailable');
                }
                chrome.runtime.sendMessage({
                    type: 'API_STATUS_UPDATE',
                    status: status
                }).catch(() => { });
            } catch (error) {
                console.error('API monitoring error:', error);
            }
        }, this.healthCheckInterval);
    }

    updateApiStatus(isAvailable, data = null) {
        this.lastApiCheck = Date.now();

        // Reset stats when API status changes to offline
        if (!isAvailable && this.lastStatus?.isAvailable) {
            this.stats = { analyzed: 0, successful: 0 };
        }

        const modelStatus = data?.models || { vi: false, en: false };
        const activeModels = Object.entries(modelStatus)
            .filter(([_, status]) => status)
            .map(([lang]) => lang.toUpperCase());

        this.lastStatus = {
            isAvailable,
            status: isAvailable ? 'healthy' : 'offline',
            timestamp: data?.timestamp || new Date().toISOString(),
            models: modelStatus,
            activeModels: activeModels,
            modelCount: activeModels.length,
            lastCheck: this.lastApiCheck,
            error: isAvailable ? null : (data?.error || 'Service unavailable')
        };

        // Update badge and notify
        this.updateStatusBadge(isAvailable, activeModels.length).catch(console.error);
        this.notifyStatusChange(this.lastStatus);
        this.cleanupOnStatusChange(isAvailable);

        return this.lastStatus;
    }

    async cleanupOnStatusChange(isAvailable) {
        if (!isAvailable) {
            // Reset connection attempts and clear any pending requests
            this.connectionAttempts = 0;
            this.pendingRequests.clear();

            // Clear stats and notify UI
            this.stats = { analyzed: 0, successful: 0 };
            await this.updateBadge();

            // Notify all ports of reset
            this.notifyStatusChange({
                ...this.lastStatus,
                stats: this.stats
            });
        }
    }

    async notifyStatusChange(status) {
        const validPorts = Array.from(this.popupPorts).filter(this.isValidPort);
        this.popupPorts = new Set(validPorts);

        const message = {
            type: 'STATUS_UPDATE',
            data: {
                api: status,
                stats: this.stats,
                timestamp: new Date().toISOString()
            }
        };

        validPorts.forEach(port => {
            try {
                port.postMessage(message);
            } catch (error) {
                console.warn('Failed to notify port:', error);
                this.popupPorts.delete(port);
            }
        });
    }

    getOfflineStatus() {
        return {
            isAvailable: false,
            status: 'offline',
            timestamp: new Date().toISOString(),
            models: { vi: false, en: false },
            error: 'Network offline',
            lastCheck: Date.now()
        };
    }
}

function extractComments(element) {
    const comments = [];

    if (!element) return comments;

    try {
        // Tìm tất cả role="article" elements
        const commentElements = element.querySelectorAll('[role="article"]');

        commentElements.forEach(container => {
            try {
                // Skip nếu là main post
                if (container === element) return;

                // Get author name - thử nhiều selectors
                const authorElement = (
                    container.querySelector('a[role="link"] span.x193iq5w span') ||
                    container.querySelector('a[href*="/user/"] span') ||
                    container.querySelector('a[role="link"] span')
                );
                const author = authorElement?.textContent?.trim();

                // Get comment text
                const textElement = container.querySelector('div[dir="auto"][style*="text-align"]');
                const text = textElement?.textContent?.trim();

                // Get timestamp
                const timeElement = container.querySelector('a[href*="comment_id"]');
                const time = timeElement?.textContent?.trim();

                // Lấy unique ID
                const commentId = container.getAttribute('data-commentid') ||
                    timeElement?.href?.match(/comment_id=(\d+)/)?.[1] ||
                    Date.now().toString();

                // Only add if valid
                if (author && text) {
                    comments.push({
                        id: commentId,
                        author,
                        text,
                        time,
                        isReply: isReplyComment(container)
                    });
                }
            } catch (err) {
                console.warn('Error extracting comment:', err);
            }
        });

    } catch (error) {
        console.error('Error in extractComments:', error);
    }

    return comments;
}

function isReplyComment(element) {
    return !!(
        element.closest('div[aria-label*="Reply"]') ||
        element.closest('div[aria-label*="Trả lời"]') ||
        element.closest('div[aria-label*="Phản hồi"]') ||
        element.querySelector('a[role="link"][href*="reply_comment_id"]') ||
        element.closest('div[style*="margin-left"]') ||
        element.closest('div[style*="padding-left"]')
    );
}

// Function to check if an element is a comment section
function isCommentSection(element) {
    // Check for common comment section identifiers
    return element.querySelector('[role="article"]') !== null;
}

// Function to process mutations for comments
function processMutations(mutations) {
    mutations.forEach(mutation => {
        mutation.addedNodes.forEach(node => {
            if (node.nodeType === Node.ELEMENT_NODE) {
                if (isCommentSection(node)) {
                    const comments = extractComments(node);
                    if (comments.length > 0) {
                        // Send comments to content script
                        chrome.tabs.query({ active: true, currentWindow: true }, function (tabs) {
                            chrome.tabs.sendMessage(tabs[0].id, {
                                type: "NEW_COMMENTS",
                                comments: comments
                            });
                        });
                    }
                }
            }
        });
    });
}

================
File: extension/content.js
================
// Prevent multiple initializations
if (!window.sentimentAnalyzer) {
    // Create style element first
    const createStyleSheet = () => {
        const styleSheet = document.createElement("style");
        styleSheet.id = 'sentiment-analyzer-styles';
        document.head.appendChild(styleSheet);
        return styleSheet;
    };

    class FacebookAnalyzer {
        constructor() {
            // Create styleSheet first
            this.styleSheet = document.getElementById('sentiment-analyzer-styles') || createStyleSheet();

            this.API_URL = 'http://localhost:7270';
            this.processedPosts = new Set();
            this.stats = {
                analyzed: 0,
                successful: 0
            };
            this.API_STATUS = false;
            this.MAX_RETRIES = 3;
            this.retryDelays = [1000, 2000, 4000]; // Exponential backoff
            this.init();
            this.registerMessageHandlers();
            this.initApiUrl();
            this.pendingUpdates = new Set();
            this.updateQueue = [];
            this.isProcessing = false;
            this.lastApiCheck = null;
            this.apiCheckInterval = 5000; // 5 seconds
            this.startApiStatusCheck();
            this.isConnectionReady = false;
            this.pendingMessages = [];
            this.initConnection();
            this.initStyles();
            this.readyState = false;
            this.initializeConnection();
            this.port = null;
            this.setupPort();

            // Add comment patterns for both languages
            this.COMMENT_PATTERNS = {
                en: [
                    /Comment by (.*?)$/i,
                    /Reply by (.*?)$/i,
                    /Comment from (.*?)$/i,
                    /Reply from (.*?)$/i,
                    /^(.*?)'s comment$/i,
                    /^(.*?)'s reply$/i
                ],
                vi: [
                    /Bình luận bởi (.*?)$/i,
                    /Trả lời bởi (.*?)$/i,
                    /Phản hồi từ (.*?)$/i,
                    /Bình luận của (.*?)$/i,
                    /Trả lời của (.*?)$/i,
                    /^(.*?) đã bình luận$/i,
                    /^(.*?) đã trả lời$/i
                ]
            };

            // Add cache control for API status
            this.lastHealthCheck = null;
            this.healthCheckCacheTime = 30000; // Cache health check for 30 seconds
            this.healthCheckPromise = null; // Store pending health check promise
            console.log('FacebookAnalyzer initialized');
            this.currentTheme = this.detectTheme();
            this.setupThemeObserver();
        }

        setupPort() {
            try {
                console.log('Setting up port connection');
                this.port = chrome.runtime.connect({ name: 'content-script' });

                this.port.onDisconnect.addListener(() => {
                    console.log('Port disconnected, attempting reconnect...');
                    setTimeout(() => this.setupPort(), 1000);
                });
            } catch (error) {
                console.error('Port setup error:', error);
                setTimeout(() => this.setupPort(), 1000);
            }
        }

        async initApiUrl() {
            try {
                console.log('Initializing API URL');
                const { apiUrl } = await chrome.storage.local.get('apiUrl');
                if (apiUrl) {
                    this.API_URL = apiUrl;
                }
                console.log('API URL set to:', this.API_URL);
            } catch (error) {
                console.error('Error loading API URL:', error);
            }
        }

        init() {
            console.log('Initializing FacebookAnalyzer');
            this.observePageChanges();
            this.addInitialButtons();
            this.handleUrlChange(); // Add this line to handle URL changes
        }

        handleUrlChange() {
            console.log('Setting up URL change handler');
            let lastUrl = location.href;
            const observer = new MutationObserver(() => {
                const currentUrl = location.href;
                if (currentUrl !== lastUrl) {
                    lastUrl = currentUrl;
                    console.log('URL changed to:', currentUrl);
                    this.onUrlChanged();
                }
            });
            observer.observe(document.body, { childList: true, subtree: true });
        }

        onUrlChanged() {
            console.log('Handling URL change');
            if (this.isFacebookPostUrl(location.href)) {
                this.processCurrentPost();
            }
        }

        isFacebookPostUrl(url) {
            const patterns = [
                /facebook\.com\/[^/]+\/posts\/\d+/,
                /facebook\.com\/[^/]+\/permalink\/\d+/,
                /facebook\.com\/[^/]+\/photos\/[^/]+\/\d+/,
                /facebook\.com\/photo\.php\?fbid=\d+/,
                /facebook\.com\/[^/]+\/videos\/\d+/,
                /facebook\.com\/video\.php\?v=\d+/,
                /facebook\.com\/[^/]+\?story_fbid=\d+/
            ];
            const isMatch = patterns.some(pattern => pattern.test(url));
            console.log('isFacebookPostUrl:', isMatch);
            return isMatch;
        }

        processCurrentPost() {
            console.log('Processing current post');
            // Check if posts are loaded on the page
            const post = document.querySelector('[role="article"]');
            if (post) {
                console.log('Post found, analyzing');
                // Analyze the post and its comments
                this.analyzePost(post);
            } else {
                console.log('Post not found, setting up observer');
                // Wait for the post to load
                const observer = new MutationObserver((mutations, obs) => {
                    const post = document.querySelector('[role="article"]');
                    if (post) {
                        obs.disconnect();
                        console.log('Post loaded, analyzing');
                        this.analyzePost(post);
                    }
                });
                observer.observe(document.body, { childList: true, subtree: true });
            }
        }

        observePageChanges() {
            console.log('Observing page changes');
            const observer = new MutationObserver(() => {
                this.addInitialButtons();
                this.addCommentSectionButtons();
            });
            observer.observe(document.body, {
                childList: true,
                subtree: true
            });
        }

        addInitialButtons() {
            console.log('Adding initial buttons');
            const posts = document.querySelectorAll('div[data-pagelet^="FeedUnit_"]');
            posts.forEach(post => {
                if (!this.processedPosts.has(post)) {
                    this.addAnalyzeButton(post);
                    this.processedPosts.add(post);
                }
            });
        }

        addAnalyzeButton(post) {
            console.log('Adding analyze button to post');
            const button = document.createElement('button');
            button.className = 'sentiment-analyze-btn';
            button.textContent = 'Phân tích cảm xúc';
            button.onclick = () => this.analyzePost(post);

            const buttonContainer = document.createElement('div');
            buttonContainer.className = 'sentiment-button-container';
            buttonContainer.appendChild(button);

            const actionsBar = post.querySelector('[aria-label="Actions for this post"]');
            if (actionsBar) {
                actionsBar.parentNode.insertBefore(buttonContainer, actionsBar.nextSibling);
            } else {
                // Fallback if actions bar is not found
                post.appendChild(buttonContainer);
            }
        }

        addCommentSectionButtons() {
            console.log('Adding comment section buttons');
            // Find all comment section buttons that don't have our analyze button
            const commentButtons = document.querySelectorAll('div[role="button"]:not(.has-analyze-btn)');

            commentButtons.forEach(button => {
                // Check if it's a comment button by looking for typical text patterns
                const text = button.textContent.toLowerCase();
                if (text.includes('bình luận') || text.includes('comments')) {
                    button.classList.add('has-analyze-btn');

                    // Create analyze button
                    const analyzeBtn = document.createElement('div');
                    analyzeBtn.className = 'sentiment-analyze-btn-inline';
                    analyzeBtn.innerHTML = `
                        <div role="button" class="analyze-comments-btn">
                            <span>Phân tích</span>
                        </div>
                    `;

                    // Add click handler
                    analyzeBtn.onclick = (e) => {
                        e.stopPropagation();
                        // Find the closest article element (post container)
                        const postElement = button.closest('[role="article"]');
                        if (postElement) {
                            this.analyzePost(postElement);
                        }
                    };

                    // Insert after the comment button
                    const container = button.parentElement;
                    if (container) {
                        // Create a wrapper if needed
                        let wrapper = container.querySelector('.comment-buttons-wrapper');
                        if (!wrapper) {
                            wrapper = document.createElement('div');
                            wrapper.className = 'comment-buttons-wrapper';
                            container.appendChild(wrapper);
                        }
                        wrapper.appendChild(analyzeBtn);
                    }
                }
            });
        }

        initConnection() {
            console.log('Initializing connection');
            // Send ready message and wait for acknowledgment
            chrome.runtime.sendMessage({ type: 'CONTENT_SCRIPT_READY' }, (response) => {
                if (response?.success) {
                    this.isConnectionReady = true;
                    // Process any pending messages
                    this.processPendingMessages();
                }
            });

            // Handle connection status check
            chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
                if (message.type === 'PING') {
                    sendResponse({ success: true, ready: this.isConnectionReady });
                    return true;
                }
            });
        }

        setupConnectionListener() {
            console.log('Setting up connection listener');
            // Notify that content script is ready
            chrome.runtime.sendMessage({ type: 'CONTENT_SCRIPT_READY' }, (response) => {
                if (chrome.runtime.lastError) {
                    console.warn('Connection setup error:', chrome.runtime.lastError);
                    return;
                }
                this.isConnectionReady = true;
            });
        }

        registerMessageHandlers() {
            console.log('Registering message handlers');
            chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
                // Immediately send acknowledgment
                sendResponse({ received: true });

                // Handle the message asynchronously
                this.handleAsyncMessage(request).then(response => {
                    // Send response through port if available
                    if (this.port) {
                        this.port.postMessage({
                            type: 'RESPONSE',
                            requestId: request.requestId,
                            response: response
                        });
                    }
                }).catch(error => {
                    console.error('Message handling error:', error);
                    if (this.port) {
                        this.port.postMessage({
                            type: 'ERROR',
                            requestId: request.requestId,
                            error: error.message
                        });
                    }
                });

                // Return true to indicate we'll send response asynchronously
                return true;
            });
        }

        async handleAsyncMessage(request) {
            console.log('Handling async message:', request);
            return new Promise(async (resolve, reject) => {
                try {
                    if (!request || !request.type) {
                        throw new Error('Invalid message format');
                    }

                    let response;
                    switch (request.type) {
                        case 'ANALYZE_POST':
                            if (!request.postId) {
                                throw new Error('Missing postId parameter');
                            }
                            // Find the post element first
                            const postElement = await this.findPostElement(request.postId);
                            if (!postElement) {
                                throw new Error('Post element not found');
                            }
                            response = await this.analyzeFacebookPost(postElement);
                            break;

                        case 'ANALYZE_CURRENT':
                            const post = document.querySelector('[role="article"]');
                            if (!post) {
                                throw new Error('No post found on current page');
                            }
                            response = await this.analyzePost(post);
                            break;

                        case 'PING':
                            response = {
                                success: true,
                                ready: this.readyState,
                                url: window.location.href,
                                status: this.API_STATUS
                            };
                            break;

                        case 'GET_STATS':
                            response = {
                                success: true,
                                stats: this.stats,
                                analyzed: this.stats.analyzed,
                                successful: this.stats.successful
                            };
                            break;

                        case 'RESET_STATS':
                            this.stats = { analyzed: 0, successful: 0 };
                            response = { success: true, stats: this.stats };
                            break;

                        case 'UPDATE_STATE':
                            if (request.stats) {
                                Object.assign(this.stats, request.stats);
                            }
                            if (request.apiStatus !== undefined) {
                                this.API_STATUS = request.apiStatus;
                            }
                            response = {
                                success: true,
                                stats: this.stats,
                                apiStatus: this.API_STATUS
                            };
                            break;

                        case 'API_URL_CHANGED':
                            await this.initApiUrl();
                            await this.checkApiStatus();
                            response = {
                                success: true,
                                apiUrl: this.API_URL,
                                status: this.API_STATUS
                            };
                            break;

                        case 'CHECK_API':
                            const status = await this.checkApiStatus();
                            response = {
                                success: true,
                                status: status,
                                apiUrl: this.API_URL
                            };
                            break;

                        case 'API_STATUS_UPDATE':
                            this.handleApiStatusUpdate(request.status);
                            response = { success: true };
                            break;

                        case 'DATA_UPDATE':
                            this.handleDataUpdate(request.data);
                            response = { success: true };
                            break;

                        default:
                            throw new Error(`Unsupported message type: ${request.type}`);
                    }

                    resolve({
                        success: true,
                        requestId: request.requestId,
                        ...response
                    });

                } catch (error) {
                    console.error('Message handling error:', error);
                    reject({
                        success: false,
                        requestId: request?.requestId,
                        error: error.message || 'Unknown error occurred',
                        details: error.stack
                    });
                }
            });
        }

        handleApiStatusUpdate(status) {
            console.log('API status updated:', status);
            this.API_STATUS = status.isAvailable;

            if (status.isAvailable) {
                this.processPendingUpdates();
            }
        }

        async findPostElement(postId) {
            console.log('Finding post element for postId:', postId);
            const selectors = [
                `[data-post-id="${postId}"]`,
                `[data-ft*="${postId}"]`,
                `[id*="post_content_${postId}"]`,
                `[id*="${postId}"]`,
                '[role="article"]'
            ];

            const element = document.querySelector(selectors.join(','));
            if (!element) {
                throw new Error('Post element not found');
            }
            return element;
        }

        async processPendingMessages() {
            console.log('Processing pending messages');
            while (this.pendingMessages.length > 0) {
                const { request, sender, sendResponse } = this.pendingMessages.shift();
                await this.handleMessage(request, sender, sendResponse);
            }
        }

        handleDataUpdate(data) {
            console.log('Handling data update:', data);
            if (data.status) {
                this.API_STATUS = data.status.isAvailable;
            }
            // Process any pending updates if API is available
            if (this.API_STATUS) {
                this.processPendingUpdates();
            }
        }

        async analyzePost(post) {
            console.log('Analyzing post:', post);

            // Ensure 'post' is a DOM Element
            if (!(post instanceof Element)) {
                console.warn('Invalid post element');
                return;
            }

            const postId = post.getAttribute('data-post-id') || Date.now().toString();

            if (this.pendingUpdates.has(postId)) {
                console.log('Post is already being analyzed');
                return;
            }

            this.pendingUpdates.add(postId);

            try {
                // Disable the analyze button to prevent multiple clicks
                const button = post.querySelector('.sentiment-analyze-btn');
                if (button) {
                    button.disabled = true;
                    button.textContent = 'Đang phân tích...';
                }

                // Analyze post content
                await this.analyzeFacebookPost(post);

                // Load all comments
                await this.loadMoreComments(post);

                // Find all comments in the post
                const comments = this.findComments(post);

                // Analyze each comment
                for (const comment of comments) {
                    await this.analyzeComment(comment);
                }

                // Update stats
                this.stats.analyzed += comments.length;
                this.stats.successful += comments.length; // Assuming all analyses are successful

                // Notify background script to update stats
                chrome.runtime.sendMessage({ type: 'UPDATE_STATS', stats: this.stats });

                // Re-enable the analyze button
                if (button) {
                    button.disabled = false;
                    button.textContent = 'Phân tích lại';
                }

            } catch (error) {
                console.error('Error analyzing post and comments:', error);
                this.showError('Có lỗi xảy ra khi phân tích bài viết này.');

                // Re-enable the analyze button
                const button = post.querySelector('.sentiment-analyze-btn');
                if (button) {
                    button.disabled = false;
                    button.textContent = 'Phân tích lại';
                }
            } finally {
                this.pendingUpdates.delete(postId);
            }
        }

        async checkApiStatus() {
            console.log('Checking API status');
            // Return cached status if within cache time
            if (this.lastHealthCheck &&
                Date.now() - this.lastHealthCheck.timestamp < this.healthCheckCacheTime) {
                return this.lastHealthCheck.status;
            }

            // Return existing promise if health check is in progress
            if (this.healthCheckPromise) {
                return this.healthCheckPromise;
            }

            // Perform new health check
            this.healthCheckPromise = (async () => {
                try {
                    const controller = new AbortController();
                    const timeoutId = setTimeout(() => controller.abort(), 3000);

                    const response = await fetch(`${this.API_URL}/health`, {
                        signal: controller.signal,
                        method: 'GET',
                        headers: {
                            'Accept': 'application/json',
                            'Cache-Control': 'no-cache'
                        },
                        mode: 'cors',
                        cache: 'no-cache'
                    });

                    clearTimeout(timeoutId);

                    if (response.ok) {
                        const data = await response.json();
                        const models = data.models || { vi: false, en: false };
                        const activeModels = Object.values(models).filter(status => status).length;

                        this.API_STATUS = data.status === "healthy" && activeModels > 0;

                        // Cache the result
                        this.lastHealthCheck = {
                            timestamp: Date.now(),
                            status: this.API_STATUS
                        };

                        return this.API_STATUS;
                    }

                    this.API_STATUS = false;
                    return false;

                } catch (error) {
                    console.error('API check error:', error);
                    this.API_STATUS = false;
                    return false;
                } finally {
                    this.healthCheckPromise = null;
                }
            })();

            return this.healthCheckPromise;
        }

        async analyzeSentiment(text, retryCount = 0) {
            console.log('Analyzing sentiment for text:', text);
            if (!this.API_STATUS && !(await this.checkApiStatus())) {
                this.showError('API không khả dụng. Vui lòng thử lại sau.');
                return null;
            }

            try {
                console.log('Sending request to:', `${this.API_URL}/predict`);

                const response = await fetch(`${this.API_URL}/predict`, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Accept': 'application/json',
                    },
                    mode: 'cors',
                    cache: 'no-cache',
                    body: JSON.stringify({
                        text: text,
                        language: 'vi'
                    })
                });

                console.log('API Response:', response.status, response.statusText);

                if (!response.ok) {
                    throw new Error(`HTTP error! status: ${response.status}`);
                }

                const result = await response.json();
                console.log('API Result:', result);
                return result;
            } catch (error) {
                if (retryCount < this.MAX_RETRIES) {
                    await new Promise(resolve => setTimeout(resolve, 1000 * (retryCount + 1)));
                    return this.analyzeSentiment(text, retryCount + 1);
                }
                this.API_STATUS = false;
                console.error('API error:', error);
                return null;
            }
        }

        async processPendingUpdates() {
            console.log('Processing pending updates');
            if (this.isProcessing || this.updateQueue.length === 0) return;

            this.isProcessing = true;
            while (this.updateQueue.length > 0) {
                const update = this.updateQueue.shift();
                try {
                    await this.processUpdate(update);
                } catch (error) {
                    console.error('Update processing error:', error);
                }
            }
            this.isProcessing = false;
        }

        async processUpdate(update) {
            console.log('Processing update:', update);
            try {
                switch (update.type) {
                    case 'POST_ANALYSIS':
                        await this.analyzePost(update.post);
                        break;
                    case 'COMMENT_ANALYSIS':
                        await this.analyzeComment(update.comment);
                        break;
                    case 'BATCH_ANALYSIS':
                        await this.analyzeBatch(update.items);
                        break;
                    case 'UPDATE_UI':
                        await this.updateUI(update.data);
                        break;
                    case 'REFRESH_BUTTONS':
                        this.addInitialButtons();
                        this.addCommentSectionButtons();
                        break;
                    case 'UPDATE_STYLES':
                        this.updateStyles(update.styles);
                        break;
                    default:
                        console.warn('Unknown update type:', update.type);
                }
            } catch (error) {
                console.error('Error processing update:', error);
                this.updateQueue.push(update); // Re-queue failed updates
            }
        }

        async analyzeComment(comment) {
            console.log('Analyzing comment:', comment);
            const loadingIndicator = this.addLoadingIndicator(comment);
            try {
                const text = comment.textContent.trim();
                const result = await this.analyzeSentiment(text);
                if (result) {
                    this.displayResult(comment, result, 'Bình luận');
                    this.stats.successful++;
                }
                this.stats.analyzed++;
            } finally {
                loadingIndicator.remove();
            }
        }

        async analyzeBatch(items) {
            console.log('Analyzing batch of items:', items);
            for (const item of items) {
                try {
                    if (item.type === 'post') {
                        await this.analyzePost(item.element);
                    } else if (item.type === 'comment') {
                        await this.analyzeComment(item.element);
                    }
                } catch (error) {
                    console.error('Batch analysis error:', error);
                }
            }
        }

        async extractPostContent(postElement) {
            console.log('Extracting post content from element:', postElement);
            try {
                const content = {
                    text: '',
                    comments: [],
                    reactions: {
                        total: 0,
                        types: {}
                    }
                };

                // Extract post content
                const postText = postElement.querySelector('[data-ad-preview="message"]');
                if (postText) {
                    content.text = postText.textContent.trim();
                }

                // Extract comments
                const commentElements = postElement.querySelectorAll('[role="article"]');
                for (const comment of commentElements) {
                    try {
                        const commentData = {
                            id: comment.getAttribute('data-commentid') || Date.now().toString(),
                            text: '',
                            user: {
                                name: '',
                                profile: ''
                            },
                            timestamp: '',
                            reactions: []
                        };

                        // Get comment text
                        const commentText = comment.querySelector('[data-ad-preview="message"]');
                        if (commentText) {
                            commentData.text = commentText.textContent.trim();
                        }

                        // Get user info
                        const userLink = comment.querySelector('a[role="link"][tabindex="0"]');
                        if (userLink) {
                            commentData.user.name = userLink.textContent.trim();
                            commentData.user.profile = userLink.href;
                        }

                        // Get timestamp if available
                        const timestamp = comment.querySelector('a[role="link"][href*="comment_id"]');
                        if (timestamp) {
                            commentData.timestamp = timestamp.textContent.trim();
                        }

                        content.comments.push(commentData);
                    } catch (err) {
                        console.error('Error extracting comment:', err);
                    }
                }

                // Extract reaction counts
                const reactionBar = postElement.querySelector('[aria-label*="reaction"]');
                if (reactionBar) {
                    const reactionText = reactionBar.getAttribute('aria-label');
                    // Parse reaction counts from aria-label text
                    const counts = this.parseReactionCounts(reactionText);
                    content.reactions = counts;
                }

                return content;
            } catch (error) {
                console.error('Error extracting post content:', error);
                throw error;
            }
        }

        parseReactionCounts(text) {
            const counts = {
                total: 0,
                types: {}
            };

            try {
                // Common reaction types in Vietnamese
                const reactionTypes = {
                    'Thích': 'like',
                    'Yêu thích': 'love',
                    'Haha': 'haha',
                    'Wow': 'wow',
                    'Buồn': 'sad',
                    'Phẫn nộ': 'angry'
                };

                // Extract numbers and reaction types from text
                for (const [vn, en] of Object.entries(reactionTypes)) {
                    const regex = new RegExp(`(\\d+)\\s*${vn}`);
                    const match = text.match(regex);
                    if (match) {
                        const count = parseInt(match[1]);
                        counts.types[en] = count;
                        counts.total += count;
                    }
                }
            } catch (err) {
                console.error('Error parsing reactions:', err);
            }

            return counts;
        }

        async analyzeFacebookPost(postElement) {
            console.log('Analyzing Facebook post:', postElement);
            try {
                // Validate post element
                if (!postElement || !(postElement instanceof Element)) {
                    throw new Error('Invalid post element provided');
                }

                let totalAnalyzed = 0;
                let successfulAnalyses = 0;

                // Use custom element query helper
                const postContent = this.findPostContent(postElement);
                if (postContent) {
                    const text = postContent.textContent.trim();
                    if (text) {
                        const postResult = await this.analyzeSentiment(text);
                        if (postResult) {
                            this.displayResult(postContent, postResult);
                            successfulAnalyses++;
                        }
                        totalAnalyzed++;
                    }
                }

                // Find and analyze comments
                const comments = this.findComments(postElement);
                for (const comment of comments) {
                    if (!comment.text) continue;

                    const loadingIndicator = this.addLoadingIndicator(comment.element);
                    try {
                        const result = await this.analyzeSentiment(comment.text);
                        if (result) {
                            this.displayResult(
                                comment.element,
                                result,
                                `Bình luận của ${comment.userName}`
                            );
                            successfulAnalyses++;
                        }
                        totalAnalyzed++;
                    } finally {
                        loadingIndicator.remove();
                    }
                }

                // Update stats
                this.stats.analyzed += totalAnalyzed;
                this.stats.successful += successfulAnalyses;

                return {
                    success: true,
                    analyzed: totalAnalyzed,
                    successful: successfulAnalyses
                };

            } catch (error) {
                console.error('Analysis error:', error);
                this.showError(error.message || 'Có lỗi xảy ra khi phân tích');
                throw error;
            }
        }

        displayResult(element, result) {
            if (!result) return;

            const resultDiv = document.createElement('div');
            resultDiv.className = `sentiment-result sentiment-${this.getSentimentClass(result.sentiment)}`;

            resultDiv.innerHTML = `
                <div style="margin: 4px 0;">
                    <span class="emoji">${result.emotion_emoji}</span>
                    <strong>${this.getSentimentLabel(result.sentiment)}</strong>
                    - ${result.emotion_vi}
                </div>
                <span class="sentiment-confidence">
                    Độ tin cậy: ${(result.sentiment_confidence * 100).toFixed(1)}%
                </span>
            `;

            // Insert after target element with smooth animation
            resultDiv.style.opacity = '0';
            resultDiv.style.transform = 'translateY(-4px)';
            element.parentNode.insertBefore(resultDiv, element.nextSibling);

            // Trigger animation
            requestAnimationFrame(() => {
                resultDiv.style.transition = 'opacity 0.3s ease, transform 0.3s ease';
                resultDiv.style.opacity = '1';
                resultDiv.style.transform = 'translateY(0)';
            });
        }

        getSentimentLabel(sentiment) {
            return {
                2: 'Tích cực',
                1: 'Trung tính',
                0: 'Tiêu cực'
            }[sentiment] || 'Trung tính';
        }

        getSentimentClass(sentiment) {
            return {
                2: 'positive',
                1: 'neutral',
                0: 'negative'
            }[sentiment] || 'neutral';
        }

        addLoadingIndicator(element) {
            const indicator = document.createElement('div');
            indicator.className = 'sentiment-loading';
            indicator.innerHTML = '<div class="spinner"></div>';
            element.parentNode.insertBefore(indicator, element.nextSibling);
            return indicator;
        }

        showError(message) {
            const errorDiv = document.createElement('div');
            errorDiv.className = 'sentiment-error';
            errorDiv.textContent = message;
            document.body.appendChild(errorDiv);
            setTimeout(() => errorDiv.remove(), 3000);
        }

        startApiStatusCheck() {
            console.log('Starting API status check');
            // Check API status every 60 seconds instead of 5 seconds
            setInterval(async () => {
                if (!this.lastHealthCheck ||
                    Date.now() - this.lastHealthCheck.timestamp >= 60000) {
                    await this.checkApiStatus();
                }
            }, 60000); // 1 minute interval
        }

        detectTheme() {
            // Check for dark mode by looking at Facebook's background color
            const bodyBg = window.getComputedStyle(document.body).backgroundColor;
            return this.isHexColorDark(bodyBg) ? 'dark' : 'light';
        }

        isHexColorDark(color) {
            // Convert RGB/RGBA to brightness value
            const rgb = color.match(/\d+/g);
            if (!rgb || rgb.length < 3) return false;

            // Calculate relative luminance
            const brightness = (parseInt(rgb[0]) * 299 + parseInt(rgb[1]) * 587 + parseInt(rgb[2]) * 114) / 1000;
            return brightness < 128;
        }

        setupThemeObserver() {
            // Watch for Facebook theme changes
            const observer = new MutationObserver(() => {
                const newTheme = this.detectTheme();
                if (newTheme !== this.currentTheme) {
                    this.currentTheme = newTheme;
                    this.updateThemeStyles();
                }
            });

            observer.observe(document.body, {
                attributes: true,
                attributeFilter: ['class']
            });
        }

        updateThemeStyles() {
            const themeStyles = this.getThemeStyles();
            let styleSheet = document.getElementById('sentiment-analyzer-styles');
            if (styleSheet) {
                styleSheet.textContent = themeStyles;
            }
        }

        getThemeStyles() {
            const baseStyles = `
                .sentiment-analyze-btn {
                    background: #1877f2;
                    color: white;
                    padding: 8px 16px;
                    border-radius: 6px;
                    border: none;
                    font-weight: 500;
                    cursor: pointer;
                    transition: background 0.2s;
                }

                .sentiment-analyze-btn:hover {
                    background: #166fe5;
                }

                .sentiment-analyze-btn:disabled {
                    background: #8ab4f8;
                    cursor: not-allowed;
                }

                .sentiment-result {
                    margin: 8px 0;
                    padding: 12px 16px;
                    border-radius: 8px;
                    font-size: 13px;
                    line-height: 1.5;
                    font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, Arial, sans-serif;
                    transition: all 0.2s ease;
                }

                .sentiment-result .emoji {
                    font-size: 16px;
                    margin-right: 6px;
                    vertical-align: -2px;
                }
            `;

            const lightModeStyles = `
                .sentiment-result {
                    box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
                }

                .sentiment-result strong {
                    color: #050505;
                }

                .sentiment-positive {
                    background-color: #e7f3e8;
                    border: 1px solid rgba(35, 134, 54, 0.15);
                    color: #1d4121;
                }

                .sentiment-negative {
                    background-color: #ffebe9;
                    border: 1px solid rgba(255, 129, 130, 0.15);
                    color: #67060c;
                }

                .sentiment-neutral {
                    background-color: #f0f2f5;
                    border: 1px solid rgba(0, 0, 0, 0.08);
                    color: #050505;
                }

                .sentiment-confidence {
                    background: rgba(0, 0, 0, 0.05);
                    color: #050505;
                }
            `;

            const darkModeStyles = `
                .sentiment-result {
                    box-shadow: 0 1px 2px rgba(255, 255, 255, 0.05);
                }

                .sentiment-result strong {
                    color: #e4e6eb;
                }

                .sentiment-positive {
                    background-color: rgba(45, 136, 64, 0.2);
                    border: 1px solid rgba(45, 136, 64, 0.3);
                    color: #88cf8f;
                }

                .sentiment-negative {
                    background-color: rgba(255, 69, 68, 0.2);
                    border: 1px solid rgba(255, 69, 68, 0.3);
                    color: #ff6b6b;
                }

                .sentiment-neutral {
                    background-color: rgba(255, 255, 255, 0.05);
                    border: 1px solid rgba(255, 255, 255, 0.1);
                    color: #e4e6eb;
                }

                .sentiment-confidence {
                    background: rgba(255, 255, 255, 0.1);
                    color: #e4e6eb;
                }
            `;

            return `
                ${baseStyles}
                ${this.currentTheme === 'dark' ? darkModeStyles : lightModeStyles}
                
                @keyframes spin {
                    0% { transform: rotate(0deg); }
                    100% { transform: rotate(360deg); }
                }
            }
            `;
        }

        initStyles() {
            // Replace existing initStyles with new theme-aware version
            const styleSheet = document.getElementById('sentiment-analyzer-styles') || createStyleSheet();
            styleSheet.textContent = this.getThemeStyles();
        }

        async initializeConnection(retryCount = 0) {
            console.log('Initializing connection');
            try {
                // Signal that content script is ready
                chrome.runtime.sendMessage({
                    type: 'CONTENT_SCRIPT_READY',
                    url: window.location.href
                }, (response) => {
                    if (chrome.runtime.lastError) {
                        console.warn('Initial connection failed:', chrome.runtime.lastError);
                        // Retry after delay
                        if (retryCount < this.MAX_RETRIES) {
                            setTimeout(() => this.initializeConnection(retryCount + 1), 1000);
                        }
                        return;
                    }
                    this.readyState = true;
                    this.processPendingMessages();
                });

                // Handle connection requests
                chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
                    if (message.type === 'PING') {
                        sendResponse({
                            success: true,
                            ready: this.readyState,
                            url: window.location.href
                        });
                        return true;
                    }
                    return false;
                });

            } catch (error) {
                console.error('Connection initialization error:', error);
                // Retry after delay
                if (retryCount < this.MAX_RETRIES) {
                    setTimeout(() => this.initializeConnection(retryCount + 1), 1000);
                }
            }
        }

        /**
         * Extract comment text from a Facebook comment element
         * @param {Element} commentElement - The root comment element
         * @returns {string|null}
         */
        extractCommentText(commentElement) {
            // Tìm div có attribute dir="auto" chứa nội dung comment
            const textContainers = commentElement.querySelectorAll('div[dir="auto"]');

            for (const container of textContainers) {
                // Kiểm tra xem div này có phải là container chứa nội dung comment không
                // bằng cách verify nó không chứa các elements khác như link, button
                if (!container.querySelector('a, button') && container.textContent.trim()) {
                    return container.textContent.trim();
                }
            }

            return null;
        }

        /**
         * Extract username from a Facebook comment element
         * @param {Element} commentElement - The root comment element
         * @returns {string|null}
         */
        extractUsername(commentElement) {
            // Tìm link profile của user
            const userLinks = commentElement.querySelectorAll('a[role="link"]');

            for (const link of userLinks) {
                // Kiểm tra xem link có phải là profile link không
                const href = link.getAttribute('href');
                if (href && href.includes('/user/')) {
                    // Tìm span chứa tên người dùng
                    const spans = link.querySelectorAll('span');
                    for (const span of spans) {
                        const text = span.textContent.trim();
                        // Loại bỏ các text không phải tên người dùng như timestamp
                        if (text && !text.includes('h') && !text.match(/^\d+$/)) {
                            return text;
                        }
                    }
                }
            }

            return null;
        }

        /**
         * Extract timestamp from a Facebook comment element
         * @param {Element} commentElement - The root comment element
         * @returns {string|null}
         */
        extractTimestamp(commentElement) {
            // Tìm link chứa timestamp
            const links = commentElement.querySelectorAll('a');

            for (const link of links) {
                const text = link.textContent.trim();
                // Timestamp thường có format như "1h", "2m", "3d" etc.
                if (text.match(/^\d+[hdmsy]$/i)) {
                    return text;
                }
            }

            return null;
        }

        /**
         * Check if user is a top contributor
         * @param {Element} commentElement - The root comment element
         * @returns {boolean}
         */
        isTopContributor(commentElement) {
            const elements = commentElement.querySelectorAll('div[role="link"]');
            for (const element of elements) {
                if (element.textContent.includes('Top contributor')) {
                    return true;
                }
            }
            return false;
        }

        /**
         * Parse a single Facebook comment
         * @param {Element} commentElement - The root comment element with role="article"
         * @returns {Object} Parsed comment data
         */
        parseComment(commentElement) {
            return {
                username: this.extractUsername(commentElement),
                text: this.extractCommentText(commentElement),
                timestamp: this.extractTimestamp(commentElement),
                isTopContributor: this.isTopContributor(commentElement)
            };
        }

        /**
         * Parse all comments in a container
         * @param {Element} container - The container element
         * @returns {Array<Object>} Array of parsed comments
         */
        parseComments(container) {
            const commentElements = container.querySelectorAll('[role="article"]');
            const comments = [];

            for (const element of commentElements) {
                try {
                    const comment = this.parseComment(element);
                    if (comment.text && comment.username) { // Only add valid comments
                        comments.push(comment);
                    }
                } catch (error) {
                    console.warn('Failed to parse comment:', error);
                }
            }

            return comments;
        }

        /**
         * Utility function to observe DOM changes and parse new comments
         * @param {Element} container - The container to observe
         * @param {Function} callback - Callback function to handle new comments
         * @returns {MutationObserver}
         */
        observeNewComments(container, callback) {
            const observer = new MutationObserver((mutations) => {
                for (const mutation of mutations) {
                    const newComments = Array.from(mutation.addedNodes)
                        .filter(node => node.nodeType === 1 && node.getAttribute('role') === 'article')
                        .map(element => this.parseComment(element))
                        .filter(comment => comment.text && comment.username);

                    if (newComments.length > 0) {
                        callback(newComments);
                    }
                }
            });

            observer.observe(container, {
                childList: true,
                subtree: true
            });

            return observer;
        }

        async loadMoreComments(postElement) {
            console.log('Loading all comments...');
            try {
                let continueLoading = true;
                let lastCommentCount = 0;
                let attempts = 0;
                const maxAttempts = 30; // Increase the number of attempts to load comments

                while (continueLoading && attempts < maxAttempts) {
                    const currentComments = postElement.querySelectorAll('[role="article"]').length;
                    console.log(`Current comment count: ${currentComments}`);

                    // Check if new comments are loaded
                    if (currentComments === lastCommentCount) {
                        attempts++;
                    } else {
                        attempts = 0; // Reset attempts if new comments are found
                        lastCommentCount = currentComments;
                    }

                    // Click all "view more comments" and "view previous comments" buttons
                    const moreCommentButtons = Array.from(postElement.querySelectorAll('div[role="button"]')).filter(button => {
                        const text = button.textContent.toLowerCase();
                        return (text.includes('xem thêm bình luận') ||
                            text.includes('xem các bình luận trước') ||
                            text.includes('view more comments') ||
                            text.includes('view previous comments') ||
                            text.match(/\d+\s*(bình luận|comments?)/i));
                    });

                    // Click all "view replies" buttons
                    const replyButtons = Array.from(postElement.querySelectorAll('div[role="button"]')).filter(button => {
                        const text = button.textContent.toLowerCase();
                        return (text.includes('phản hồi') ||
                            text.includes('trả lời') ||
                            text.includes('replies') ||
                            text.match(/\d+\s*(reply|repl)/i));
                    });

                    let clickedAny = false;

                    // Click "view more comments" buttons
                    for (const button of moreCommentButtons) {
                        try {
                            // Scroll to button
                            await this.smoothScrollTo(button);
                            await new Promise(r => setTimeout(r, 1000));

                            button.click();
                            clickedAny = true;
                            console.log('Clicked more comments button');
                            await new Promise(r => setTimeout(r, 2000));
                        } catch (error) {
                            console.warn('Error clicking more comments button:', error);
                        }
                    }

                    // Click "view replies" buttons
                    for (const button of replyButtons) {
                        try {
                            await this.smoothScrollTo(button);
                            await new Promise(r => setTimeout(r, 1000));

                            button.click();
                            clickedAny = true;
                            console.log('Clicked reply button');
                            await new Promise(r => setTimeout(r, 1500));
                        } catch (error) {
                            console.warn('Error clicking reply button:', error);
                        }
                    }

                    // Stop if no buttons were clicked
                    if (!clickedAny) {
                        attempts++;
                    }

                    // Scroll to the bottom to trigger lazy loading
                    await this.smoothScrollTo(postElement.lastElementChild);
                    await new Promise(r => setTimeout(r, 2000));

                    continueLoading = clickedAny || attempts < 3;
                }

                // Final count
                const finalCommentCount = postElement.querySelectorAll('[role="article"]').length - 1; // Subtract 1 for the main post
                console.log(`Finished loading comments. Total found: ${finalCommentCount}`);

            } catch (error) {
                console.error('Error loading comments:', error);
            }
        }

        // Thêm helper method để scroll mượt
        async smoothScrollTo(element) {
            if (!element) return;

            element.scrollIntoView({
                behavior: 'smooth',
                block: 'center'
            });

            // Đợi scroll hoàn tất
            await new Promise(resolve => {
                let lastPos = window.scrollY;
                const checkScrollEnd = setInterval(() => {
                    if (window.scrollY === lastPos) {
                        clearInterval(checkScrollEnd);
                        resolve();
                    }
                    lastPos = window.scrollY;
                }, 50);

                // Timeout sau 3 giây nếu scroll không kết thúc
                setTimeout(() => {
                    clearInterval(checkScrollEnd);
                    resolve();
                }, 3000);
            });
        }

        findComments(postElement) {
            const comments = new Set(); // Sử dụng Set để tránh trùng lặp
            try {
                // Tìm tất cả role="article" elements
                const commentElements = postElement.querySelectorAll('[role="article"]');
                
                commentElements.forEach(element => {
                    // Skip nếu element này là main post
                    if (element === postElement) return;

                    try {
                        // Lấy text content
                        const textElement = element.querySelector('div[dir="auto"][style*="text-align"]');
                        const text = textElement?.textContent?.trim();

                        // Lấy author name - thử các selector khác nhau
                        const authorElement = (
                            element.querySelector('a[role="link"] span.x193iq5w span') || 
                            element.querySelector('a[href*="/user/"] span') ||
                            element.querySelector('a[role="link"] span')
                        );
                        const author = authorElement?.textContent?.trim();

                        // Lấy timestamp
                        const timeElement = element.querySelector('a[href*="comment_id"]');
                        const timestamp = timeElement?.textContent?.trim();

                        // Kiểm tra xem comment có phải là reply không
                        const isReply = this.isReplyComment(element);

                        // Chỉ thêm vào nếu có đủ text và author
                        if (text && author) {
                            comments.add({
                                element,
                                text,
                                userName: author,
                                timestamp,
                                isReply,
                                // Thêm id để track
                                id: element.getAttribute('data-commentid') || 
                                    timeElement?.href?.match(/comment_id=(\d+)/)?.[1] ||
                                    Date.now().toString()
                            });
                        }
                    } catch (err) {
                        console.warn('Error parsing comment:', err);
                    }
                });

                const commentArray = Array.from(comments);
                console.log(`Found ${commentArray.length} unique comments`);
                return commentArray;

            } catch (error) {
                console.error('Error finding comments:', error);
                return Array.from(comments);
            }
        }

        isReplyComment(element) {
            // Kiểm tra các pattern chỉ ra đây là reply
            return !!(
                element.closest('div[aria-label*="Reply"]') ||
                element.closest('div[aria-label*="Trả lời"]') ||
                element.closest('div[aria-label*="Phản hồi"]') ||
                element.querySelector('a[role="link"][href*="reply_comment_id"]') ||
                element.closest('div[style*="margin-left"]') || // Replies thường được indent
                element.closest('div[style*="padding-left"]')
            );
        }

        findPostContent(element) {
            if (!element) return null;

            // Try different selectors in order of preference
            const selectors = [
                'div[dir="auto"][style*="text-align"]',
                'div[data-ad-preview="message"]',
                'div[data-ad-comet-preview="message"]',
                // Fallback selectors
                '[role="article"] div[dir="auto"]',
                '[data-ad-preview="message"]'
            ];

            for (const selector of selectors) {
                const content = element.querySelector(selector);
                if (content?.textContent.trim()) {
                    return content;
                }
            }

            return null;
        }
    }

    // Create single instance
    window.sentimentAnalyzer = new FacebookAnalyzer();

    // Initialize styles only once
    if (!document.getElementById('sentiment-analyzer-styles')) {
        const styleSheet = document.createElement("style");
        styleSheet.id = 'sentiment-analyzer-styles';
        styleSheet.textContent = `
            .sentiment-analyze-btn {
                background: #1877f2;
                color: white;
                padding: 8px 16px;
                border-radius: 6px;
                border: none;
                font-weight: 500;
                cursor: pointer;
                transition: background 0.2s;
            }

            .sentiment-analyze-btn:hover {
                background: #166fe5;
            }

            .sentiment-analyze-btn:disabled {
                background: #8ab4f8;
                cursor: not-allowed;
            }

            .sentiment-result {
                margin: 8px 0;
                padding: 12px 16px;
                border-radius: 8px;
                font-size: 13px;
                line-height: 1.5;
                font-family: -apple-system, BlinkMacSystemFont, Segoe UI, Helvetica, Arial, sans-serif;
                box-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
                transition: all 0.2s ease;
            }

            .sentiment-result strong {
                font-weight: 600;
                color: #050505;
            }

            .sentiment-result .emoji {
                font-size: 16px;
                margin-right: 6px;
                vertical-align: -2px;
            }

            .sentiment-positive {
                background-color: #e7f3e8;
                border: 1px solid rgba(35, 134, 54, 0.15);
                color: #1d4121;
            }

            .sentiment-negative {
                background-color: #ffebe9;
                border: 1px solid rgba(255, 129, 130, 0.15);
                color: #67060c;
            }

            .sentiment-neutral {
                background-color: #f0f2f5;
                border: 1px solid rgba(0, 0, 0, 0.08);
                color: #050505;
            }

            .sentiment-result:hover {
                box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
                transform: translateY(-1px);
            }

            .sentiment-confidence {
                display: inline-block;
                margin-top: 4px;
                padding: 2px 6px;
                border-radius: 4px;
                font-size: 12px;
                font-weight: 500;
                background: rgba(0, 0, 0, 0.05);
                color: inherit;
            }

            .sentiment-loading {
                display: flex;
                justify-content: center;
                margin: 8px 0;
            }

            .spinner {
                width: 20px;
                height: 20px;
                border: 3px solid #f3f3f3;
                border-top: 3px solid #1877f2;
                border-radius: 50%;
                animation: spin 1s linear infinite;
            }

            .sentiment-error {
                position: fixed;
                bottom: 20px;
                right: 20px;
                background: #fce8e6;
                color: #ea4335;
                padding: 12px 20px;
                border-radius: 8px;
                box-shadow: 0 2px 8px rgba(0,0,0,0.15);
                z-index: 9999;
            }

            @keyframes spin {
                0% { transform: rotate(0deg); }
                100% { transform: rotate(360deg); }
            }
        `;
        document.head.appendChild(styleSheet);
    }

    // Create a set to track processed comments
    const processedComments = new Set();

    // Listen for new comments from background script
    chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
        if (message.type === "NEW_COMMENTS") {
            message.comments.forEach(comment => {
                // Create unique ID for comment to avoid duplicates
                const commentId = `${comment.author}-${comment.text}-${comment.time}`;

                if (!processedComments.has(commentId)) {
                    processedComments.add(commentId);

                    // Send to API for sentiment analysis
                    analyzeSentiment(comment.text)
                        .then(sentiment => {
                            // Add sentiment result to comment
                            displaySentimentResult(sentiment, comment);
                        })
                        .catch(err => console.error('Error analyzing comment:', err));
                }
            });
        }
    });

    function displaySentimentResult(sentiment, comment) {
        // Find the comment element again using author and text
        const commentElements = document.querySelectorAll('[role="article"][tabindex="-1"]');

        for (const element of commentElements) {
            const textElement = element.querySelector('div[dir="auto"][style="text-align: start"]');
            if (textElement && textElement.textContent.includes(comment.text)) {
                // Create sentiment display element
                const sentimentDiv = document.createElement('div');
                sentimentDiv.className = `sentiment-result sentiment-${sentiment.label.toLowerCase()}`;
                sentimentDiv.innerHTML = `
                    <div style="margin: 4px 0">
                        <span class="emoji">${getSentimentEmoji(sentiment.label)}</span>
                        <strong>${sentiment.label}</strong>
                        - ${sentiment.explanation}
                    </div>
                    <span class="sentiment-confidence">
                        Độ tin cậy: ${(sentiment.score * 100).toFixed(1)}%
                    </span>
                `;

                // Insert after comment text
                textElement.appendChild(sentimentDiv);
                break;
            }
        }
    }
}

================
File: extension/manifest.json
================
{
  "manifest_version": 3,
  "name": "Facebook Sentiment Analyzer",
  "version": "1.0",
  "description": "Analyzes sentiment in Facebook posts and comments using sentiment analysis API",
  "permissions": ["storage", "activeTab", "scripting", "tabs"],
  "host_permissions": [
    "http://localhost:7270/*",
    "http://127.0.0.1:7270/*",
    "http://workspace.tamais.me:7270/*",
    "https://workspace.tamais.me:7270/*",
    "http://*/*",
    "https://*/*"
  ],
  "icons": {
    "16": "icons/icon16.png",
    "48": "icons/icon48.png",
    "128": "icons/icon128.png"
  },
  "action": {
    "default_popup": "popup.html",
    "default_icon": {
      "16": "icons/icon16.png",
      "48": "icons/icon48.png",
      "128": "icons/icon128.png"
    }
  },
  "content_security_policy": {
    "extension_pages": "script-src 'self'; object-src 'self'"
  },
  "content_scripts": [
    {
      "matches": ["https://*.facebook.com/*"],
      "css": ["style.css"],
      "js": ["content.js"],
      "run_at": "document_idle",
      "all_frames": false
    }
  ],
  "web_accessible_resources": [
    {
      "resources": ["popup.css"],
      "matches": ["https://*.facebook.com/*"]
    }
  ],
  "background": {
    "service_worker": "background.js",
    "type": "module"
  }
}

================
File: extension/package.json
================
{
  "scripts": {
    "build": "tailwindcss -i ./src/input.css -o ./popup.css --watch"
  },
  "devDependencies": {
    "tailwindcss": "^3.3.0"
  }
}

================
File: extension/popup.css
================
*, ::before, ::after {
  --tw-border-spacing-x: 0;
  --tw-border-spacing-y: 0;
  --tw-translate-x: 0;
  --tw-translate-y: 0;
  --tw-rotate: 0;
  --tw-skew-x: 0;
  --tw-skew-y: 0;
  --tw-scale-x: 1;
  --tw-scale-y: 1;
  --tw-pan-x:  ;
  --tw-pan-y:  ;
  --tw-pinch-zoom:  ;
  --tw-scroll-snap-strictness: proximity;
  --tw-gradient-from-position:  ;
  --tw-gradient-via-position:  ;
  --tw-gradient-to-position:  ;
  --tw-ordinal:  ;
  --tw-slashed-zero:  ;
  --tw-numeric-figure:  ;
  --tw-numeric-spacing:  ;
  --tw-numeric-fraction:  ;
  --tw-ring-inset:  ;
  --tw-ring-offset-width: 0px;
  --tw-ring-offset-color: #fff;
  --tw-ring-color: rgb(59 130 246 / 0.5);
  --tw-ring-offset-shadow: 0 0 #0000;
  --tw-ring-shadow: 0 0 #0000;
  --tw-shadow: 0 0 #0000;
  --tw-shadow-colored: 0 0 #0000;
  --tw-blur:  ;
  --tw-brightness:  ;
  --tw-contrast:  ;
  --tw-grayscale:  ;
  --tw-hue-rotate:  ;
  --tw-invert:  ;
  --tw-saturate:  ;
  --tw-sepia:  ;
  --tw-drop-shadow:  ;
  --tw-backdrop-blur:  ;
  --tw-backdrop-brightness:  ;
  --tw-backdrop-contrast:  ;
  --tw-backdrop-grayscale:  ;
  --tw-backdrop-hue-rotate:  ;
  --tw-backdrop-invert:  ;
  --tw-backdrop-opacity:  ;
  --tw-backdrop-saturate:  ;
  --tw-backdrop-sepia:  ;
  --tw-contain-size:  ;
  --tw-contain-layout:  ;
  --tw-contain-paint:  ;
  --tw-contain-style:  ;
}

::backdrop {
  --tw-border-spacing-x: 0;
  --tw-border-spacing-y: 0;
  --tw-translate-x: 0;
  --tw-translate-y: 0;
  --tw-rotate: 0;
  --tw-skew-x: 0;
  --tw-skew-y: 0;
  --tw-scale-x: 1;
  --tw-scale-y: 1;
  --tw-pan-x:  ;
  --tw-pan-y:  ;
  --tw-pinch-zoom:  ;
  --tw-scroll-snap-strictness: proximity;
  --tw-gradient-from-position:  ;
  --tw-gradient-via-position:  ;
  --tw-gradient-to-position:  ;
  --tw-ordinal:  ;
  --tw-slashed-zero:  ;
  --tw-numeric-figure:  ;
  --tw-numeric-spacing:  ;
  --tw-numeric-fraction:  ;
  --tw-ring-inset:  ;
  --tw-ring-offset-width: 0px;
  --tw-ring-offset-color: #fff;
  --tw-ring-color: rgb(59 130 246 / 0.5);
  --tw-ring-offset-shadow: 0 0 #0000;
  --tw-ring-shadow: 0 0 #0000;
  --tw-shadow: 0 0 #0000;
  --tw-shadow-colored: 0 0 #0000;
  --tw-blur:  ;
  --tw-brightness:  ;
  --tw-contrast:  ;
  --tw-grayscale:  ;
  --tw-hue-rotate:  ;
  --tw-invert:  ;
  --tw-saturate:  ;
  --tw-sepia:  ;
  --tw-drop-shadow:  ;
  --tw-backdrop-blur:  ;
  --tw-backdrop-brightness:  ;
  --tw-backdrop-contrast:  ;
  --tw-backdrop-grayscale:  ;
  --tw-backdrop-hue-rotate:  ;
  --tw-backdrop-invert:  ;
  --tw-backdrop-opacity:  ;
  --tw-backdrop-saturate:  ;
  --tw-backdrop-sepia:  ;
  --tw-contain-size:  ;
  --tw-contain-layout:  ;
  --tw-contain-paint:  ;
  --tw-contain-style:  ;
}

/*
! tailwindcss v3.4.15 | MIT License | https://tailwindcss.com
*/

/*
1. Prevent padding and border from affecting element width. (https://github.com/mozdevs/cssremedy/issues/4)
2. Allow adding a border to an element by just adding a border-width. (https://github.com/tailwindcss/tailwindcss/pull/116)
*/

*,
::before,
::after {
  box-sizing: border-box;
  /* 1 */
  border-width: 0;
  /* 2 */
  border-style: solid;
  /* 2 */
  border-color: #e5e7eb;
  /* 2 */
}

::before,
::after {
  --tw-content: '';
}

/*
1. Use a consistent sensible line-height in all browsers.
2. Prevent adjustments of font size after orientation changes in iOS.
3. Use a more readable tab size.
4. Use the user's configured `sans` font-family by default.
5. Use the user's configured `sans` font-feature-settings by default.
6. Use the user's configured `sans` font-variation-settings by default.
7. Disable tap highlights on iOS
*/

html,
:host {
  line-height: 1.5;
  /* 1 */
  -webkit-text-size-adjust: 100%;
  /* 2 */
  -moz-tab-size: 4;
  /* 3 */
  -o-tab-size: 4;
     tab-size: 4;
  /* 3 */
  font-family: ui-sans-serif, system-ui, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol", "Noto Color Emoji";
  /* 4 */
  font-feature-settings: normal;
  /* 5 */
  font-variation-settings: normal;
  /* 6 */
  -webkit-tap-highlight-color: transparent;
  /* 7 */
}

/*
1. Remove the margin in all browsers.
2. Inherit line-height from `html` so users can set them as a class directly on the `html` element.
*/

body {
  margin: 0;
  /* 1 */
  line-height: inherit;
  /* 2 */
}

/*
1. Add the correct height in Firefox.
2. Correct the inheritance of border color in Firefox. (https://bugzilla.mozilla.org/show_bug.cgi?id=190655)
3. Ensure horizontal rules are visible by default.
*/

hr {
  height: 0;
  /* 1 */
  color: inherit;
  /* 2 */
  border-top-width: 1px;
  /* 3 */
}

/*
Add the correct text decoration in Chrome, Edge, and Safari.
*/

abbr:where([title]) {
  -webkit-text-decoration: underline dotted;
          text-decoration: underline dotted;
}

/*
Remove the default font size and weight for headings.
*/

h1,
h2,
h3,
h4,
h5,
h6 {
  font-size: inherit;
  font-weight: inherit;
}

/*
Reset links to optimize for opt-in styling instead of opt-out.
*/

a {
  color: inherit;
  text-decoration: inherit;
}

/*
Add the correct font weight in Edge and Safari.
*/

b,
strong {
  font-weight: bolder;
}

/*
1. Use the user's configured `mono` font-family by default.
2. Use the user's configured `mono` font-feature-settings by default.
3. Use the user's configured `mono` font-variation-settings by default.
4. Correct the odd `em` font sizing in all browsers.
*/

code,
kbd,
samp,
pre {
  font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  /* 1 */
  font-feature-settings: normal;
  /* 2 */
  font-variation-settings: normal;
  /* 3 */
  font-size: 1em;
  /* 4 */
}

/*
Add the correct font size in all browsers.
*/

small {
  font-size: 80%;
}

/*
Prevent `sub` and `sup` elements from affecting the line height in all browsers.
*/

sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}

sub {
  bottom: -0.25em;
}

sup {
  top: -0.5em;
}

/*
1. Remove text indentation from table contents in Chrome and Safari. (https://bugs.chromium.org/p/chromium/issues/detail?id=999088, https://bugs.webkit.org/show_bug.cgi?id=201297)
2. Correct table border color inheritance in all Chrome and Safari. (https://bugs.chromium.org/p/chromium/issues/detail?id=935729, https://bugs.webkit.org/show_bug.cgi?id=195016)
3. Remove gaps between table borders by default.
*/

table {
  text-indent: 0;
  /* 1 */
  border-color: inherit;
  /* 2 */
  border-collapse: collapse;
  /* 3 */
}

/*
1. Change the font styles in all browsers.
2. Remove the margin in Firefox and Safari.
3. Remove default padding in all browsers.
*/

button,
input,
optgroup,
select,
textarea {
  font-family: inherit;
  /* 1 */
  font-feature-settings: inherit;
  /* 1 */
  font-variation-settings: inherit;
  /* 1 */
  font-size: 100%;
  /* 1 */
  font-weight: inherit;
  /* 1 */
  line-height: inherit;
  /* 1 */
  letter-spacing: inherit;
  /* 1 */
  color: inherit;
  /* 1 */
  margin: 0;
  /* 2 */
  padding: 0;
  /* 3 */
}

/*
Remove the inheritance of text transform in Edge and Firefox.
*/

button,
select {
  text-transform: none;
}

/*
1. Correct the inability to style clickable types in iOS and Safari.
2. Remove default button styles.
*/

button,
input:where([type='button']),
input:where([type='reset']),
input:where([type='submit']) {
  -webkit-appearance: button;
  /* 1 */
  background-color: transparent;
  /* 2 */
  background-image: none;
  /* 2 */
}

/*
Use the modern Firefox focus style for all focusable elements.
*/

:-moz-focusring {
  outline: auto;
}

/*
Remove the additional `:invalid` styles in Firefox. (https://github.com/mozilla/gecko-dev/blob/2f9eacd9d3d995c937b4251a5557d95d494c9be1/layout/style/res/forms.css#L728-L737)
*/

:-moz-ui-invalid {
  box-shadow: none;
}

/*
Add the correct vertical alignment in Chrome and Firefox.
*/

progress {
  vertical-align: baseline;
}

/*
Correct the cursor style of increment and decrement buttons in Safari.
*/

::-webkit-inner-spin-button,
::-webkit-outer-spin-button {
  height: auto;
}

/*
1. Correct the odd appearance in Chrome and Safari.
2. Correct the outline style in Safari.
*/

[type='search'] {
  -webkit-appearance: textfield;
  /* 1 */
  outline-offset: -2px;
  /* 2 */
}

/*
Remove the inner padding in Chrome and Safari on macOS.
*/

::-webkit-search-decoration {
  -webkit-appearance: none;
}

/*
1. Correct the inability to style clickable types in iOS and Safari.
2. Change font properties to `inherit` in Safari.
*/

::-webkit-file-upload-button {
  -webkit-appearance: button;
  /* 1 */
  font: inherit;
  /* 2 */
}

/*
Add the correct display in Chrome and Safari.
*/

summary {
  display: list-item;
}

/*
Removes the default spacing and border for appropriate elements.
*/

blockquote,
dl,
dd,
h1,
h2,
h3,
h4,
h5,
h6,
hr,
figure,
p,
pre {
  margin: 0;
}

fieldset {
  margin: 0;
  padding: 0;
}

legend {
  padding: 0;
}

ol,
ul,
menu {
  list-style: none;
  margin: 0;
  padding: 0;
}

/*
Reset default styling for dialogs.
*/

dialog {
  padding: 0;
}

/*
Prevent resizing textareas horizontally by default.
*/

textarea {
  resize: vertical;
}

/*
1. Reset the default placeholder opacity in Firefox. (https://github.com/tailwindlabs/tailwindcss/issues/3300)
2. Set the default placeholder color to the user's configured gray 400 color.
*/

input::-moz-placeholder, textarea::-moz-placeholder {
  opacity: 1;
  /* 1 */
  color: #9ca3af;
  /* 2 */
}

input::placeholder,
textarea::placeholder {
  opacity: 1;
  /* 1 */
  color: #9ca3af;
  /* 2 */
}

/*
Set the default cursor for buttons.
*/

button,
[role="button"] {
  cursor: pointer;
}

/*
Make sure disabled buttons don't get the pointer cursor.
*/

:disabled {
  cursor: default;
}

/*
1. Make replaced elements `display: block` by default. (https://github.com/mozdevs/cssremedy/issues/14)
2. Add `vertical-align: middle` to align replaced elements more sensibly by default. (https://github.com/jensimmons/cssremedy/issues/14#issuecomment-634934210)
   This can trigger a poorly considered lint error in some tools but is included by design.
*/

img,
svg,
video,
canvas,
audio,
iframe,
embed,
object {
  display: block;
  /* 1 */
  vertical-align: middle;
  /* 2 */
}

/*
Constrain images and videos to the parent width and preserve their intrinsic aspect ratio. (https://github.com/mozdevs/cssremedy/issues/14)
*/

img,
video {
  max-width: 100%;
  height: auto;
}

/* Make elements with the HTML hidden attribute stay hidden by default */

[hidden]:where(:not([hidden="until-found"])) {
  display: none;
}

.container {
  width: 100%;
}

@media (min-width: 640px) {
  .container {
    max-width: 640px;
  }
}

@media (min-width: 768px) {
  .container {
    max-width: 768px;
  }
}

@media (min-width: 1024px) {
  .container {
    max-width: 1024px;
  }
}

@media (min-width: 1280px) {
  .container {
    max-width: 1280px;
  }
}

@media (min-width: 1536px) {
  .container {
    max-width: 1536px;
  }
}

.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border-width: 0;
}

.not-sr-only {
  position: static;
  width: auto;
  height: auto;
  padding: 0;
  margin: 0;
  overflow: visible;
  clip: auto;
  white-space: normal;
}

.pointer-events-none {
  pointer-events: none;
}

.pointer-events-auto {
  pointer-events: auto;
}

.\!visible {
  visibility: visible !important;
}

.visible {
  visibility: visible;
}

.invisible {
  visibility: hidden;
}

.collapse {
  visibility: collapse;
}

.static {
  position: static;
}

.fixed {
  position: fixed;
}

.absolute {
  position: absolute;
}

.relative {
  position: relative;
}

.sticky {
  position: sticky;
}

.-inset-1 {
  inset: -0.25rem;
}

.end-1 {
  inset-inline-end: 0.25rem;
}

.isolate {
  isolation: isolate;
}

.isolation-auto {
  isolation: auto;
}

.float-start {
  float: inline-start;
}

.float-end {
  float: inline-end;
}

.float-right {
  float: right;
}

.float-left {
  float: left;
}

.float-none {
  float: none;
}

.clear-start {
  clear: inline-start;
}

.clear-end {
  clear: inline-end;
}

.clear-left {
  clear: left;
}

.clear-right {
  clear: right;
}

.clear-both {
  clear: both;
}

.clear-none {
  clear: none;
}

.-mx-5 {
  margin-left: -1.25rem;
  margin-right: -1.25rem;
}

.-mt-5 {
  margin-top: -1.25rem;
}

.mb-1 {
  margin-bottom: 0.25rem;
}

.mb-2 {
  margin-bottom: 0.5rem;
}

.mb-6 {
  margin-bottom: 1.5rem;
}

.mt-1 {
  margin-top: 0.25rem;
}

.mt-2 {
  margin-top: 0.5rem;
}

.box-border {
  box-sizing: border-box;
}

.box-content {
  box-sizing: content-box;
}

.line-clamp-none {
  overflow: visible;
  display: block;
  -webkit-box-orient: horizontal;
  -webkit-line-clamp: none;
}

.block {
  display: block;
}

.inline-block {
  display: inline-block;
}

.inline {
  display: inline;
}

.flex {
  display: flex;
}

.inline-flex {
  display: inline-flex;
}

.table {
  display: table;
}

.inline-table {
  display: inline-table;
}

.table-caption {
  display: table-caption;
}

.table-cell {
  display: table-cell;
}

.table-column {
  display: table-column;
}

.table-column-group {
  display: table-column-group;
}

.table-footer-group {
  display: table-footer-group;
}

.table-header-group {
  display: table-header-group;
}

.table-row-group {
  display: table-row-group;
}

.table-row {
  display: table-row;
}

.flow-root {
  display: flow-root;
}

.grid {
  display: grid;
}

.inline-grid {
  display: inline-grid;
}

.contents {
  display: contents;
}

.list-item {
  display: list-item;
}

.hidden {
  display: none;
}

.h-10 {
  height: 2.5rem;
}

.h-3 {
  height: 0.75rem;
}

.h-4 {
  height: 1rem;
}

.h-5 {
  height: 1.25rem;
}

.w-10 {
  width: 2.5rem;
}

.w-3 {
  width: 0.75rem;
}

.w-4 {
  width: 1rem;
}

.w-5 {
  width: 1.25rem;
}

.w-\[380px\] {
  width: 380px;
}

.w-\[this-is\\\\\] {
  width: this-is\\;
}

.w-\[this-is\] {
  width: this-is;
}

.w-\[weird-and-invalid\] {
  width: weird-and-invalid;
}

.flex-shrink {
  flex-shrink: 1;
}

.shrink {
  flex-shrink: 1;
}

.flex-grow {
  flex-grow: 1;
}

.grow {
  flex-grow: 1;
}

.table-auto {
  table-layout: auto;
}

.table-fixed {
  table-layout: fixed;
}

.caption-top {
  caption-side: top;
}

.caption-bottom {
  caption-side: bottom;
}

.border-collapse {
  border-collapse: collapse;
}

.border-separate {
  border-collapse: separate;
}

.\!transform {
  transform: translate(var(--tw-translate-x), var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y)) !important;
}

.transform {
  transform: translate(var(--tw-translate-x), var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));
}

.transform-cpu {
  transform: translate(var(--tw-translate-x), var(--tw-translate-y)) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));
}

.transform-gpu {
  transform: translate3d(var(--tw-translate-x), var(--tw-translate-y), 0) rotate(var(--tw-rotate)) skewX(var(--tw-skew-x)) skewY(var(--tw-skew-y)) scaleX(var(--tw-scale-x)) scaleY(var(--tw-scale-y));
}

.transform-none {
  transform: none;
}

.touch-auto {
  touch-action: auto;
}

.touch-none {
  touch-action: none;
}

.touch-pan-x {
  --tw-pan-x: pan-x;
  touch-action: var(--tw-pan-x) var(--tw-pan-y) var(--tw-pinch-zoom);
}

.touch-pan-left {
  --tw-pan-x: pan-left;
  touch-action: var(--tw-pan-x) var(--tw-pan-y) var(--tw-pinch-zoom);
}

.touch-pan-right {
  --tw-pan-x: pan-right;
  touch-action: var(--tw-pan-x) var(--tw-pan-y) var(--tw-pinch-zoom);
}

.touch-pan-y {
  --tw-pan-y: pan-y;
  touch-action: var(--tw-pan-x) var(--tw-pan-y) var(--tw-pinch-zoom);
}

.touch-pan-up {
  --tw-pan-y: pan-up;
  touch-action: var(--tw-pan-x) var(--tw-pan-y) var(--tw-pinch-zoom);
}

.touch-pan-down {
  --tw-pan-y: pan-down;
  touch-action: var(--tw-pan-x) var(--tw-pan-y) var(--tw-pinch-zoom);
}

.touch-pinch-zoom {
  --tw-pinch-zoom: pinch-zoom;
  touch-action: var(--tw-pan-x) var(--tw-pan-y) var(--tw-pinch-zoom);
}

.touch-manipulation {
  touch-action: manipulation;
}

.select-none {
  -webkit-user-select: none;
     -moz-user-select: none;
          user-select: none;
}

.select-text {
  -webkit-user-select: text;
     -moz-user-select: text;
          user-select: text;
}

.select-all {
  -webkit-user-select: all;
     -moz-user-select: all;
          user-select: all;
}

.select-auto {
  -webkit-user-select: auto;
     -moz-user-select: auto;
          user-select: auto;
}

.resize-none {
  resize: none;
}

.resize-y {
  resize: vertical;
}

.resize-x {
  resize: horizontal;
}

.resize {
  resize: both;
}

.snap-none {
  scroll-snap-type: none;
}

.snap-x {
  scroll-snap-type: x var(--tw-scroll-snap-strictness);
}

.snap-y {
  scroll-snap-type: y var(--tw-scroll-snap-strictness);
}

.snap-both {
  scroll-snap-type: both var(--tw-scroll-snap-strictness);
}

.snap-mandatory {
  --tw-scroll-snap-strictness: mandatory;
}

.snap-proximity {
  --tw-scroll-snap-strictness: proximity;
}

.snap-start {
  scroll-snap-align: start;
}

.snap-end {
  scroll-snap-align: end;
}

.snap-center {
  scroll-snap-align: center;
}

.snap-align-none {
  scroll-snap-align: none;
}

.snap-normal {
  scroll-snap-stop: normal;
}

.snap-always {
  scroll-snap-stop: always;
}

.list-inside {
  list-style-position: inside;
}

.list-outside {
  list-style-position: outside;
}

.appearance-none {
  -webkit-appearance: none;
     -moz-appearance: none;
          appearance: none;
}

.appearance-auto {
  -webkit-appearance: auto;
     -moz-appearance: auto;
          appearance: auto;
}

.break-before-auto {
  -moz-column-break-before: auto;
       break-before: auto;
}

.break-before-avoid {
  -moz-column-break-before: avoid;
       break-before: avoid;
}

.break-before-all {
  -moz-column-break-before: all;
       break-before: all;
}

.break-before-avoid-page {
  -moz-column-break-before: avoid;
       break-before: avoid-page;
}

.break-before-page {
  -moz-column-break-before: page;
       break-before: page;
}

.break-before-left {
  -moz-column-break-before: left;
       break-before: left;
}

.break-before-right {
  -moz-column-break-before: right;
       break-before: right;
}

.break-before-column {
  -moz-column-break-before: column;
       break-before: column;
}

.break-inside-auto {
  -moz-column-break-inside: auto;
       break-inside: auto;
}

.break-inside-avoid {
  -moz-column-break-inside: avoid;
       break-inside: avoid;
}

.break-inside-avoid-page {
  break-inside: avoid-page;
}

.break-inside-avoid-column {
  -moz-column-break-inside: avoid;
       break-inside: avoid-column;
}

.break-after-auto {
  -moz-column-break-after: auto;
       break-after: auto;
}

.break-after-avoid {
  -moz-column-break-after: avoid;
       break-after: avoid;
}

.break-after-all {
  -moz-column-break-after: all;
       break-after: all;
}

.break-after-avoid-page {
  -moz-column-break-after: avoid;
       break-after: avoid-page;
}

.break-after-page {
  -moz-column-break-after: page;
       break-after: page;
}

.break-after-left {
  -moz-column-break-after: left;
       break-after: left;
}

.break-after-right {
  -moz-column-break-after: right;
       break-after: right;
}

.break-after-column {
  -moz-column-break-after: column;
       break-after: column;
}

.grid-flow-row {
  grid-auto-flow: row;
}

.grid-flow-col {
  grid-auto-flow: column;
}

.grid-flow-dense {
  grid-auto-flow: dense;
}

.grid-flow-row-dense {
  grid-auto-flow: row dense;
}

.grid-flow-col-dense {
  grid-auto-flow: column dense;
}

.grid-cols-2 {
  grid-template-columns: repeat(2, minmax(0, 1fr));
}

.flex-row {
  flex-direction: row;
}

.flex-row-reverse {
  flex-direction: row-reverse;
}

.flex-col {
  flex-direction: column;
}

.flex-col-reverse {
  flex-direction: column-reverse;
}

.flex-wrap {
  flex-wrap: wrap;
}

.flex-wrap-reverse {
  flex-wrap: wrap-reverse;
}

.flex-nowrap {
  flex-wrap: nowrap;
}

.place-content-center {
  place-content: center;
}

.place-content-start {
  place-content: start;
}

.place-content-end {
  place-content: end;
}

.place-content-between {
  place-content: space-between;
}

.place-content-around {
  place-content: space-around;
}

.place-content-evenly {
  place-content: space-evenly;
}

.place-content-baseline {
  place-content: baseline;
}

.place-content-stretch {
  place-content: stretch;
}

.place-items-start {
  place-items: start;
}

.place-items-end {
  place-items: end;
}

.place-items-center {
  place-items: center;
}

.place-items-baseline {
  place-items: baseline;
}

.place-items-stretch {
  place-items: stretch;
}

.content-normal {
  align-content: normal;
}

.content-center {
  align-content: center;
}

.content-start {
  align-content: flex-start;
}

.content-end {
  align-content: flex-end;
}

.content-between {
  align-content: space-between;
}

.content-around {
  align-content: space-around;
}

.content-evenly {
  align-content: space-evenly;
}

.content-baseline {
  align-content: baseline;
}

.content-stretch {
  align-content: stretch;
}

.items-start {
  align-items: flex-start;
}

.items-end {
  align-items: flex-end;
}

.items-center {
  align-items: center;
}

.items-baseline {
  align-items: baseline;
}

.items-stretch {
  align-items: stretch;
}

.justify-normal {
  justify-content: normal;
}

.justify-start {
  justify-content: flex-start;
}

.justify-end {
  justify-content: flex-end;
}

.justify-center {
  justify-content: center;
}

.justify-between {
  justify-content: space-between;
}

.justify-around {
  justify-content: space-around;
}

.justify-evenly {
  justify-content: space-evenly;
}

.justify-stretch {
  justify-content: stretch;
}

.justify-items-start {
  justify-items: start;
}

.justify-items-end {
  justify-items: end;
}

.justify-items-center {
  justify-items: center;
}

.justify-items-stretch {
  justify-items: stretch;
}

.gap-4 {
  gap: 1rem;
}

.space-x-2 > :not([hidden]) ~ :not([hidden]) {
  --tw-space-x-reverse: 0;
  margin-right: calc(0.5rem * var(--tw-space-x-reverse));
  margin-left: calc(0.5rem * calc(1 - var(--tw-space-x-reverse)));
}

.space-y-4 > :not([hidden]) ~ :not([hidden]) {
  --tw-space-y-reverse: 0;
  margin-top: calc(1rem * calc(1 - var(--tw-space-y-reverse)));
  margin-bottom: calc(1rem * var(--tw-space-y-reverse));
}

.space-y-reverse > :not([hidden]) ~ :not([hidden]) {
  --tw-space-y-reverse: 1;
}

.space-x-reverse > :not([hidden]) ~ :not([hidden]) {
  --tw-space-x-reverse: 1;
}

.divide-x > :not([hidden]) ~ :not([hidden]) {
  --tw-divide-x-reverse: 0;
  border-right-width: calc(1px * var(--tw-divide-x-reverse));
  border-left-width: calc(1px * calc(1 - var(--tw-divide-x-reverse)));
}

.divide-y > :not([hidden]) ~ :not([hidden]) {
  --tw-divide-y-reverse: 0;
  border-top-width: calc(1px * calc(1 - var(--tw-divide-y-reverse)));
  border-bottom-width: calc(1px * var(--tw-divide-y-reverse));
}

.divide-y-reverse > :not([hidden]) ~ :not([hidden]) {
  --tw-divide-y-reverse: 1;
}

.divide-x-reverse > :not([hidden]) ~ :not([hidden]) {
  --tw-divide-x-reverse: 1;
}

.divide-solid > :not([hidden]) ~ :not([hidden]) {
  border-style: solid;
}

.divide-dashed > :not([hidden]) ~ :not([hidden]) {
  border-style: dashed;
}

.divide-dotted > :not([hidden]) ~ :not([hidden]) {
  border-style: dotted;
}

.divide-double > :not([hidden]) ~ :not([hidden]) {
  border-style: double;
}

.divide-none > :not([hidden]) ~ :not([hidden]) {
  border-style: none;
}

.place-self-auto {
  place-self: auto;
}

.place-self-start {
  place-self: start;
}

.place-self-end {
  place-self: end;
}

.place-self-center {
  place-self: center;
}

.place-self-stretch {
  place-self: stretch;
}

.self-auto {
  align-self: auto;
}

.self-start {
  align-self: flex-start;
}

.self-end {
  align-self: flex-end;
}

.self-center {
  align-self: center;
}

.self-stretch {
  align-self: stretch;
}

.self-baseline {
  align-self: baseline;
}

.justify-self-auto {
  justify-self: auto;
}

.justify-self-start {
  justify-self: start;
}

.justify-self-end {
  justify-self: end;
}

.justify-self-center {
  justify-self: center;
}

.justify-self-stretch {
  justify-self: stretch;
}

.overflow-auto {
  overflow: auto;
}

.overflow-hidden {
  overflow: hidden;
}

.overflow-clip {
  overflow: clip;
}

.overflow-visible {
  overflow: visible;
}

.overflow-scroll {
  overflow: scroll;
}

.overflow-x-auto {
  overflow-x: auto;
}

.overflow-y-auto {
  overflow-y: auto;
}

.overflow-x-hidden {
  overflow-x: hidden;
}

.overflow-y-hidden {
  overflow-y: hidden;
}

.overflow-x-clip {
  overflow-x: clip;
}

.overflow-y-clip {
  overflow-y: clip;
}

.overflow-x-visible {
  overflow-x: visible;
}

.overflow-y-visible {
  overflow-y: visible;
}

.overflow-x-scroll {
  overflow-x: scroll;
}

.overflow-y-scroll {
  overflow-y: scroll;
}

.overscroll-auto {
  overscroll-behavior: auto;
}

.overscroll-contain {
  overscroll-behavior: contain;
}

.overscroll-none {
  overscroll-behavior: none;
}

.overscroll-y-auto {
  overscroll-behavior-y: auto;
}

.overscroll-y-contain {
  overscroll-behavior-y: contain;
}

.overscroll-y-none {
  overscroll-behavior-y: none;
}

.overscroll-x-auto {
  overscroll-behavior-x: auto;
}

.overscroll-x-contain {
  overscroll-behavior-x: contain;
}

.overscroll-x-none {
  overscroll-behavior-x: none;
}

.scroll-auto {
  scroll-behavior: auto;
}

.scroll-smooth {
  scroll-behavior: smooth;
}

.truncate {
  overflow: hidden;
  text-overflow: ellipsis;
  white-space: nowrap;
}

.overflow-ellipsis {
  text-overflow: ellipsis;
}

.text-ellipsis {
  text-overflow: ellipsis;
}

.text-clip {
  text-overflow: clip;
}

.hyphens-none {
  -webkit-hyphens: none;
          hyphens: none;
}

.hyphens-manual {
  -webkit-hyphens: manual;
          hyphens: manual;
}

.hyphens-auto {
  -webkit-hyphens: auto;
          hyphens: auto;
}

.whitespace-normal {
  white-space: normal;
}

.whitespace-nowrap {
  white-space: nowrap;
}

.whitespace-pre {
  white-space: pre;
}

.whitespace-pre-line {
  white-space: pre-line;
}

.whitespace-pre-wrap {
  white-space: pre-wrap;
}

.whitespace-break-spaces {
  white-space: break-spaces;
}

.text-wrap {
  text-wrap: wrap;
}

.text-nowrap {
  text-wrap: nowrap;
}

.text-balance {
  text-wrap: balance;
}

.text-pretty {
  text-wrap: pretty;
}

.break-normal {
  overflow-wrap: normal;
  word-break: normal;
}

.break-words {
  overflow-wrap: break-word;
}

.break-all {
  word-break: break-all;
}

.break-keep {
  word-break: keep-all;
}

.rounded {
  border-radius: 0.25rem;
}

.rounded-full {
  border-radius: 9999px;
}

.rounded-xl {
  border-radius: 0.75rem;
}

.rounded-b {
  border-bottom-right-radius: 0.25rem;
  border-bottom-left-radius: 0.25rem;
}

.rounded-e {
  border-start-end-radius: 0.25rem;
  border-end-end-radius: 0.25rem;
}

.rounded-l {
  border-top-left-radius: 0.25rem;
  border-bottom-left-radius: 0.25rem;
}

.rounded-r {
  border-top-right-radius: 0.25rem;
  border-bottom-right-radius: 0.25rem;
}

.rounded-s {
  border-start-start-radius: 0.25rem;
  border-end-start-radius: 0.25rem;
}

.rounded-t {
  border-top-left-radius: 0.25rem;
  border-top-right-radius: 0.25rem;
}

.rounded-bl {
  border-bottom-left-radius: 0.25rem;
}

.rounded-br {
  border-bottom-right-radius: 0.25rem;
}

.rounded-ee {
  border-end-end-radius: 0.25rem;
}

.rounded-es {
  border-end-start-radius: 0.25rem;
}

.rounded-se {
  border-start-end-radius: 0.25rem;
}

.rounded-ss {
  border-start-start-radius: 0.25rem;
}

.rounded-tl {
  border-top-left-radius: 0.25rem;
}

.rounded-tr {
  border-top-right-radius: 0.25rem;
}

.border {
  border-width: 1px;
}

.border-x {
  border-left-width: 1px;
  border-right-width: 1px;
}

.border-y {
  border-top-width: 1px;
  border-bottom-width: 1px;
}

.border-b {
  border-bottom-width: 1px;
}

.border-e {
  border-inline-end-width: 1px;
}

.border-l {
  border-left-width: 1px;
}

.border-r {
  border-right-width: 1px;
}

.border-s {
  border-inline-start-width: 1px;
}

.border-t {
  border-top-width: 1px;
}

.border-solid {
  border-style: solid;
}

.border-dashed {
  border-style: dashed;
}

.border-dotted {
  border-style: dotted;
}

.border-double {
  border-style: double;
}

.border-hidden {
  border-style: hidden;
}

.border-none {
  border-style: none;
}

.border-gray-200 {
  --tw-border-opacity: 1;
  border-color: rgb(229 231 235 / var(--tw-border-opacity, 1));
}

.bg-\[rgb\(255\2c 0\2c 0\)\] {
  --tw-bg-opacity: 1;
  background-color: rgb(255 0 0 / var(--tw-bg-opacity, 1));
}

.bg-blue-50 {
  --tw-bg-opacity: 1;
  background-color: rgb(239 246 255 / var(--tw-bg-opacity, 1));
}

.bg-gray-50 {
  --tw-bg-opacity: 1;
  background-color: rgb(249 250 251 / var(--tw-bg-opacity, 1));
}

.bg-white {
  --tw-bg-opacity: 1;
  background-color: rgb(255 255 255 / var(--tw-bg-opacity, 1));
}

.bg-white\/10 {
  background-color: rgb(255 255 255 / 0.1);
}

.bg-gradient-to-r {
  background-image: linear-gradient(to right, var(--tw-gradient-stops));
}

.from-blue-600 {
  --tw-gradient-from: #2563eb var(--tw-gradient-from-position);
  --tw-gradient-to: rgb(37 99 235 / 0) var(--tw-gradient-to-position);
  --tw-gradient-stops: var(--tw-gradient-from), var(--tw-gradient-to);
}

.to-blue-700 {
  --tw-gradient-to: #1d4ed8 var(--tw-gradient-to-position);
}

.decoration-slice {
  -webkit-box-decoration-break: slice;
          box-decoration-break: slice;
}

.decoration-clone {
  -webkit-box-decoration-break: clone;
          box-decoration-break: clone;
}

.box-decoration-slice {
  -webkit-box-decoration-break: slice;
          box-decoration-break: slice;
}

.box-decoration-clone {
  -webkit-box-decoration-break: clone;
          box-decoration-break: clone;
}

.bg-fixed {
  background-attachment: fixed;
}

.bg-local {
  background-attachment: local;
}

.bg-scroll {
  background-attachment: scroll;
}

.bg-clip-border {
  background-clip: border-box;
}

.bg-clip-padding {
  background-clip: padding-box;
}

.bg-clip-content {
  background-clip: content-box;
}

.bg-clip-text {
  -webkit-background-clip: text;
          background-clip: text;
}

.bg-repeat {
  background-repeat: repeat;
}

.bg-no-repeat {
  background-repeat: no-repeat;
}

.bg-repeat-x {
  background-repeat: repeat-x;
}

.bg-repeat-y {
  background-repeat: repeat-y;
}

.bg-repeat-round {
  background-repeat: round;
}

.bg-repeat-space {
  background-repeat: space;
}

.bg-origin-border {
  background-origin: border-box;
}

.bg-origin-padding {
  background-origin: padding-box;
}

.bg-origin-content {
  background-origin: content-box;
}

.object-contain {
  -o-object-fit: contain;
     object-fit: contain;
}

.object-cover {
  -o-object-fit: cover;
     object-fit: cover;
}

.object-fill {
  -o-object-fit: fill;
     object-fit: fill;
}

.object-none {
  -o-object-fit: none;
     object-fit: none;
}

.object-scale-down {
  -o-object-fit: scale-down;
     object-fit: scale-down;
}

.p-4 {
  padding: 1rem;
}

.p-5 {
  padding: 1.25rem;
}

.px-1 {
  padding-left: 0.25rem;
  padding-right: 0.25rem;
}

.px-1\.5 {
  padding-left: 0.375rem;
  padding-right: 0.375rem;
}

.px-2 {
  padding-left: 0.5rem;
  padding-right: 0.5rem;
}

.px-5 {
  padding-left: 1.25rem;
  padding-right: 1.25rem;
}

.py-1 {
  padding-top: 0.25rem;
  padding-bottom: 0.25rem;
}

.pb-5 {
  padding-bottom: 1.25rem;
}

.pt-8 {
  padding-top: 2rem;
}

.text-left {
  text-align: left;
}

.text-center {
  text-align: center;
}

.text-right {
  text-align: right;
}

.text-justify {
  text-align: justify;
}

.text-start {
  text-align: start;
}

.text-end {
  text-align: end;
}

.align-baseline {
  vertical-align: baseline;
}

.align-top {
  vertical-align: top;
}

.align-middle {
  vertical-align: middle;
}

.align-bottom {
  vertical-align: bottom;
}

.align-text-top {
  vertical-align: text-top;
}

.align-text-bottom {
  vertical-align: text-bottom;
}

.align-sub {
  vertical-align: sub;
}

.align-super {
  vertical-align: super;
}

.font-\[Inter\] {
  font-family: Inter;
}

.text-2xl {
  font-size: 1.5rem;
  line-height: 2rem;
}

.text-sm {
  font-size: 0.875rem;
  line-height: 1.25rem;
}

.text-xl {
  font-size: 1.25rem;
  line-height: 1.75rem;
}

.text-xs {
  font-size: 0.75rem;
  line-height: 1rem;
}

.font-bold {
  font-weight: 700;
}

.font-medium {
  font-weight: 500;
}

.font-semibold {
  font-weight: 600;
}

.uppercase {
  text-transform: uppercase;
}

.lowercase {
  text-transform: lowercase;
}

.capitalize {
  text-transform: capitalize;
}

.normal-case {
  text-transform: none;
}

.italic {
  font-style: italic;
}

.not-italic {
  font-style: normal;
}

.normal-nums {
  font-variant-numeric: normal;
}

.ordinal {
  --tw-ordinal: ordinal;
  font-variant-numeric: var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw-numeric-spacing) var(--tw-numeric-fraction);
}

.slashed-zero {
  --tw-slashed-zero: slashed-zero;
  font-variant-numeric: var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw-numeric-spacing) var(--tw-numeric-fraction);
}

.lining-nums {
  --tw-numeric-figure: lining-nums;
  font-variant-numeric: var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw-numeric-spacing) var(--tw-numeric-fraction);
}

.oldstyle-nums {
  --tw-numeric-figure: oldstyle-nums;
  font-variant-numeric: var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw-numeric-spacing) var(--tw-numeric-fraction);
}

.proportional-nums {
  --tw-numeric-spacing: proportional-nums;
  font-variant-numeric: var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw-numeric-spacing) var(--tw-numeric-fraction);
}

.tabular-nums {
  --tw-numeric-spacing: tabular-nums;
  font-variant-numeric: var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw-numeric-spacing) var(--tw-numeric-fraction);
}

.diagonal-fractions {
  --tw-numeric-fraction: diagonal-fractions;
  font-variant-numeric: var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw-numeric-spacing) var(--tw-numeric-fraction);
}

.stacked-fractions {
  --tw-numeric-fraction: stacked-fractions;
  font-variant-numeric: var(--tw-ordinal) var(--tw-slashed-zero) var(--tw-numeric-figure) var(--tw-numeric-spacing) var(--tw-numeric-fraction);
}

.text-\[\#336699\]\/\[\.35\] {
  color: rgb(51 102 153 / .35);
}

.text-blue-100 {
  --tw-text-opacity: 1;
  color: rgb(219 234 254 / var(--tw-text-opacity, 1));
}

.text-blue-500 {
  --tw-text-opacity: 1;
  color: rgb(59 130 246 / var(--tw-text-opacity, 1));
}

.text-blue-600 {
  --tw-text-opacity: 1;
  color: rgb(37 99 235 / var(--tw-text-opacity, 1));
}

.text-gray-500 {
  --tw-text-opacity: 1;
  color: rgb(107 114 128 / var(--tw-text-opacity, 1));
}

.text-gray-900 {
  --tw-text-opacity: 1;
  color: rgb(17 24 39 / var(--tw-text-opacity, 1));
}

.text-white {
  --tw-text-opacity: 1;
  color: rgb(255 255 255 / var(--tw-text-opacity, 1));
}

.underline {
  text-decoration-line: underline;
}

.overline {
  text-decoration-line: overline;
}

.line-through {
  text-decoration-line: line-through;
}

.no-underline {
  text-decoration-line: none;
}

.decoration-solid {
  text-decoration-style: solid;
}

.decoration-double {
  text-decoration-style: double;
}

.decoration-dotted {
  text-decoration-style: dotted;
}

.decoration-dashed {
  text-decoration-style: dashed;
}

.decoration-wavy {
  text-decoration-style: wavy;
}

.antialiased {
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

.subpixel-antialiased {
  -webkit-font-smoothing: auto;
  -moz-osx-font-smoothing: auto;
}

.bg-blend-normal {
  background-blend-mode: normal;
}

.bg-blend-multiply {
  background-blend-mode: multiply;
}

.bg-blend-screen {
  background-blend-mode: screen;
}

.bg-blend-overlay {
  background-blend-mode: overlay;
}

.bg-blend-darken {
  background-blend-mode: darken;
}

.bg-blend-lighten {
  background-blend-mode: lighten;
}

.bg-blend-color-dodge {
  background-blend-mode: color-dodge;
}

.bg-blend-color-burn {
  background-blend-mode: color-burn;
}

.bg-blend-hard-light {
  background-blend-mode: hard-light;
}

.bg-blend-soft-light {
  background-blend-mode: soft-light;
}

.bg-blend-difference {
  background-blend-mode: difference;
}

.bg-blend-exclusion {
  background-blend-mode: exclusion;
}

.bg-blend-hue {
  background-blend-mode: hue;
}

.bg-blend-saturation {
  background-blend-mode: saturation;
}

.bg-blend-color {
  background-blend-mode: color;
}

.bg-blend-luminosity {
  background-blend-mode: luminosity;
}

.mix-blend-normal {
  mix-blend-mode: normal;
}

.mix-blend-multiply {
  mix-blend-mode: multiply;
}

.mix-blend-screen {
  mix-blend-mode: screen;
}

.mix-blend-overlay {
  mix-blend-mode: overlay;
}

.mix-blend-darken {
  mix-blend-mode: darken;
}

.mix-blend-lighten {
  mix-blend-mode: lighten;
}

.mix-blend-color-dodge {
  mix-blend-mode: color-dodge;
}

.mix-blend-color-burn {
  mix-blend-mode: color-burn;
}

.mix-blend-hard-light {
  mix-blend-mode: hard-light;
}

.mix-blend-soft-light {
  mix-blend-mode: soft-light;
}

.mix-blend-difference {
  mix-blend-mode: difference;
}

.mix-blend-exclusion {
  mix-blend-mode: exclusion;
}

.mix-blend-hue {
  mix-blend-mode: hue;
}

.mix-blend-saturation {
  mix-blend-mode: saturation;
}

.mix-blend-color {
  mix-blend-mode: color;
}

.mix-blend-luminosity {
  mix-blend-mode: luminosity;
}

.mix-blend-plus-darker {
  mix-blend-mode: plus-darker;
}

.mix-blend-plus-lighter {
  mix-blend-mode: plus-lighter;
}

.\!shadow {
  --tw-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1) !important;
  --tw-shadow-colored: 0 1px 3px 0 var(--tw-shadow-color), 0 1px 2px -1px var(--tw-shadow-color) !important;
  box-shadow: var(--tw-ring-offset-shadow, 0 0 #0000), var(--tw-ring-shadow, 0 0 #0000), var(--tw-shadow) !important;
}

.shadow {
  --tw-shadow: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
  --tw-shadow-colored: 0 1px 3px 0 var(--tw-shadow-color), 0 1px 2px -1px var(--tw-shadow-color);
  box-shadow: var(--tw-ring-offset-shadow, 0 0 #0000), var(--tw-ring-shadow, 0 0 #0000), var(--tw-shadow);
}

.shadow-sm {
  --tw-shadow: 0 1px 2px 0 rgb(0 0 0 / 0.05);
  --tw-shadow-colored: 0 1px 2px 0 var(--tw-shadow-color);
  box-shadow: var(--tw-ring-offset-shadow, 0 0 #0000), var(--tw-ring-shadow, 0 0 #0000), var(--tw-shadow);
}

.outline-none {
  outline: 2px solid transparent;
  outline-offset: 2px;
}

.outline {
  outline-style: solid;
}

.outline-dashed {
  outline-style: dashed;
}

.outline-dotted {
  outline-style: dotted;
}

.outline-double {
  outline-style: double;
}

.ring {
  --tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);
  --tw-ring-shadow: var(--tw-ring-inset) 0 0 0 calc(3px + var(--tw-ring-offset-width)) var(--tw-ring-color);
  box-shadow: var(--tw-ring-offset-shadow), var(--tw-ring-shadow), var(--tw-shadow, 0 0 #0000);
}

.ring-inset {
  --tw-ring-inset: inset;
}

.blur {
  --tw-blur: blur(8px);
  filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow);
}

.drop-shadow {
  --tw-drop-shadow: drop-shadow(0 1px 2px rgb(0 0 0 / 0.1)) drop-shadow(0 1px 1px rgb(0 0 0 / 0.06));
  filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow);
}

.grayscale {
  --tw-grayscale: grayscale(100%);
  filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow);
}

.invert {
  --tw-invert: invert(100%);
  filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow);
}

.sepia {
  --tw-sepia: sepia(100%);
  filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow);
}

.\!filter {
  filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow) !important;
}

.filter {
  filter: var(--tw-blur) var(--tw-brightness) var(--tw-contrast) var(--tw-grayscale) var(--tw-hue-rotate) var(--tw-invert) var(--tw-saturate) var(--tw-sepia) var(--tw-drop-shadow);
}

.filter-none {
  filter: none;
}

.backdrop-blur {
  --tw-backdrop-blur: blur(8px);
  -webkit-backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
  backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
}

.backdrop-grayscale {
  --tw-backdrop-grayscale: grayscale(100%);
  -webkit-backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
  backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
}

.backdrop-invert {
  --tw-backdrop-invert: invert(100%);
  -webkit-backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
  backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
}

.backdrop-sepia {
  --tw-backdrop-sepia: sepia(100%);
  -webkit-backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
  backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
}

.backdrop-filter {
  -webkit-backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
  backdrop-filter: var(--tw-backdrop-blur) var(--tw-backdrop-brightness) var(--tw-backdrop-contrast) var(--tw-backdrop-grayscale) var(--tw-backdrop-hue-rotate) var(--tw-backdrop-invert) var(--tw-backdrop-opacity) var(--tw-backdrop-saturate) var(--tw-backdrop-sepia);
}

.backdrop-filter-none {
  -webkit-backdrop-filter: none;
  backdrop-filter: none;
}

.transition {
  transition-property: color, background-color, border-color, text-decoration-color, fill, stroke, opacity, box-shadow, transform, filter, -webkit-backdrop-filter;
  transition-property: color, background-color, border-color, text-decoration-color, fill, stroke, opacity, box-shadow, transform, filter, backdrop-filter;
  transition-property: color, background-color, border-color, text-decoration-color, fill, stroke, opacity, box-shadow, transform, filter, backdrop-filter, -webkit-backdrop-filter;
  transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);
  transition-duration: 150ms;
}

.ease-in {
  transition-timing-function: cubic-bezier(0.4, 0, 1, 1);
}

.ease-in-out {
  transition-timing-function: cubic-bezier(0.4, 0, 0.2, 1);
}

.ease-out {
  transition-timing-function: cubic-bezier(0, 0, 0.2, 1);
}

.contain-none {
  contain: none;
}

.contain-content {
  contain: content;
}

.contain-strict {
  contain: strict;
}

.contain-size {
  --tw-contain-size: size;
  contain: var(--tw-contain-size) var(--tw-contain-layout) var(--tw-contain-paint) var(--tw-contain-style);
}

.contain-inline-size {
  --tw-contain-size: inline-size;
  contain: var(--tw-contain-size) var(--tw-contain-layout) var(--tw-contain-paint) var(--tw-contain-style);
}

.contain-layout {
  --tw-contain-layout: layout;
  contain: var(--tw-contain-size) var(--tw-contain-layout) var(--tw-contain-paint) var(--tw-contain-style);
}

.contain-paint {
  --tw-contain-paint: paint;
  contain: var(--tw-contain-size) var(--tw-contain-layout) var(--tw-contain-paint) var(--tw-contain-style);
}

.contain-style {
  --tw-contain-style: style;
  contain: var(--tw-contain-size) var(--tw-contain-layout) var(--tw-contain-paint) var(--tw-contain-style);
}

.content-\[\'this-is-also-valid\]-weirdly-enough\'\] {
  --tw-content: 'this-is-also-valid]-weirdly-enough';
  content: var(--tw-content);
}

.forced-color-adjust-auto {
  forced-color-adjust: auto;
}

.forced-color-adjust-none {
  forced-color-adjust: none;
}

@media (min-width: 640px) {
  .sm\:container {
    width: 100%;
  }

  @media (min-width: 640px) {
    .sm\:container {
      max-width: 640px;
    }
  }

  @media (min-width: 768px) {
    .sm\:container {
      max-width: 768px;
    }
  }

  @media (min-width: 1024px) {
    .sm\:container {
      max-width: 1024px;
    }
  }

  @media (min-width: 1280px) {
    .sm\:container {
      max-width: 1280px;
    }
  }

  @media (min-width: 1536px) {
    .sm\:container {
      max-width: 1536px;
    }
  }
}

.hover\:font-bold:hover {
  font-weight: 700;
}

.before\:hover\:text-center:hover::before {
  content: var(--tw-content);
  text-align: center;
}

.hover\:before\:text-center:hover::before {
  content: var(--tw-content);
  text-align: center;
}

.focus\:hover\:text-center:hover:focus {
  text-align: center;
}

.hover\:focus\:text-center:focus:hover {
  text-align: center;
}

@media (min-width: 640px) {
  .sm\:underline {
    text-decoration-line: underline;
  }
}

@media (min-width: 1024px) {
  .dark\:lg\:hover\:\[paint-order\:markers\]:hover:is(.dark *) {
    paint-order: markers;
  }
}

.analysis-overview {
    padding: 15px;
    background: white;
    border-radius: 8px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    margin-bottom: 20px;
}

.analysis-overview h3 {
    margin: 0 0 15px;
    font-size: 16px;
    color: #1a73e8;
}

.stats-grid {
    display: grid;
    grid-template-columns: repeat(2, 1fr);
    gap: 10px;
}

.stat-box {
    padding: 12px;
    border-radius: 6px;
    text-align: center;
    background: #f8f9fa;
    transition: transform 0.2s;
}

.stat-box:hover {
    transform: translateY(-2px);
}

.stat-label {
    font-size: 13px;
    color: #5f6368;
    margin-bottom: 5px;
}

.stat-value {
    font-size: 24px;
    font-weight: 500;
    color: #202124;
}

.sentiment-positive {
    background: #e6f4ea;
    border: 1px solid rgba(52, 168, 83, 0.2);
}

.sentiment-negative {
    background: #fce8e6;
    border: 1px solid rgba(217, 48, 37, 0.2);
}

.sentiment-neutral {
    background: #f1f3f4;
    border: 1px solid rgba(95, 99, 104, 0.2);
}

/* Dark theme */
@media (prefers-color-scheme: dark) {
    .analysis-overview {
        background: #292a2d;
    }

    .analysis-overview h3 {
        color: #8ab4f8;
    }

    .stat-box {
        background: #202124;
    }

    .stat-label {
        color: #9aa0a6;
    }

    .stat-value {
        color: #e8eaed;
    }

    .sentiment-positive {
        background: rgba(52, 168, 83, 0.2);
    }

    .sentiment-negative {
        background: rgba(217, 48, 37, 0.2); 
    }

    .sentiment-neutral {
        background: rgba(95, 99, 104, 0.2);
    }
}

/* ...existing code... */

================
File: extension/popup.js
================
let port;
let reconnectTimeout = null;
let updateInterval = null;
let lastUpdateTime = null;
const UPDATE_THRESHOLD = 2000; // 2 seconds

function updatePopupUI(data) {
    try {
        // Required elements lookup with fallbacks
        const elements = {
            statusIndicator: document.getElementById('status-indicator') || createElementIfMissing('status-indicator'),
            statusBadge: document.getElementById('status-badge') || createElementIfMissing('status-badge'),
            apiStatus: document.getElementById('apiStatus') || createElementIfMissing('apiStatus'),
            analyzedCount: document.getElementById('analyzed-count') || createElementIfMissing('analyzed-count'),
            successRate: document.getElementById('success-rate') || createElementIfMissing('success-rate'),
            lastUpdate: document.getElementById('last-update') || createElementIfMissing('last-update'),
            errorContainer: document.getElementById('error-container') || createElementIfMissing('error-container')
        };

        // Show error if any elements are missing
        const missingElements = Object.entries(elements)
            .filter(([key, element]) => !element)
            .map(([key]) => key);

        if (missingElements.length > 0) {
            showError(`Missing UI elements: ${missingElements.join(', ')}`);
            return;
        }

        // Hide error container if everything is OK
        elements.errorContainer.classList.add('hidden');

        // Rest of existing updatePopupUI code...
        if (!data || !data.api) return;

        // Update status indicator
        if (data.api.isAvailable) {
            elements.statusIndicator.className = 'h-3 w-3 rounded-full bg-green-500';
            elements.statusBadge.textContent = 'Online';
            elements.statusBadge.className = 'text-xs font-medium bg-green-100 text-green-800 px-2 py-1 rounded-full';

            if (data.api.models) {
                const modelStatus = Object.entries(data.api.models)
                    .map(([lang, status]) => `${lang.toUpperCase()}: ${status ? '✓' : '✗'}`)
                    .join(' | ');
                elements.apiStatus.textContent = `Connected | ${modelStatus}`;
            } else {
                elements.apiStatus.textContent = 'Connected';
            }
        } else {
            elements.statusIndicator.className = 'h-3 w-3 rounded-full bg-red-500';
            elements.statusBadge.textContent = 'Offline';
            elements.statusBadge.className = 'text-xs font-medium bg-red-100 text-red-800 px-2 py-1 rounded-full';
            elements.apiStatus.textContent = data.api.error || 'Connection failed';
        }

        // Update stats
        if (data.stats) {
            elements.analyzedCount.textContent = data.stats.analyzed || '0';
            elements.successRate.textContent =
                `${Math.round((data.stats.successful / data.stats.analyzed) * 100) || 0}%`;
        }

        // Update timestamp
        if (data.timestamp) {
            const lastUpdate = new Date(data.timestamp);
            elements.lastUpdate.textContent = `Last updated: ${lastUpdate.toLocaleTimeString()}`;
        }
    } catch (error) {
        showError(`UI Update Error: ${error.message}`);
    }
}

function createElementIfMissing(id) {
    // Create missing element with default styling
    const element = document.createElement('div');
    element.id = id;
    element.className = 'missing-element';
    document.body.appendChild(element);
    console.warn(`Created missing element: ${id}`);
    return element;
}

function showError(message) {
    const errorContainer = document.getElementById('error-container') ||
        createElementIfMissing('error-container');
    errorContainer.classList.remove('hidden');
    errorContainer.textContent = message;
    console.error(message);
}

function setupConnection() {
    try {
        if (port) {
            try {
                port.disconnect();
            } catch (e) {
                console.warn('Error disconnecting old port:', e);
            }
            port = null;
        }

        const connect = (retryCount = 0) => {
            try {
                port = chrome.runtime.connect({ name: 'popup' });
                setupMessageHandlers(port);
                startUpdateCycle(port);

                // Add auto-reconnect logic
                port.onDisconnect.addListener(() => {
                    if (chrome.runtime.lastError) {
                        console.warn('Connection lost:', chrome.runtime.lastError);
                        retryConnection(retryCount);
                    }
                });
            } catch (error) {
                console.error('Connection error:', error);
                retryConnection(retryCount);
            }
        };

        connect();
    } catch (error) {
        console.error('Setup error:', error);
    }
}

function retryConnection(retryCount) {
    port = null;
    clearInterval(updateInterval);
    if (reconnectTimeout) clearTimeout(reconnectTimeout);

    if (retryCount < 3) {
        reconnectTimeout = setTimeout(
            () => setupConnection(retryCount + 1),
            1000 * Math.pow(2, retryCount)
        );
    }
}

function setupMessageHandlers(port) {
    if (!port) return;

    port.onMessage.addListener((msg) => {
        try {
            switch (msg.type) {
                case 'PING':
                    port.postMessage({ type: 'PONG' });
                    break;

                case 'STATUS_UPDATE':
                    if (msg.data) updatePopupUI(msg.data);
                    break;

                case 'API_ERROR':
                    handleApiError(msg.error);
                    break;

                case 'STATS_UPDATE':
                    updateStats(msg.stats);
                    break;

                default:
                    console.warn('Unknown message type:', msg.type);
            }
        } catch (error) {
            console.error('Message handler error:', error);
            showError(error.message);
        }
    });
}

function handleApiError(error) {
    const errorContainer = document.getElementById('error-container');
    if (errorContainer) {
        errorContainer.classList.remove('hidden');
        errorContainer.textContent = `API Error: ${error}`;
        setTimeout(() => {
            errorContainer.classList.add('hidden');
        }, 5000);
    }
}

function updateStats(stats) {
    const elements = {
        analyzedCount: document.getElementById('analyzed-count'),
        successRate: document.getElementById('success-rate')
    };

    if (elements.analyzedCount) {
        elements.analyzedCount.textContent = stats.analyzed || '0';
    }

    if (elements.successRate) {
        const rate = stats.analyzed > 0
            ? Math.round((stats.successful / stats.analyzed) * 100)
            : 0;
        elements.successRate.textContent = `${rate}%`;
    }
}

function startUpdateCycle(port) {
    if (updateInterval) clearInterval(updateInterval);

    // Initial state request
    requestUpdate(port);

    // Setup periodic updates with throttling
    updateInterval = setInterval(() => {
        const now = Date.now();
        if (!lastUpdateTime || now - lastUpdateTime >= UPDATE_THRESHOLD) {
            requestUpdate(port);
        }
    }, 3000);
}

function requestUpdate(port) {
    if (!port) return;

    try {
        port.postMessage({ type: 'GET_INITIAL_STATE' });
        lastUpdateTime = Date.now();
    } catch (e) {
        console.warn('Update request failed:', e);
        setupConnection();
    }
}

async function getCurrentTab() {
    try {
        const tabs = await chrome.tabs.query({
            active: true,
            currentWindow: true
        });

        if (!tabs || tabs.length === 0) {
            throw new Error('No active tab found');
        }
        return tabs[0];
    } catch (error) {
        console.error('Error getting current tab:', error);
        throw new Error('Could not access current tab');
    }
}

async function extractFacebookAccessToken(tab) {
    if (!tab?.id) {
        throw new Error('Invalid tab');
    }

    try {
        const result = await chrome.scripting.executeScript({
            target: { tabId: tab.id },
            func: () => {
                try {
                    // Try to get EAAB token first
                    const ls = window.localStorage;
                    const tokenKeys = Object.keys(ls).filter(key =>
                        key.includes('token') ||
                        key.includes('EAAB') ||
                        key.includes('accessToken')
                    );

                    for (const key of tokenKeys) {
                        const value = ls.getItem(key);
                        if (value && value.includes('EAAB')) {
                            return value.match(/EAAB[^"]+/)[0];
                        }
                    }

                    // Fallback to user ID from cookie
                    const cookieMatch = document.cookie.match(/c_user=([^;]+)/);
                    const userId = cookieMatch ? cookieMatch[1] : null;

                    if (!userId) {
                        throw new Error('Facebook access token not found');
                    }

                    return userId;
                } catch (e) {
                    console.error('Error extracting token:', e);
                    return null;
                }
            }
        });

        if (!result || !result[0]?.result) {
            throw new Error('Could not extract Facebook access token');
        }

        return result[0].result;
    } catch (error) {
        console.error('Script execution error:', error);
        throw new Error('Failed to access Facebook data. Please make sure you are logged in.');
    }
}

async function analyzeFacebookPost(postId, accessToken) {
    try {
        // Get post details from Facebook API
        const postResponse = await fetch(
            `https://graph.facebook.com/v18.0/${postId}?fields=message,comments{message,id}&access_token=${accessToken}`
        );
        const postData = await postResponse.json();

        // Send all text for analysis
        const texts = [postData.message];
        if (postData.comments) {
            texts.push(...postData.comments.data.map(c => c.message));
        }

        // Send to our sentiment API
        const response = await fetch(`${this.API_URL}/batch`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                texts: texts,
                language: 'vi'
            })
        });

        return await response.json();
    } catch (error) {
        console.error('Analysis error:', error);
        throw error;
    }
}

function extractPostId(url) {
    // Try different Facebook URL patterns
    const patterns = [
        /\/posts\/(\d+)/,                    // Standard post URL
        /\/permalink\/(\d+)/,                // Permalink format
        /\?story_fbid=(\d+)/,               // Story format
        /\/photo\.php\?fbid=(\d+)/,         // Photo URL format
        /\/video\.php\?v=(\d+)/,            // Video URL format
        /\/(\d+)(?:\/)?(?:\?|$)/            // Direct ID format
    ];

    for (const pattern of patterns) {
        const match = url.match(pattern);
        if (match && match[1]) {
            return match[1];
        }
    }
    return null;
}

document.addEventListener('DOMContentLoaded', async () => {
    setupConnection();

    // Setup API configuration
    const { apiUrl } = await chrome.storage.local.get('apiUrl');
    if (apiUrl) {
        document.getElementById('apiUrl').value = apiUrl;
    }

    // API configuration save handler
    document.getElementById('saveApiConfig').addEventListener('click', async () => {
        const apiUrl = document.getElementById('apiUrl').value.trim();
        const status = document.getElementById('apiUrlStatus');

        if (!apiUrl) {
            status.textContent = 'Please enter an API URL';
            status.className = 'text-xs text-red-500';
            return;
        }

        try {
            await chrome.storage.local.set({ apiUrl });
            chrome.runtime.sendMessage({ type: 'API_URL_CHANGED', apiUrl });

            status.textContent = 'API URL saved successfully';
            status.className = 'text-xs text-green-500';
            setTimeout(() => status.textContent = '', 3000);
        } catch (error) {
            status.textContent = 'Error saving API URL';
            status.className = 'text-xs text-red-500';
        }
    });

    // Add reset handler for API configuration
    document.getElementById('resetApiConfig').addEventListener('click', async () => {
        const status = document.getElementById('apiUrlStatus');

        try {
            // Clear API URL from storage
            await chrome.storage.local.remove('apiUrl');

            // Reset input field
            document.getElementById('apiUrl').value = '';

            // Notify background script
            chrome.runtime.sendMessage({
                type: 'API_URL_CHANGED',
                apiUrl: 'http://localhost:7270' // Reset to default
            });

            status.textContent = 'Configuration reset successfully';
            status.className = 'text-xs text-green-500';
            setTimeout(() => status.textContent = '', 3000);
        } catch (error) {
            status.textContent = 'Error resetting configuration';
            status.className = 'text-xs text-red-500';
        }
    });

    // Add analyze current post handler
    document.getElementById('analyzeCurrentPost').addEventListener('click', async () => {
        const button = document.getElementById('analyzeCurrentPost');
        const errorContainer = document.getElementById('error-container');

        button.disabled = true;
        button.innerHTML = '<span class="spinner-border spinner-border-sm"></span> Đang phân tích...';
        errorContainer.classList.add('hidden');

        try {
            // Get current tab with validation
            const tab = await getCurrentTab();

            if (!tab?.url?.includes('facebook.com')) {
                throw new Error('Vui lòng mở bài viết Facebook để phân tích');
            }

            // Get access token with validation
            const accessToken = await extractFacebookAccessToken(tab);

            // Extract post ID with validation
            const postId = extractPostId(tab.url);
            if (!postId) {
                throw new Error('Không tìm thấy bài viết Facebook trên trang này');
            }

            // Send message with timeout and error handling
            const response = await new Promise((resolve, reject) => {
                const timeout = setTimeout(() => {
                    reject(new Error('Phân tích quá thời gian, vui lòng thử lại'));
                }, 30000); // 30 second timeout

                chrome.tabs.sendMessage(tab.id, {
                    type: 'ANALYZE_POST',
                    postId: postId,
                    accessToken: accessToken
                }, (response) => {
                    clearTimeout(timeout);
                    if (chrome.runtime.lastError) {
                        reject(new Error(chrome.runtime.lastError.message));
                    } else {
                        resolve(response);
                    }
                });
            });

            if (!response?.success) {
                throw new Error(response?.error || 'Phân tích thất bại');
            }

            // Hide error container on success
            errorContainer.classList.add('hidden');

        } catch (error) {
            console.error('Analysis error:', error);
            errorContainer.textContent = error.message;
            errorContainer.classList.remove('hidden');
        } finally {
            // Always reset button state
            button.disabled = false;
            button.textContent = 'Phân tích bài viết này';
        }
    });
});

// Cleanup
window.addEventListener('unload', () => {
    if (updateInterval) clearInterval(updateInterval);
    if (reconnectTimeout) clearTimeout(reconnectTimeout);
    if (port) port.disconnect();
});

async function ensureContentScriptConnection(tab) {
    return new Promise((resolve, reject) => {
        const maxRetries = 5;
        let retryCount = 0;

        const checkConnection = () => {
            chrome.tabs.sendMessage(tab.id, { type: 'PING' }, response => {
                if (chrome.runtime.lastError || !response?.success) {
                    if (retryCount++ < maxRetries) {
                        // Check if script already exists before injecting
                        chrome.scripting.executeScript({
                            target: { tabId: tab.id },
                            func: () => Boolean(window.sentimentAnalyzer)
                        }).then(result => {
                            const exists = result[0]?.result;
                            if (!exists) {
                                // Only inject if not already present
                                chrome.scripting.executeScript({
                                    target: { tabId: tab.id },
                                    files: ['content.js']
                                }).then(() => {
                                    setTimeout(checkConnection, 500);
                                }).catch(reject);
                            } else {
                                setTimeout(checkConnection, 500);
                            }
                        }).catch(reject);
                        return;
                    }
                    reject(new Error('Could not establish connection'));
                    return;
                }
                resolve(true);
            });
        };

        checkConnection();
    });
}

async function analyzeCurrentPost(tab) {
    const button = document.getElementById('analyzeCurrentPost');
    const errorContainer = document.getElementById('error-container');

    try {
        button.disabled = true;
        button.innerHTML = '<span class="spinner-border spinner-border-sm"></span> Đang kết nối...';
        errorContainer.classList.add('hidden');

        // Ensure content script is ready
        await ensureContentScriptConnection(tab);

        // Continue with analysis
        button.innerHTML = '<span class="spinner-border spinner-border-sm"></span> Đang phân tích...';

        // ...rest of the analysis code...

    } catch (error) {
        console.error('Analysis error:', error);
        errorContainer.textContent = error.message;
        errorContainer.classList.remove('hidden');
    } finally {
        button.disabled = false;
        button.textContent = 'Phân tích bài viết này';
    }
}

async function ensureContentScriptConnection(tab) {
    return new Promise((resolve, reject) => {
        const maxRetries = 5;
        let retryCount = 0;

        const checkConnection = () => {
            chrome.tabs.sendMessage(tab.id, { type: 'PING' }, response => {
                if (chrome.runtime.lastError || !response?.success) {
                    if (retryCount++ < maxRetries) {
                        // Inject content script if needed
                        chrome.scripting.executeScript({
                            target: { tabId: tab.id },
                            files: ['content.js']
                        }).then(() => {
                            setTimeout(checkConnection, 500);
                        }).catch(reject);
                        return;
                    }
                    reject(new Error('Could not establish connection'));
                    return;
                }

                if (!response.ready) {
                    if (retryCount++ < maxRetries) {
                        setTimeout(checkConnection, 500);
                        return;
                    }
                    reject(new Error('Content script not ready'));
                    return;
                }

                resolve(true);
            });
        };

        checkConnection();
    });
}

async function analyzeCurrentPost(tab) {
    const button = document.getElementById('analyzeCurrentPost');
    const errorContainer = document.getElementById('error-container');

    try {
        button.disabled = true;
        button.innerHTML = '<span class="spinner-border spinner-border-sm"></span> Đang kết nối...';

        // Ensure connection is ready
        await ensureContentScriptConnection(tab);

        button.innerHTML = '<span class="spinner-border spinner-border-sm"></span> Đang phân tích...';

        const postId = extractPostId(tab.url);
        if (!postId) {
            throw new Error('Không tìm thấy bài viết Facebook trên trang này');
        }

        const response = await sendMessageWithRetry(tab.id, {
            type: 'ANALYZE_POST',
            postId: postId
        });

        if (!response?.success) {
            throw new Error(response?.error || 'Phân tích thất bại');
        }

        errorContainer.classList.add('hidden');

    } catch (error) {
        console.error('Analysis error:', error);
        errorContainer.textContent = error.message;
        errorContainer.classList.remove('hidden');
    } finally {
        button.disabled = false;
        button.textContent = 'Phân tích bài viết này';
    }
}

async function sendMessageWithRetry(tabId, message, maxRetries = 3) {
    const requestId = Date.now().toString();
    message.requestId = requestId;

    return new Promise((resolve, reject) => {
        const timeout = setTimeout(() => {
            cleanup();
            reject(new Error('Quá thời gian chờ phản hồi'));
        }, 30000);

        const responseHandler = (response) => {
            if (response.requestId === requestId) {
                cleanup();
                if (response.success === false) {
                    reject(new Error(response.error || 'Phân tích thất bại'));
                } else {
                    resolve(response);
                }
            }
        };

        const cleanup = () => {
            clearTimeout(timeout);
            chrome.runtime.onMessage.removeListener(responseHandler);
        };

        // Listen for response
        chrome.runtime.onMessage.addListener(responseHandler);

        // Send message
        chrome.tabs.sendMessage(tabId, message, (ack) => {
            if (chrome.runtime.lastError) {
                cleanup();
                reject(new Error(chrome.runtime.lastError.message));
            }
            // Acknowledgment received, waiting for async response
        });
    });
}

async function ensureContentScriptConnection(tab) {
    let retryCount = 0;
    const maxRetries = 5;

    while (retryCount < maxRetries) {
        try {
            const response = await sendMessageWithRetry(tab.id, { type: 'PING' });
            if (response?.success) {
                return true;
            }
        } catch (error) {
            console.warn(`Connection attempt ${retryCount + 1} failed:`, error);

            // Inject content script if needed
            if (retryCount === 0) {
                try {
                    await chrome.scripting.executeScript({
                        target: { tabId: tab.id },
                        files: ['content.js']
                    });
                } catch (injectionError) {
                    console.error('Script injection failed:', injectionError);
                }
            }
        }

        retryCount++;
        if (retryCount < maxRetries) {
            await new Promise(resolve => setTimeout(resolve, 1000));
        }
    }

    throw new Error('Could not establish connection to content script');
}

// Update analyze button handler
document.getElementById('analyzeCurrentPost').addEventListener('click', async () => {
    const button = document.getElementById('analyzeCurrentPost');
    const errorContainer = document.getElementById('error-container');

    try {
        button.disabled = true;
        button.innerHTML = '<span class="spinner-border spinner-border-sm"></span> Đang xử lý...';
        errorContainer.classList.add('hidden');

        const tab = await getCurrentTab();
        if (!tab?.url?.includes('facebook.com')) {
            throw new Error('Vui lòng mở bài viết Facebook để phân tích');
        }

        await ensureContentScriptConnection(tab);

        const postId = extractPostId(tab.url);
        if (!postId) {
            throw new Error('Không tìm thấy bài viết trên trang này');
        }

        const response = await sendMessageWithRetry(tab.id, {
            type: 'ANALYZE_POST',
            postId: postId
        });

        if (!response.analyzed) {
            throw new Error('Không có nội dung nào được phân tích');
        }

        // Show success message
        errorContainer.textContent = `Đã phân tích ${response.analyzed} nội dung thành công`;
        errorContainer.className = 'mt-2 p-2 rounded-md bg-green-100 text-green-700 text-sm';
        errorContainer.classList.remove('hidden');

    } catch (error) {
        console.error('Analysis error:', error);
        errorContainer.textContent = error.message || 'Có lỗi xảy ra';
        errorContainer.className = 'mt-2 p-2 rounded-md bg-red-100 text-red-700 text-sm';
        errorContainer.classList.remove('hidden');
    } finally {
        button.disabled = false;
        button.textContent = 'Phân tích bài viết này';
    }
});

class PopupAnalytics {
    constructor() {
        this.stats = {
            total: 0,
            successful: 0,
            positive: 0,
            negative: 0,
            neutral: 0
        };
        this.initializeElements();
        this.setupListeners();
    }

    initializeElements() {
        this.elements = {
            totalAnalyzed: document.getElementById('totalAnalyzed'),
            totalSuccessful: document.getElementById('totalSuccessful'),
            totalPositive: document.getElementById('totalPositive'),
            totalNegative: document.getElementById('totalNegative'),
            totalNeutral: document.getElementById('totalNeutral')
        };
    }

    setupListeners() {
        // Listen for stats updates from content script
        chrome.runtime.onMessage.addListener((message, sender, sendResponse) => {
            if (message.type === 'STATS_UPDATE') {
                this.updateStats(message.stats);
            }
        });

        // Request initial stats
        chrome.runtime.sendMessage({ type: 'GET_STATS' }, (response) => {
            if (response && response.success) {
                this.updateStats(response.stats);
            }
        });
    }

    updateStats(stats) {
        // Update local stats
        Object.assign(this.stats, stats);

        // Update UI
        this.elements.totalAnalyzed.textContent = this.stats.total;
        this.elements.totalSuccessful.textContent = this.stats.successful;
        this.elements.totalPositive.textContent = this.stats.positive;
        this.elements.totalNegative.textContent = this.stats.negative;
        this.elements.totalNeutral.textContent = this.stats.neutral;

        // Add percentage tooltips
        if (this.stats.total > 0) {
            this.elements.totalPositive.setAttribute('title', 
                `${((this.stats.positive / this.stats.total) * 100).toFixed(1)}%`);
            this.elements.totalNegative.setAttribute('title',
                `${((this.stats.negative / this.stats.total) * 100).toFixed(1)}%`);
            this.elements.totalNeutral.setAttribute('title',
                `${((this.stats.neutral / this.stats.total) * 100).toFixed(1)}%`);
        }
    }
}

// Initialize analytics when popup loads
document.addEventListener('DOMContentLoaded', () => {
    window.popupAnalytics = new PopupAnalytics();
});

================
File: extension/src/input.css
================
@tailwind base;
@tailwind components;
@tailwind utilities;

================
File: extension/style.css
================
.sentiment-analyze-btn {
  background-color: #1877f2;
  color: white;
  border: none;
  padding: 8px 12px;
  border-radius: 6px;
  cursor: pointer;
  font-size: 14px;
  margin: 5px 0;
  transition: background-color 0.2s;
}

.sentiment-analyze-btn:hover {
  background-color: #166fe5;
}

.sentiment-result {
  margin: 5px 0;
  padding: 10px;
  border-radius: 8px;
  background-color: #f0f2f5;
  font-size: 13px;
}

.sentiment-positive {
  border-left: 4px solid #4caf50;
}

.sentiment-neutral {
  border-left: 4px solid #ff9800;
}

.sentiment-negative {
  border-left: 4px solid #f44336;
}

.sentiment-button-container {
  margin: 8px 0;
}

.comment-buttons-wrapper {
    display: flex;
    align-items: center;
    gap: 8px;
}

.sentiment-analyze-btn-inline {
    display: inline-flex;
    align-items: center;
    cursor: pointer;
    color: #65676B;
    font-size: inherit;
    padding: 4px 8px;
    border-radius: 6px;
    transition: background-color 0.2s;
}

.sentiment-analyze-btn-inline:hover {
    background-color: rgba(0, 0, 0, 0.05);
}

.analyze-comments-btn {
    display: flex;
    align-items: center;
    gap: 4px;
}

================
File: extension/tailwind.config.js
================
module.exports = {
  content: ["./**/*.{html,js}"],
  darkMode: 'class',
  theme: {
    extend: {
      colors: {
        border: "hsl(var(--border))",
        background: "hsl(var(--background))",
        foreground: "hsl(var(--foreground))",
      }
    }
  }
}

================
File: metrics.json
================
{"requests": [], "response_times": [], "errors": [], "start_time": "2024-11-29T18:32:58.952649", "total_requests": 0, "total_errors": 0, "model_performance": {"vi": {"loading_time": 0.0, "inference_times": [], "accuracy": 0.0, "precision": 0.0, "recall": 0.0}, "en": {"loading_time": 0.0, "inference_times": [], "accuracy": 0.0, "precision": 0.0, "recall": 0.0}}}

================
File: notebooks/0.0-init-environment.ipynb
================
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Environment for Sentiment Analysis Project\n",
    "\n",
    "Notebook này sẽ:\n",
    "1. Tạo môi trường ảo (venv)\n",
    "2. Cài đặt các dependencies\n",
    "3. Cài đặt Jupyter kernel cho venv\n",
    "4. Tải dữ liệu NLTK cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (8.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (3.0.48)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (4.12.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (2.18.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: stack-data in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from ipython) (0.19.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from jedi>=0.16->ipython) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython) (0.2.13)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from stack-data->ipython) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\tamaisme\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipython\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "✅ Virtual environment created at 'venv'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tạo virtual environment\n",
    "def create_venv():\n",
    "    venv_path = '../venv'\n",
    "    if not os.path.exists(venv_path):\n",
    "        !python -m venv {venv_path}\n",
    "        display(Markdown(\"✅ Virtual environment created at 'venv'\"))\n",
    "    else:\n",
    "        display(Markdown(\"ℹ️ Virtual environment already exists\"))\n",
    "    return venv_path\n",
    "\n",
    "venv_path = create_venv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "✅ Dependencies installed"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cài đặt dependencies trong venv\n",
    "def install_dependencies():\n",
    "    if sys.platform.startswith('win'):\n",
    "        pip_path = os.path.join(venv_path, 'Scripts', 'pip')\n",
    "    else:\n",
    "        pip_path = os.path.join(venv_path, 'bin', 'pip')\n",
    "    \n",
    "    # Cài đặt jupyter trong venv\n",
    "    os.system(f\"{pip_path} install jupyter ipykernel\")\n",
    "    \n",
    "    # Cài đặt project và dependencies\n",
    "    project_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    os.system(f\"{pip_path} install -e {project_path}\")\n",
    "    os.system(f\"{pip_path} install -r {project_path}/requirements.txt\")\n",
    "    \n",
    "    display(Markdown(\"✅ Dependencies installed\"))\n",
    "\n",
    "install_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "✅ Jupyter kernel installed"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cài đặt Jupyter kernel cho venv\n",
    "def setup_jupyter_kernel():\n",
    "    if sys.platform.startswith('win'):\n",
    "        python_path = os.path.join(venv_path, 'Scripts', 'python')\n",
    "    else:\n",
    "        python_path = os.path.join(venv_path, 'bin', 'python')\n",
    "        \n",
    "    os.system(f\"{python_path} -m ipykernel install --user --name=sentiment_analysis --display-name='Python (Sentiment Analysis)'\")\n",
    "    display(Markdown(\"✅ Jupyter kernel installed\"))\n",
    "\n",
    "setup_jupyter_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltkNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2024.11.6-cp39-cp39-win_amd64.whl (274 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Collecting click\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tamaisme\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.9.1 regex-2024.11.6 tqdm-4.67.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\tamaisme\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tamaisme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tamaisme\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "✅ NLTK data downloaded"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tải dữ liệu NLTK cần thiết\n",
    "%pip install nltk\n",
    "\n",
    "def download_nltk_data():\n",
    "    import nltk\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "    display(Markdown(\"✅ NLTK data downloaded\"))\n",
    "\n",
    "download_nltk_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hướng dẫn sử dụng\n",
    "\n",
    "1. Sau khi chạy notebook này, restart Jupyter Server\n",
    "2. Khi tạo notebook mới, chọn kernel \"Python (Sentiment Analysis)\"\n",
    "3. Kiểm tra cài đặt bằng cách chạy code sau trong notebook mới:\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "import underthesea\n",
    "print(\"Environment ready!\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

================
File: notebooks/1.0-data_labeling.ipynb
================
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Labeling Tool for Sentiment Analysis\n",
    "\n",
    "Tool này giúp gán nhãn sentiment cho các câu input và lưu thành file CSV để training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLabeler:\n",
    "    def __init__(self, language):\n",
    "        self.language = language\n",
    "        self.data = []\n",
    "        self.setup_widgets()\n",
    "        \n",
    "    def setup_widgets(self):\n",
    "        self.text_input = widgets.Textarea(\n",
    "            placeholder='Nhập văn bản cần gán nhãn ở đây...' if self.language == 'vi' else 'Enter text to label here...',\n",
    "            layout={'width': '100%', 'height': '100px'}\n",
    "        )\n",
    "        \n",
    "        self.label_buttons = [\n",
    "            widgets.Button(description='Tích cực / Positive', button_style='success'),\n",
    "            widgets.Button(description='Tiêu cực / Negative', button_style='danger'),\n",
    "            widgets.Button(description='Trung tính / Neutral', button_style='info')\n",
    "        ]\n",
    "        \n",
    "        for btn in self.label_buttons:\n",
    "            btn.on_click(self.on_button_clicked)\n",
    "        \n",
    "        self.save_button = widgets.Button(\n",
    "            description='Lưu dữ liệu / Save data',\n",
    "            button_style='warning'\n",
    "        )\n",
    "        self.save_button.on_click(self.save_data)\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "    def display(self):\n",
    "        display(self.text_input)\n",
    "        display(widgets.HBox(self.label_buttons))\n",
    "        display(self.save_button)\n",
    "        display(self.output)\n",
    "        \n",
    "    def on_button_clicked(self, btn):\n",
    "        text = self.text_input.value.strip()\n",
    "        if not text:\n",
    "            return\n",
    "            \n",
    "        label_map = {\n",
    "            'Tích cực / Positive': 'positive',\n",
    "            'Tiêu cực / Negative': 'negative',\n",
    "            'Trung tính / Neutral': 'neutral'\n",
    "        }\n",
    "        \n",
    "        self.data.append({\n",
    "            'text': text,\n",
    "            'label': label_map[btn.description]\n",
    "        })\n",
    "        \n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            print(f\"Đã gán nhãn {len(self.data)} câu\" if self.language == 'vi' else f\"Labeled {len(self.data)} sentences\")\n",
    "            \n",
    "        self.text_input.value = ''\n",
    "        \n",
    "    def save_data(self, btn):\n",
    "        if not self.data:\n",
    "            return\n",
    "            \n",
    "        df = pd.DataFrame(self.data)\n",
    "        \n",
    "        # Ensure data directory exists\n",
    "        os.makedirs('../data/raw', exist_ok=True)\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_path = f'../data/raw/{self.language}_social_media_manual.csv'\n",
    "        \n",
    "        # If file exists, append to it\n",
    "        if os.path.exists(output_path):\n",
    "            existing_df = pd.read_csv(output_path)\n",
    "            df = pd.concat([existing_df, df], ignore_index=True)\n",
    "        \n",
    "        df.to_csv(output_path, index=False)\n",
    "        \n",
    "        with self.output:\n",
    "            clear_output()\n",
    "            print(f\"Đã lưu {len(df)} câu vào {output_path}\" if self.language == 'vi' \n",
    "                  else f\"Saved {len(df)} sentences to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gán nhãn cho Tiếng Việt / Vietnamese Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa2d001d8d34bcb92ad9f8c5eee3ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='100px', width='100%'), placeholder='Nhập văn bản cần gán nhãn ở đây..…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b009a31b0304491fb9c612c0246d8ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='Tích cực / Positive', style=ButtonStyle()), Button(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db87944ebe24d24960f81e39a41c3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Lưu dữ liệu / Save data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6111b751db54876859f23bb541a284e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vi_labeler = SentimentLabeler('vi')\n",
    "vi_labeler.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gán nhãn cho Tiếng Anh / English Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719f33b627df48d59de15d2f06201db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', layout=Layout(height='100px', width='100%'), placeholder='Enter text to label here...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1504f750d6f442ad8a21f88d92c3a5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='success', description='Tích cực / Positive', style=ButtonStyle()), Button(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e43e2b91bc464caf45e2f8f9e64a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='warning', description='Lưu dữ liệu / Save data', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1df89cb17947c28f98a942ec6fc93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "en_labeler = SentimentLabeler('en')\n",
    "en_labeler.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

================
File: notebooks/continue_training.ipynb
================
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continue Training Sentiment Analysis Model\n",
    "\n",
    "Notebook này cho phép:\n",
    "1. Khôi phục model từ checkpoint\n",
    "2. Tiếp tục train với dữ liệu mới\n",
    "3. Đánh giá và lưu kết quả training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath('')))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.config import Config\n",
    "from src.models.model_trainer import EnhancedModelTrainer\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.preprocessor import DataPreprocessor\n",
    "from src.features.feature_engineering import FeatureExtractor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded feature extractor with None dimensions\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo config và components\n",
    "config = Config()\n",
    "language = 'vi'  # hoặc 'en'\n",
    "\n",
    "trainer = EnhancedModelTrainer(language, config)\n",
    "preprocessor = DataPreprocessor(language, config)\n",
    "feature_extractor = FeatureExtractor(language, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Available Checkpoints"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. vi_checkpoint.pkl\n",
      "   Timestamp: Unknown\n",
      "   Epoch: Unknown\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to NoneType.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Timestamp: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f if cp[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] else \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to NoneType.__format__"
     ]
    }
   ],
   "source": [
    "# Liệt kê các checkpoints có sẵn\n",
    "checkpoints = trainer.list_checkpoints()\n",
    "\n",
    "display(Markdown(\"## Available Checkpoints\"))\n",
    "for i, cp in enumerate(checkpoints):\n",
    "    print(f\"{i+1}. {cp['filename']}\")\n",
    "    print(f\"   Timestamp: {cp['timestamp']}\")\n",
    "    print(f\"   Epoch: {cp['epoch']}\")\n",
    "    print(f\"   Score: {cp['metrics']:.4f if cp['metrics'] else 'N/A'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Chọn checkpoint để tiếp tục train\u001b[39;00m\n\u001b[0;32m      2\u001b[0m checkpoint_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter checkpoint number (or press Enter for latest): \u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 3\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter number of epochs to train: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m checkpoint_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(checkpoints):\n\u001b[0;32m      6\u001b[0m     checkpoint_name \u001b[38;5;241m=\u001b[39m checkpoints[checkpoint_idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "# Chọn checkpoint để tiếp tục train\n",
    "checkpoint_idx = int(input(\"Enter checkpoint number (or press Enter for latest): \") or 0) - 1\n",
    "num_epochs = int(input(\"Enter number of epochs to train: \"))\n",
    "\n",
    "if 0 <= checkpoint_idx < len(checkpoints):\n",
    "    checkpoint_name = checkpoints[checkpoint_idx]['filename']\n",
    "else:\n",
    "    checkpoint_name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải dữ liệu training\n",
    "train_file = input(\"Enter training data file path: \")\n",
    "df = pd.read_csv(train_file)\n",
    "\n",
    "# Tiền xử lý dữ liệu\n",
    "processed_df = preprocessor.preprocess(df)\n",
    "print(f\"\\nProcessed {len(processed_df)} samples\")\n",
    "\n",
    "# Chuẩn bị features và labels\n",
    "X_train = processed_df[\"cleaned_text\"] \n",
    "y_train = processed_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tiếp tục training\n",
    "model, metrics = trainer.continue_training(\n",
    "    X_train=X_train,\n",
    "    y_train=y_train, \n",
    "    checkpoint_name=checkpoint_name,\n",
    "    num_epochs=num_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiển thị kết quả training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for model_name, model_metrics in metrics['models'].items():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    \n",
    "    train_scores = model_metrics['train_scores']\n",
    "    valid_scores = model_metrics['valid_scores']\n",
    "    epochs = range(1, len(train_scores) + 1)\n",
    "    \n",
    "    plt.plot(epochs, train_scores, 'o-', label='Training')\n",
    "    plt.plot(epochs, valid_scores, 's--', label='Validation')\n",
    "    \n",
    "    plt.title(f'{model_name} Learning Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n{model_name} Final Metrics:\")\n",
    "    print(f\"Best Score: {model_metrics['best_score']:.4f}\")\n",
    "    print(f\"Training Time: {model_metrics['training_time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hướng dẫn sử dụng\n",
    "\n",
    "1. Chọn ngôn ngữ ('vi' hoặc 'en') trong cell thứ 2\n",
    "2. Chọn checkpoint muốn tiếp tục train từ danh sách\n",
    "3. Nhập số epoch muốn train thêm \n",
    "4. Nhập đường dẫn file dữ liệu training (.csv)\n",
    "5. Theo dõi quá trình training và kết quả\n",
    "\n",
    "Model và metrics sẽ được tự động lưu theo checkpoint."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

================
File: notebooks/sentiment_analysis_pipeline.ipynb
================
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Pipeline\n",
    "Notebook này thực hiện toàn bộ quy trình từ xử lý dữ liệu thô đến training và đánh giá model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import các module cần thiết\n",
    "from src.config import Config\n",
    "from src.data.data_loader import DataLoader\n",
    "from src.data.preprocessor import DataPreprocessor \n",
    "from src.features.feature_engineering import FeatureExtractor\n",
    "from src.models.model_trainer import EnhancedModelTrainer\n",
    "from src.models.model_predictor import SentimentPredictor\n",
    "from src.utils.evaluation import ModelEvaluator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Cấu hình và Khởi tạo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo config\n",
    "config = Config()\n",
    "\n",
    "# Chọn ngôn ngữ\n",
    "language = 'vi'  # hoặc 'en'\n",
    "\n",
    "# Khởi tạo các component\n",
    "data_loader = DataLoader(config)\n",
    "preprocessor = DataPreprocessor(language, config)\n",
    "feature_extractor = FeatureExtractor(language, config)\n",
    "model_trainer = EnhancedModelTrainer(language, config)\n",
    "evaluator = ModelEvaluator(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load và Xử lý Dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Info:\n",
      "Total samples: 10000\n",
      "\n",
      "Class distribution:\n",
      "No label column found in the dataset\n",
      "2024-12-08 11:55:55,018 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-12-08 11:56:00,197 - src.data.preprocessor - INFO - Preprocessed 7700 valid samples\n",
      "2024-12-08 11:56:00,219 - src.data.preprocessor - INFO - Saved processed data to c:\\Users\\tamaisme\\Desktop\\Vietnamese-English-Sentiment-Analysis-System\\data\\processed\\vi_processed.csv\n",
      "2024-12-08 11:56:00,221 - src.data.data_loader - INFO - Class distribution before split: {0: 0.4944155844155844, 2: 0.39025974025974025, 1: 0.11532467532467533}\n",
      "2024-12-08 11:56:00,227 - src.data.data_loader - INFO - Training set size: 5390 samples\n",
      "2024-12-08 11:56:00,228 - src.data.data_loader - INFO - Test set size: 2310 samples\n",
      "2024-12-08 11:56:00,229 - src.data.data_loader - INFO - Training distribution: {0: 0.49443413729128016, 2: 0.3901669758812616, 1: 0.11539888682745826}\n",
      "2024-12-08 11:56:00,230 - src.data.data_loader - INFO - Test distribution: {0: 0.49437229437229435, 2: 0.3904761904761905, 1: 0.11515151515151516}\n",
      "2024-12-08 11:56:00,232 - src.data.data_loader - INFO - Using 5390 valid samples after NaN removal\n",
      "2024-12-08 11:56:00,234 - src.data.data_loader - INFO - Using 2310 valid samples after NaN removal\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "file_path = os.path.join(config.DATA_DIR, 'raw', f'{language}_social_media.csv')\n",
    "df = data_loader.load_data(file_path)\n",
    "\n",
    "# Hiển thị thông tin cơ bản\n",
    "print(\"Dataset Info:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(\"\\nClass distribution:\")\n",
    "\n",
    "# checking if labels is exists in the dataset\n",
    "if 'label' in df.columns:\n",
    "    print(df['label'].value_counts())\n",
    "else:\n",
    "    print(\"No label column found in the dataset\")\n",
    "\n",
    "# Preprocess data\n",
    "processed_df = preprocessor.preprocess(df)\n",
    "\n",
    "# Save processed data to file\n",
    "processed_data_path = os.path.join(config.DATA_DIR, 'processed', f'{language}_processed.csv')\n",
    "preprocessor.save_processed_data(processed_df, processed_data_path)\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = data_loader.split_data(processed_df)\n",
    "\n",
    "# Get features and labels\n",
    "X_train, y_train = data_loader.get_features_and_labels(train_df)\n",
    "X_test, y_test = data_loader.get_features_and_labels(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Phân tích Dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Phân tích độ dài văn bản\n",
    "plt.figure(figsize=(10, 5))\n",
    "text_lengths = processed_df['cleaned_text'].str.len()\n",
    "sns.histplot(text_lengths)\n",
    "plt.title('Text Length Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Phân tích phân phối nhãn\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=processed_df, x='label')\n",
    "plt.title('Label Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word features shape: (5390, 2000)\n",
      "Char features shape: (5390, 500)\n",
      "Tfidf features shape: (5390, 2000)\n",
      "Linguistic features shape: (5390, 6)\n",
      "Emotion features shape: (5390, 15)\n",
      "All features shape after hstack: (5390, 4521)\n",
      "Word features shape: (2310, 2000)\n",
      "Char features shape: (2310, 500)\n",
      "Tfidf features shape: (2310, 2000)\n",
      "Linguistic features shape: (2310, 6)\n",
      "Emotion features shape: (2310, 15)\n",
      "All features shape after hstack: (2310, 4521)\n",
      "Feature shapes:\n",
      "Training features: (5390, 4521)\n",
      "Testing features: (2310, 4521)\n"
     ]
    }
   ],
   "source": [
    "# Extract features\n",
    "X_train_features = feature_extractor.extract_features(X_train)\n",
    "X_test_features = feature_extractor.extract_features(X_test)\n",
    "\n",
    "print(\"Feature shapes:\")\n",
    "print(f\"Training features: {X_train_features.shape}\")\n",
    "print(f\"Testing features: {X_test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-08 11:56:02,366 - src.models.model_trainer - INFO - Starting model training...\n",
      "Word features shape: (5390, 2000)\n",
      "Char features shape: (5390, 500)\n",
      "Tfidf features shape: (5390, 2000)\n",
      "Linguistic features shape: (5390, 6)\n",
      "Emotion features shape: (5390, 15)\n",
      "All features shape after hstack: (5390, 4521)\n",
      "Word features shape: (5390, 2000)\n",
      "Char features shape: (5390, 500)\n",
      "Tfidf features shape: (5390, 2000)\n",
      "Linguistic features shape: (5390, 6)\n",
      "Emotion features shape: (5390, 15)\n",
      "All features shape after hstack: (5390, 4521)\n",
      "2024-12-08 11:56:04,665 - src.models.model_trainer - INFO - \n",
      "Training rf model...\n",
      "2024-12-08 11:56:29,658 - src.models.model_trainer - INFO - Fold 1/10 - Train: 0.7670, Val: 0.7466\n",
      "2024-12-08 11:56:55,850 - src.models.model_trainer - INFO - Fold 2/10 - Train: 0.7712, Val: 0.6914\n",
      "2024-12-08 11:57:24,608 - src.models.model_trainer - INFO - Fold 3/10 - Train: 0.7704, Val: 0.7258\n",
      "2024-12-08 11:57:55,553 - src.models.model_trainer - INFO - Fold 4/10 - Train: 0.7670, Val: 0.6967\n",
      "2024-12-08 11:58:25,342 - src.models.model_trainer - INFO - Fold 5/10 - Train: 0.7714, Val: 0.6816\n",
      "2024-12-08 11:58:49,039 - src.models.model_trainer - INFO - Fold 6/10 - Train: 0.7767, Val: 0.6557\n",
      "2024-12-08 11:58:49,040 - src.models.model_trainer - INFO - Early stopping triggered at fold 6\n",
      "2024-12-08 11:59:15,302 - src.models.model_trainer - INFO - rf Final Scores:\n",
      "Best validation score: 0.7466\n",
      "Final training score: 0.7767\n",
      "2024-12-08 11:59:15,304 - src.models.model_trainer - INFO - \n",
      "Training svm model...\n",
      "2024-12-08 11:59:16,141 - src.models.model_trainer - INFO - Fold 1/10 - Train: 0.9317, Val: 0.7045\n",
      "2024-12-08 11:59:16,942 - src.models.model_trainer - INFO - Fold 2/10 - Train: 0.9331, Val: 0.6812\n",
      "2024-12-08 11:59:17,660 - src.models.model_trainer - INFO - Fold 3/10 - Train: 0.9342, Val: 0.6856\n",
      "2024-12-08 11:59:18,412 - src.models.model_trainer - INFO - Fold 4/10 - Train: 0.9370, Val: 0.6736\n",
      "2024-12-08 11:59:19,142 - src.models.model_trainer - INFO - Fold 5/10 - Train: 0.9334, Val: 0.6683\n",
      "2024-12-08 11:59:19,967 - src.models.model_trainer - INFO - Fold 6/10 - Train: 0.9380, Val: 0.6772\n",
      "2024-12-08 11:59:19,970 - src.models.model_trainer - INFO - Early stopping triggered at fold 6\n",
      "2024-12-08 11:59:20,531 - src.models.model_trainer - INFO - svm Final Scores:\n",
      "Best validation score: 0.7045\n",
      "Final training score: 0.9380\n",
      "2024-12-08 11:59:20,532 - src.models.model_trainer - INFO - \n",
      "Training nb model...\n",
      "2024-12-08 11:59:20,924 - src.models.model_trainer - INFO - Fold 1/10 - Train: 0.7661, Val: 0.7321\n",
      "2024-12-08 11:59:21,312 - src.models.model_trainer - INFO - Fold 2/10 - Train: 0.7651, Val: 0.6986\n",
      "2024-12-08 11:59:21,719 - src.models.model_trainer - INFO - Fold 3/10 - Train: 0.7663, Val: 0.6871\n",
      "2024-12-08 11:59:22,104 - src.models.model_trainer - INFO - Fold 4/10 - Train: 0.7708, Val: 0.6981\n",
      "2024-12-08 11:59:22,521 - src.models.model_trainer - INFO - Fold 5/10 - Train: 0.7728, Val: 0.7049\n",
      "2024-12-08 11:59:22,932 - src.models.model_trainer - INFO - Fold 6/10 - Train: 0.7678, Val: 0.6793\n",
      "2024-12-08 11:59:22,933 - src.models.model_trainer - INFO - Early stopping triggered at fold 6\n",
      "2024-12-08 11:59:23,163 - src.models.model_trainer - INFO - nb Final Scores:\n",
      "Best validation score: 0.7321\n",
      "Final training score: 0.7678\n",
      "2024-12-08 11:59:23,521 - src.models.model_trainer - INFO - Saved final model to c:\\Users\\tamaisme\\Desktop\\Vietnamese-English-Sentiment-Analysis-System\\data\\models\\vi_sentiment_model.pkl\n",
      "Checkpoint saved at c:\\Users\\tamaisme\\Desktop\\Vietnamese-English-Sentiment-Analysis-System\\data\\checkpoints\\vi_checkpoint.pkl\n",
      "Best model: rf\n",
      "Best score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Train models\n",
    "models = model_trainer.train_with_grid_search(X_train, y_train)\n",
    "\n",
    "# Check if models is not None\n",
    "if models:\n",
    "    # Save checkpoint\n",
    "    checkpoint_path = os.path.join(config.DATA_DIR, 'checkpoints', f'{language}_checkpoint.pkl')\n",
    "    joblib.dump(models, checkpoint_path)\n",
    "    print(f\"Checkpoint saved at {checkpoint_path}\")\n",
    "\n",
    "    # Get best model performance\n",
    "    best_model_name = max(models.items(), key=lambda x: getattr(x[1], 'best_score_', 0))[0]\n",
    "    best_model = models[best_model_name]\n",
    "\n",
    "    print(f\"Best model: {best_model_name}\")\n",
    "    print(f\"Best score: {getattr(best_model, 'best_score_', 0):.4f}\")\n",
    "else:\n",
    "    print(\"No models were trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Đánh giá Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded feature extractor with None dimensions\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78      1142\n",
      "           1       0.23      0.22      0.22       266\n",
      "           2       0.80      0.73      0.76       902\n",
      "\n",
      "    accuracy                           0.71      2310\n",
      "   macro avg       0.59      0.59      0.59      2310\n",
      "weighted avg       0.71      0.71      0.71      2310\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAIQCAYAAADnzpi9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAABM+ElEQVR4nO3deViVdf7/8ddhERAFRFkrl9RUUrPUFNdSlAxLUyvLMTTLFrBR1IwmzdTErLTcp76OOi6VTdli427qmLhEaW6ZpoXbAZcARRaF8/vDn6dugQQV4b57Pua6r6tz359zn/c5F4NvXp/7/hybw+FwCAAAAKbmUtYFAAAA4NrR1AEAAFgATR0AAIAF0NQBAABYAE0dAACABdDUAQAAWABNHQAAgAXQ1AEAAFgATR0AAIAF0NQBFrR//3517txZvr6+stls+uyzz67r+X/55RfZbDbNnTv3up7XzO655x7dc889ZV0GgL8wmjqglPz888965plndOutt8rT01M+Pj5q3bq13n33XWVlZZXqa0dHR2vnzp16/fXXNX/+fDVr1qxUX+9G6tevn2w2m3x8fAr9HPfv3y+bzSabzaa33nqrxOc/duyYRo8ere3bt1+HagHgxnEr6wIAK/rqq6/08MMPy8PDQ0888YQaNmyo3Nxcbdy4UcOHD9fu3bv13nvvlcprZ2VlKTExUf/4xz8UGxtbKq9Ro0YNZWVlyd3dvVTOfyVubm46d+6cvvzySz3yyCOGYwsXLpSnp6eys7Ov6tzHjh3Ta6+9ppo1a6pJkybFft7KlSuv6vUA4HqhqQOus0OHDql3796qUaOG1q5dq5CQEOexmJgYHThwQF999VWpvf6JEyckSX5+fqX2GjabTZ6enqV2/ivx8PBQ69at9cEHHxRo6hYtWqSoqCh98sknN6SWc+fOqWLFiqpQocINeT0AKArTr8B1NnHiRJ09e1azZ882NHSX1KlTR3//+9+djy9cuKCxY8eqdu3a8vDwUM2aNfXyyy8rJyfH8LyaNWuqa9eu2rhxo+6++255enrq1ltv1b///W/nmNGjR6tGjRqSpOHDh8tms6lmzZqSLk5bXvrvPxo9erRsNpth36pVq9SmTRv5+fmpUqVKqlevnl5++WXn8aKuqVu7dq3atm0rb29v+fn5qVu3btq7d2+hr3fgwAH169dPfn5+8vX1Vf/+/XXu3LmiP9jLPP7441q2bJnS0tKc+7Zt26b9+/fr8ccfLzD+9OnTGjZsmBo1aqRKlSrJx8dHXbp00Y4dO5xj1q1bp+bNm0uS+vfv75zGvfQ+77nnHjVs2FBJSUlq166dKlas6PxcLr+mLjo6Wp6engXef2RkpKpUqaJjx44V+70CQHHQ1AHX2Zdffqlbb71VrVq1Ktb4p556SqNGjdJdd92lyZMnq3379kpISFDv3r0LjD1w4IB69eqlTp066e2331aVKlXUr18/7d69W5LUo0cPTZ48WZL02GOPaf78+XrnnXdKVP/u3bvVtWtX5eTkaMyYMXr77bf14IMP6ptvvvnT561evVqRkZFKTU3V6NGjFRcXp02bNql169b65ZdfCox/5JFHdObMGSUkJOiRRx7R3Llz9dprrxW7zh49eshms+nTTz917lu0aJHq16+vu+66q8D4gwcP6rPPPlPXrl01adIkDR8+XDt37lT79u2dDVaDBg00ZswYSdLAgQM1f/58zZ8/X+3atXOe59SpU+rSpYuaNGmid955R/fee2+h9b377rsKCAhQdHS08vLyJEn//Oc/tXLlSk2dOlWhoaHFfq8AUCwOANdNenq6Q5KjW7duxRq/fft2hyTHU089Zdg/bNgwhyTH2rVrnftq1KjhkOTYsGGDc19qaqrDw8PDMXToUOe+Q4cOOSQ53nzzTcM5o6OjHTVq1ChQw6uvvur446+CyZMnOyQ5Tpw4UWTdl15jzpw5zn1NmjRxBAYGOk6dOuXct2PHDoeLi4vjiSeeKPB6Tz75pOGcDz30kKNq1apFvuYf34e3t7fD4XA4evXq5ejYsaPD4XA48vLyHMHBwY7XXnut0M8gOzvbkZeXV+B9eHh4OMaMGePct23btgLv7ZL27ds7JDlmzZpV6LH27dsb9q1YscIhyTFu3DjHwYMHHZUqVXJ07979iu8RAK4GSR1wHWVkZEiSKleuXKzx//3vfyVJcXFxhv1Dhw6VpALX3oWFhalt27bOxwEBAapXr54OHjx41TVf7tK1eJ9//rny8/OL9Zzjx49r+/bt6tevn/z9/Z37GzdurE6dOjnf5x89++yzhsdt27bVqVOnnJ9hcTz++ONat26d7Ha71q5dK7vdXujUq3TxOjwXl4u/8vLy8nTq1Cnn1PJ3331X7Nf08PBQ//79izW2c+fOeuaZZzRmzBj16NFDnp6e+uc//1ns1wKAkqCpA64jHx8fSdKZM2eKNf7XX3+Vi4uL6tSpY9gfHBwsPz8//frrr4b91atXL3COKlWq6LfffrvKigt69NFH1bp1az311FMKCgpS7969tXjx4j9t8C7VWa9evQLHGjRooJMnTyozM9Ow//L3UqVKFUkq0Xu5//77VblyZX300UdauHChmjdvXuCzvCQ/P1+TJ09W3bp15eHhoWrVqikgIEA//PCD0tPTi/2aN910U4luinjrrbfk7++v7du3a8qUKQoMDCz2cwGgJGjqgOvIx8dHoaGh2rVrV4med/mNCkVxdXUtdL/D4bjq17h0vdclXl5e2rBhg1avXq2+ffvqhx9+0KOPPqpOnToVGHstruW9XOLh4aEePXpo3rx5WrJkSZEpnSSNHz9ecXFxateunRYsWKAVK1Zo1apVuv3224udSEoXP5+S+P7775WamipJ2rlzZ4meCwAlQVMHXGddu3bVzz//rMTExCuOrVGjhvLz87V//37D/pSUFKWlpTnvZL0eqlSpYrhT9JLL00BJcnFxUceOHTVp0iTt2bNHr7/+utauXauvv/660HNfqnPfvn0Fjv3444+qVq2avL29r+0NFOHxxx/X999/rzNnzhR6c8kl//nPf3Tvvfdq9uzZ6t27tzp37qyIiIgCn0lxG+ziyMzMVP/+/RUWFqaBAwdq4sSJ2rZt23U7PwD8EU0dcJ29+OKL8vb21lNPPaWUlJQCx3/++We9++67ki5OH0oqcIfqpEmTJElRUVHXra7atWsrPT1dP/zwg3Pf8ePHtWTJEsO406dPF3jupUV4L19m5ZKQkBA1adJE8+bNMzRJu3bt0sqVK53vszTce++9Gjt2rKZNm6bg4OAix7m6uhZIAT/++GMdPXrUsO9S81lYA1xSI0aMUHJysubNm6dJkyapZs2aio6OLvJzBIBrweLDwHVWu3ZtLVq0SI8++qgaNGhg+EaJTZs26eOPP1a/fv0kSXfccYeio6P13nvvKS0tTe3bt9fWrVs1b948de/evcjlMq5G7969NWLECD300EN64YUXdO7cOc2cOVO33Xab4UaBMWPGaMOGDYqKilKNGjWUmpqqGTNm6Oabb1abNm2KPP+bb76pLl26KDw8XAMGDFBWVpamTp0qX19fjR49+rq9j8u5uLjolVdeueK4rl27asyYMerfv79atWqlnTt3auHChbr11lsN42rXri0/Pz/NmjVLlStXlre3t1q0aKFatWqVqK61a9dqxowZevXVV51LrMyZM0f33HOPRo4cqYkTJ5bofABwRWV89y1gWT/99JPj6aefdtSsWdNRoUIFR+XKlR2tW7d2TJ061ZGdne0cd/78ecdrr73mqFWrlsPd3d1xyy23OOLj4w1jHI6LS5pERUUVeJ3Ll9IoakkTh8PhWLlypaNhw4aOChUqOOrVq+dYsGBBgSVN1qxZ4+jWrZsjNDTUUaFCBUdoaKjjsccec/z0008FXuPyZT9Wr17taN26tcPLy8vh4+PjeOCBBxx79uwxjLn0epcvmTJnzhyHJMehQ4eK/EwdDuOSJkUpakmToUOHOkJCQhxeXl6O1q1bOxITEwtdiuTzzz93hIWFOdzc3Azvs3379o7bb7+90Nf843kyMjIcNWrUcNx1112O8+fPG8YNGTLE4eLi4khMTPzT9wAAJWVzOEpwVTIAAADKJa6pAwAAsACaOgAAAAugqQMAALAAmjoAAAALoKkDAACwAJo6AAAAC6CpAwAAsIBy840SXnfGlnUJgEHyhnfKugTAwM31+n0vLXC9VKnoWmavXZq9Q9b300rt3KWFpA4AAMACyk1SBwAAUCI2sqk/4tMAAACwAJI6AABgTjauM/0jkjoAAAALIKkDAADmxDV1BjR1AADAnJh+NaDFBQAAsACSOgAAYE5MvxrwaQAAAFyDM2fOaPDgwapRo4a8vLzUqlUrbdu2zXnc4XBo1KhRCgkJkZeXlyIiIrR//37DOU6fPq0+ffrIx8dHfn5+GjBggM6ePVuiOmjqAACAOdlspbeVwFNPPaVVq1Zp/vz52rlzpzp37qyIiAgdPXpUkjRx4kRNmTJFs2bN0pYtW+Tt7a3IyEhlZ2c7z9GnTx/t3r1bq1at0tKlS7VhwwYNHDiwZB+Hw+FwlOgZpYTvfkV5w3e/orzhu19RHpXpd7+2GF5q587a8mbxxmVlqXLlyvr8888VFRXl3N+0aVN16dJFY8eOVWhoqIYOHaphw4ZJktLT0xUUFKS5c+eqd+/e2rt3r8LCwrRt2zY1a9ZMkrR8+XLdf//9OnLkiEJDQ4tVC0kdAAAwJ5tL6W3FdOHCBeXl5cnT09Ow38vLSxs3btShQ4dkt9sVERHhPObr66sWLVooMTFRkpSYmCg/Pz9nQydJERERcnFx0ZYtW4pdC00dAADAZXJycpSRkWHYcnJyCoyrXLmywsPDNXbsWB07dkx5eXlasGCBEhMTdfz4cdntdklSUFCQ4XlBQUHOY3a7XYGBgYbjbm5u8vf3d44pDpo6AABgTqV4TV1CQoJ8fX0NW0JCQqFlzJ8/Xw6HQzfddJM8PDw0ZcoUPfbYY3JxubFtFk0dAADAZeLj45Wenm7Y4uPjCx1bu3ZtrV+/XmfPntXhw4e1detWnT9/XrfeequCg4MlSSkpKYbnpKSkOI8FBwcrNTXVcPzChQs6ffq0c0xx0NQBAABzKsVr6jw8POTj42PYPDw8/rQcb29vhYSE6LffftOKFSvUrVs31apVS8HBwVqzZo1zXEZGhrZs2aLw8HBJUnh4uNLS0pSUlOQcs3btWuXn56tFixbF/jhYfBgAAJhTOfmasBUrVsjhcKhevXo6cOCAhg8frvr166t///6y2WwaPHiwxo0bp7p166pWrVoaOXKkQkND1b17d0lSgwYNdN999+npp5/WrFmzdP78ecXGxqp3797FvvNVoqkDAAC4JpemZo8cOSJ/f3/17NlTr7/+utzd3SVJL774ojIzMzVw4EClpaWpTZs2Wr58ueGO2YULFyo2NlYdO3aUi4uLevbsqSlTppSoDtapA4rAOnUob1inDuVRma5T12ZkqZ07a+PYUjt3aeGaOgAAAAtg+hUAAJhTObmmrrwgqQMAALAAkjoAAGBOJfg6r78CPg0AAAALIKkDAADmRFJnQFMHAADMyYUbJf6IFhcAAMACSOoAAIA5Mf1qwKcBAABgASR1AADAnFh82ICkDgAAwAJI6gAAgDlxTZ0BnwYAAIAFkNQBAABz4po6A5o6AABgTky/GvBpAAAAWABJHQAAMCemXw1I6gAAACyApA4AAJgT19QZ8GkAAABYAEkdAAAwJ66pMyCpAwAAsACSOgAAYE5cU2dAUwcAAMyJ6VcDWlwAAAALIKkDAADmxPSrAZ8GAACABZDUAQAAcyKpM+DTAAAAsACSOgAAYE7c/WpAUgcAAGABJHUAAMCcuKbOgKYOAACYE9OvBrS4AAAAFkBSBwAAzInpVwM+DQAAAAsgqQMAAObENXUGJHUAAAAWQFIHAABMyUZSZ0BSBwAAYAEkdQAAwJRI6oxI6gAAgDnZSnErgby8PI0cOVK1atWSl5eXateurbFjx8rhcDjHOBwOjRo1SiEhIfLy8lJERIT2799vOM/p06fVp08f+fj4yM/PTwMGDNDZs2eLXQdNHQAAwDV44403NHPmTE2bNk179+7VG2+8oYkTJ2rq1KnOMRMnTtSUKVM0a9YsbdmyRd7e3oqMjFR2drZzTJ8+fbR7926tWrVKS5cu1YYNGzRw4MBi12Fz/LGNLENed8aWdQmAQfKGd8q6BMDAzZWpJpQ/VSq6ltlrV3pkbqmd++zifsUe27VrVwUFBWn27NnOfT179pSXl5cWLFggh8Oh0NBQDR06VMOGDZMkpaenKygoSHPnzlXv3r21d+9ehYWFadu2bWrWrJkkafny5br//vt15MgRhYaGXrEOkjoAAIBr0KpVK61Zs0Y//fSTJGnHjh3auHGjunTpIkk6dOiQ7Ha7IiIinM/x9fVVixYtlJiYKElKTEyUn5+fs6GTpIiICLm4uGjLli3FqoMbJQAAgCmV5o0SOTk5ysnJMezz8PCQh4dHgbEvvfSSMjIyVL9+fbm6uiovL0+vv/66+vTpI0my2+2SpKCgIMPzgoKCnMfsdrsCAwMNx93c3OTv7+8ccyUkdQAAAJdJSEiQr6+vYUtISCh07OLFi7Vw4UItWrRI3333nebNm6e33npL8+bNu6E1k9QBAABTKs2kLj4+XnFxcYZ9haV0kjR8+HC99NJL6t27tySpUaNG+vXXX5WQkKDo6GgFBwdLklJSUhQSEuJ8XkpKipo0aSJJCg4OVmpqquG8Fy5c0OnTp53PvxKSOgAAgMt4eHjIx8fHsBXV1J07d04uLsaWytXVVfn5+ZKkWrVqKTg4WGvWrHEez8jI0JYtWxQeHi5JCg8PV1pampKSkpxj1q5dq/z8fLVo0aJYNZPUmUClih569fmuerDDHQqoUkk79h3RsIn/UdKeZLm5uWj08w8oss3tqnVzVWWczdbaLT9q5JQvdPxEuiSpbdO6Wvl/fy/03G36TFTSnuQb+XZgAdu/+1aL5v9L+/bu0amTJzT+rSlqd09H5/H1a1fps08Wa9+Pu5WRnq45C/+juvUaGM5x6uQJzXj3bW3buknnMs+peo2aeuLJgbqnY+cb/XZgUZmZmXpvxhStX7tav/12WrfVa6AhL8Yr7PZGkqSWd4YV+rzYwUP1t+gBN7JUXKXysvjwAw88oNdff13Vq1fX7bffru+//16TJk3Sk08+KelinYMHD9a4ceNUt25d1apVSyNHjlRoaKi6d+8uSWrQoIHuu+8+Pf3005o1a5bOnz+v2NhY9e7du1h3vko0daYwc9TjCqsTqidfmafjJ9L12P1366tZg3RXz3E6m5WjJg1u0YT3l+mHn46qik9FvTW8lz5+5xm16TNRkrR5x0HVjIg3nHPU81117931aOhwVbKyslSnbj1FPdhD/xhe8A+GrKwsNW5ypzp0itQb414t9BzjXn1ZZ89kaMLb0+TrV0Wrln+lUfFD9X//Xqzb6jco9DlASYwfM1IHD+zXq+PeULWAAC3/75ca9OwAffDJlwoMDNJXq9Ybxid+8z+9/tpI3csfFuZRPno6TZ06VSNHjtTzzz+v1NRUhYaG6plnntGoUaOcY1588UVlZmZq4MCBSktLU5s2bbR8+XJ5eno6xyxcuFCxsbHq2LGjXFxc1LNnT02ZMqXYdbBOXTnn6eGuExvf0sND3tPyjbud+79Z+KJWfrNHr81YWuA5TcOqa+PCF3Vbl5E6bP+twHE3Nxf9vOJ1zfxwvSa8v7xU6zcz1qkrnjbNbi+Q1F1y/NhRPfxg50KTuk5tm2noS6N0X9SDzn33d2yl5wbF6YHuvUq9bjNinbriy87OVsc2zTVx8jS1btveuT/68V4Kb91Wz8YU/GPkxSGxOncuU9P+OedGlmp6ZblOne/j80vt3OmL+pbauUsL19SVc26uLnJzc1V27nnD/uyc82p1Z+1Cn+NT2Uv5+flKO5NV6PGu7Rurqq+35n+++brXCxRXw8Z3au2q5cpIT1N+fr5Wr/ivcnNydWfT5mVdGiwgLy9PeXl5qlChgmG/h4endnz/XYHxp06d1DcbN+iB7j1vVIm4Dmw2W6ltZlTi6deTJ0/qX//6lxITE53rpgQHB6tVq1bq16+fAgICrnuRf2Vnz+Vo846Din+6i/YdSlHKqQw9cl8ztWhcSz8fPlFgvEcFN417oZsWL0/SmczsQs4oRXcP16rEvTqamlbK1QNFGzPhbb0aP1T3d2wtV1c3eXp6avxb7+rmW2qUdWmwAG9vbzVq3ET/en+WataqLf+qVbVy+Vfa9cN23XxL9QLj//vl5/KuWFH3dOhUBtUC10eJkrpt27bptttu05QpU+Tr66t27dqpXbt28vX11ZQpU1S/fn19++23VzxPTk6OMjIyDJsjP++q34TVPfnKv2WzSQdXvq70Le8o5rH2Wrz8W+XnG2fO3dxctGDiANlsNr0w/qNCz3VToJ86hTfQvM8Sb0TpQJH+b+ZUnTlzRu/MmK3/m/+RHu0TrVEvDdXPB34q69JgEa+OmyA5HHog8h61a9FEH3+wUJ3uu182l4L/9C39/FN17tK1yLsbUT6R1BmVKKkbNGiQHn74Yc2aNavAG3Y4HHr22Wc1aNAg51deFCUhIUGvvfaaYZ9rUHO5h9xdknL+Mg4dOanOT72rip4V5FPJU/aTGZo/ob8OHT3pHOPm5qKFbwxQ9ZAq6jJwapEpXd9uLXUqPVNL1/9wo8oHCjh6JFmfLF6kf3/0uW6tXUeSVPe2+tqxPUmfLv5Aw18u/OYKoCRuvqW6Zs7+t7KyzinzbKaqBQToHyPidNNNNxvGbf/uW/36yyGNm/B2GVUKXB8lSup27NihIUOGFNrB2mw2DRkyRNu3b7/ieeLj45Wenm7Y3IKalqSUv6Rz2bmyn8yQX2UvRbRqoKXrdkr6vaGrXT1AUc9O0+n0zCLP8cSDLbVo6VZduJB/o8oGCsjOvvhHh4uL8XeJq4uL8h38bOL68vKqqGoBAcrISNeWTd+o3T0dDMe/+OxT1W9wu+rWq19GFeJqkdQZlSipCw4O1tatW1W/fuE/+Fu3bi3wvWaFKey702wuZXf3THkXEd5ANpv00y+pqn1LgMYP6a6fDqXo318kys3NRYvefEp31r9FPf4+S64uNgVVrSxJOp1+Tucv/D6tfc/dt6nWzdU0Z8mmsnorsIhz5zJ19PDvy+EcP3pE+/ftVWVfXwUHhyojPU0p9uM6eeLidZ/Jv/4iSfKvWk1VqwWoRs1auvmW6npz/GuK+fsw+fr5acO6tdq2JVETJ88oi7cEC9q8aaMcDodq1Kylw4eTNW3ym6pRq5a6PviQc0zm2bNau2qFXogbXoaVAtdHiZq6YcOGaeDAgUpKSlLHjh2dDVxKSorWrFmj999/X2+99VapFPpX5lvJU2MGPaibgvx0Ov2cPl+zXa9O/1IXLuSreoi/HrinsSRp60fGteg6P/Wu/pe03/m4X/dWStz+s376JeWG1g/r+XHPbr3wbH/n46mTL66J2KVrN/1j9Hht3PC1xr/2ivP4qy8PkyT1f/p5DXgmRm5u7nrz3VmaNXWSRsTFKuvcOd10yy36x+jxCm/T7sa+GVjW2bNnNHPqO0pNscvH11f3duysZ2P+Ljd3d+eYVSv+K4cc6nxfVBlWiqtl1kSttJR4nbqPPvpIkydPVlJSkvLyLqZArq6uatq0qeLi4vTII49cVSGsU4fyhnXqUN6wTh3Ko7Jcp65q9Aeldu5T8x4rtXOXlhIvafLoo4/q0Ucf1fnz53Xy5MUL9atVqyb3P/zlAwAAgBvrqr8mzN3dXSEhIdezFgAAgGJj+tWIb5QAAACwgKtO6gAAAMoSSZ0RSR0AAIAFkNQBAABTIqkzIqkDAACwAJI6AABgTgR1BiR1AAAAFkBSBwAATIlr6oxo6gAAgCnR1Bkx/QoAAGABJHUAAMCUSOqMSOoAAAAsgKQOAACYEkmdEUkdAACABZDUAQAAcyKoMyCpAwAAsACSOgAAYEpcU2dEUwcAAEyJps6I6VcAAAALIKkDAACmRFJnRFIHAABgASR1AADAnAjqDEjqAAAALICkDgAAmBLX1BmR1AEAAFgASR0AADAlkjojmjoAAGBKNHVGTL8CAABYAEkdAAAwJZI6I5I6AAAACyCpAwAA5kRQZ0BSBwAAYAEkdQAAwJS4ps6IpA4AAOAa1KxZUzabrcAWExMjScrOzlZMTIyqVq2qSpUqqWfPnkpJSTGcIzk5WVFRUapYsaICAwM1fPhwXbhwoUR1kNQBAABTKi9J3bZt25SXl+d8vGvXLnXq1EkPP/ywJGnIkCH66quv9PHHH8vX11exsbHq0aOHvvnmG0lSXl6eoqKiFBwcrE2bNun48eN64okn5O7urvHjxxe7DpvD4XBc37d2dbzujC3rEgCD5A3vlHUJgIGba/n4Bwz4oyoVXcvstesMW1Zq5z7wVperfu7gwYO1dOlS7d+/XxkZGQoICNCiRYvUq1cvSdKPP/6oBg0aKDExUS1bttSyZcvUtWtXHTt2TEFBQZKkWbNmacSIETpx4oQqVKhQrNdl+hUAAOAyOTk5ysjIMGw5OTlXfF5ubq4WLFigJ598UjabTUlJSTp//rwiIiKcY+rXr6/q1asrMTFRkpSYmKhGjRo5GzpJioyMVEZGhnbv3l3smmnqAACAKRV2Hdv12hISEuTr62vYEhISrljTZ599prS0NPXr10+SZLfbVaFCBfn5+RnGBQUFyW63O8f8saG7dPzSseLimjoAAIDLxMfHKy4uzrDPw8Pjis+bPXu2unTpotDQ0NIqrUg0dQAAwJRK8z4JDw+PYjVxf/Trr79q9erV+vTTT537goODlZubq7S0NENal5KSouDgYOeYrVu3Gs516e7YS2OKg+lXAACA62DOnDkKDAxUVFSUc1/Tpk3l7u6uNWvWOPft27dPycnJCg8PlySFh4dr586dSk1NdY5ZtWqVfHx8FBYWVuzXJ6kDAACmVF6WNJGk/Px8zZkzR9HR0XJz+7298vX11YABAxQXFyd/f3/5+Pho0KBBCg8PV8uWLSVJnTt3VlhYmPr27auJEyfKbrfrlVdeUUxMTInSQpo6AACAa7R69WolJyfrySefLHBs8uTJcnFxUc+ePZWTk6PIyEjNmDHDedzV1VVLly7Vc889p/DwcHl7eys6OlpjxowpUQ2sUwcUgXXqUN6wTh3Ko7Jcp67+SytK7dw/TogstXOXFpI6AABgSi4u/KHzR9woAQAAYAEkdQAAwJTK0X0S5QJJHQAAgAWQ1AEAAFMqT0ualAckdQAAABZAUgcAAEyJoM6IpA4AAMACSOoAAIApcU2dEU0dAAAwJZo6I6ZfAQAALICkDgAAmBJBnRFJHQAAgAWQ1AEAAFPimjojkjoAAAALIKkDAACmRFBnRFIHAABgASR1AADAlLimzoimDgAAmBI9nRHTrwAAABZAUgcAAEyJ6VcjkjoAAAALIKkDAACmRFBnRFIHAABgASR1AADAlLimzoikDgAAwALKTVK3f+2ksi4BMKjsVW7+7wFIkhyOsq4AKF8I6oz4VwsAAJgS069GTL8CAABYAEkdAAAwJYI6I5I6AAAACyCpAwAApsQ1dUYkdQAAABZAUgcAAEyJoM6IpA4AAMACSOoAAIApcU2dEUkdAACABZDUAQAAUyKpM6KpAwAApkRPZ8T0KwAAgAWQ1AEAAFNi+tWIpA4AAMACaOoAAIAp2Wylt5XU0aNH9be//U1Vq1aVl5eXGjVqpG+//dZ53OFwaNSoUQoJCZGXl5ciIiK0f/9+wzlOnz6tPn36yMfHR35+fhowYIDOnj1b7Bpo6gAAAK7Bb7/9ptatW8vd3V3Lli3Tnj179Pbbb6tKlSrOMRMnTtSUKVM0a9YsbdmyRd7e3oqMjFR2drZzTJ8+fbR7926tWrVKS5cu1YYNGzRw4MBi12FzOByO6/rOrtKR33LLugTAoFrlCmVdAmBQPn5bA0Ze7mX32h2mJJbaude+EF7ssS+99JK++eYb/e9//yv0uMPhUGhoqIYOHaphw4ZJktLT0xUUFKS5c+eqd+/e2rt3r8LCwrRt2zY1a9ZMkrR8+XLdf//9OnLkiEJDQ69YB0kdAADAZXJycpSRkWHYcnJyCh37xRdfqFmzZnr44YcVGBioO++8U++//77z+KFDh2S32xUREeHc5+vrqxYtWigx8WJjmpiYKD8/P2dDJ0kRERFycXHRli1bilUzTR0AADCl0rymLiEhQb6+voYtISGh0DoOHjyomTNnqm7dulqxYoWee+45vfDCC5o3b54kyW63S5KCgoIMzwsKCnIes9vtCgwMNBx3c3OTv7+/c8yVsKQJAAAwJZdSXNIkPj5ecXFxhn0eHh6Fjs3Pz1ezZs00fvx4SdKdd96pXbt2adasWYqOji61Gi9HUgcAAHAZDw8P+fj4GLaimrqQkBCFhYUZ9jVo0EDJycmSpODgYElSSkqKYUxKSorzWHBwsFJTUw3HL1y4oNOnTzvHXAlNHQAAMKXysqRJ69attW/fPsO+n376STVq1JAk1apVS8HBwVqzZo3zeEZGhrZs2aLw8Is3ZISHhystLU1JSUnOMWvXrlV+fr5atGhRrDqYfgUAALgGQ4YMUatWrTR+/Hg98sgj2rp1q9577z299957ki5+88XgwYM1btw41a1bV7Vq1dLIkSMVGhqq7t27S7qY7N133316+umnNWvWLJ0/f16xsbHq3bt3se58lWjqAACASZWXrwlr3ry5lixZovj4eI0ZM0a1atXSO++8oz59+jjHvPjii8rMzNTAgQOVlpamNm3aaPny5fL09HSOWbhwoWJjY9WxY0e5uLioZ8+emjJlSrHrYJ06oAisU4fypnz8tgaMynKdusgZxVvq42qseL54U57lCUkdAAAwJZfyEdSVG9woAQAAYAEkdQAAwJTKyzV15QVNHQAAMCV6OiOmXwEAACyApA4AAJiSTUR1f0RSBwAAYAEkdQAAwJRY0sSIpA4AAMACSOoAAIApsaSJEUkdAACABZDUAQAAUyKoM6KpAwAApuRCV2fA9CsAAIAFkNQBAABTIqgzIqkDAACwAJI6AABgSixpYkRSBwAAYAEkdQAAwJQI6oxI6gAAACyApA4AAJgS69QZ0dQBAABToqUzYvoVAADAAkjqAACAKbGkiRFJHQAAgAWQ1AEAAFNyIagzIKkDAACwAJI6AABgSlxTZ0RSBwAAYAEkdQAAwJQI6oxo6gAAgCkx/WrE9CsAAIAFkNQBAABTYkkTI5I6AAAACyCpAwAApsQ1dUYkdQAAABZAUgcAAEyJnM6IpA4AAMACSOoAAIApuXBNnQFNHQAAMCV6OiOmXwEAACyApA4AAJgSS5oYkdQBAABcg9GjR8tmsxm2+vXrO49nZ2crJiZGVatWVaVKldSzZ0+lpKQYzpGcnKyoqChVrFhRgYGBGj58uC5cuFCiOkjqAACAKZWnoO7222/X6tWrnY/d3H5vsYYMGaKvvvpKH3/8sXx9fRUbG6sePXrom2++kSTl5eUpKipKwcHB2rRpk44fP64nnnhC7u7uGj9+fLFrIKkzgR++/1b/GBqrR7p2UMeWjbRx/Zoix05+Y4w6tmykTz6cX+jx3NxcDezbSx1bNtKBn34srZLxFzNz+lTdcXs9w9at633O4ydPnNDLLw1Xh3at1aJZEz3a6yGtXrmiDCvGX0FKSopeHjFM7Vu3UIumjdXroQe0e9fOQseOe22UmjSspwXz597YImEZbm5uCg4Odm7VqlWTJKWnp2v27NmaNGmSOnTooKZNm2rOnDnatGmTNm/eLElauXKl9uzZowULFqhJkybq0qWLxo4dq+nTpys3N7fYNdDUmUBWVpZq171NLwz7x5+O27hujfbu+kFVAwKLHPPetEmqWi3gepcIqHadulqzbqNzmzt/kfPYP14eoV8OHdK702bqkyVfqmNEJw0fOlh79+4pw4phZRnp6erX9zG5ubtr2qz39ennXylu2Aj5+PgWGLt29Sr98MMOBQQW/bsT5ZOLzVZqW05OjjIyMgxbTk5OkbXs379foaGhuvXWW9WnTx8lJydLkpKSknT+/HlFREQ4x9avX1/Vq1dXYmKiJCkxMVGNGjVSUFCQc0xkZKQyMjK0e/fu4n8eJf0AceO1aNVWTz77gtrc07HIMSdSUzT17fF6+bUJcnMtfFZ9y6b/KWnLJj3zwrDSKhV/YW6urqoWEODcqlTxdx7b8f33eqzP39SocWPdfMstGvjs86pc2Ud7S/DLCiiJOf96X8HBwRozLkGNGjXWTTffolat2+iW6tUN41JSUjQhYazGv/GW3Nzcy6halEcJCQny9fU1bAkJCYWObdGihebOnavly5dr5syZOnTokNq2baszZ87IbrerQoUK8vPzMzwnKChIdrtdkmS32w0N3aXjl44VF9fUWUB+fr4mvPayHvlbf9W8tU6hY06fOqlJCaM1ZuIUeXp43uAK8Vfwa/KvirinjSp4eOiOO5rohcFDFRIaKkm64847tWL5MrVrd48q+/hoxfJlysnNUbPmd5dx1bCq9V+vVXjrNhoW94KSvt2mwMAgPdL7cfXs9YhzTH5+vl6JH67ofgNUp07dMqwWV6s0r6mLj49XXFycYZ+Hh0ehY7t06eL878aNG6tFixaqUaOGFi9eLC8vr9Ir8jI0dRbw4fx/ydXVVT0e6VPocYfDoYljX9EDDz2ieg1ul/3Y0RtcIayuUePGGvt6gmrWrKUTJ07onzOnq/8TffTJ51/K27uS3nz7Hb04dIjatW4hNzc3eXp6avK701S9Ro2yLh0WdeTIYX380Qf62xP99dTTz2rXrp2amDBO7u7uerDbQ5KkObPfl6urmx7/2xNlXC2uVmkuaeLh4VFkE3clfn5+uu2223TgwAF16tRJubm5SktLM6R1KSkpCg4OliQFBwdr69athnNcujv20pjiuO7Tr4cPH9aTTz75p2NKOk+Nov304259+tECvThyXJE/3EsWL1LWuXN6LPqpG1wd/iratG2vzpFddFu9+mrdpq2mzXxPZ85kaMXyZZKk6VPf1ZkzGXpv9lwt+ugT9Y3urxeHDtb+n/aVceWwqvx8h+o3uF0vDI5T/QZh6vXwo+rR8xH9Z/GHkqQ9u3dp0YJ/a8zrCax1huvu7Nmz+vnnnxUSEqKmTZvK3d1da9b8fpPjvn37lJycrPDwcElSeHi4du7cqdTUVOeYVatWycfHR2FhYcV+3eve1J0+fVrz5s370zGFzVNPnzzxepfyl7Bz+3dK++20HuveWZ1aN1Gn1k2UYj+mWVPe0uPdIyVJ3ydt0Z5dO3Rfu6bq1LqJ+j4cJUl6rn9vTRjz5zdfAFfDx8dHNWrU1OHkZB1OTtaHixbotXHj1aJluOrVr69nn49V2O0N9eEHC8u6VFhUQECAateubdhX69Zbdfz4MUnSd999q9OnT6lLp3vV9I4wNb0jTMePHdWkN99Ql84dyqJkXAWXUtxKYtiwYVq/fr1++eUXbdq0SQ899JBcXV312GOPydfXVwMGDFBcXJy+/vprJSUlqX///goPD1fLli0lSZ07d1ZYWJj69u2rHTt2aMWKFXrllVcUExNTorSwxNOvX3zxxZ8eP3jw4BXPUdg89Ylz/KV0NSK6PKC7mrc07Bsx+Fl1uq+r7uvaXZIUGxevJ58Z5Dx+6uQJjfj7Mxo59k01aNjoRpaLv4hzmZk6fPiwoh4MUHZ2liTJxWb8Neni4ipHvqMsysNfwB133qVffjlk2Pfrr78oJOQmSVLXB7qpZctWhuPPPTNAXR/opm7de9ywOmENR44c0WOPPaZTp04pICBAbdq00ebNmxUQcHG1icmTJ8vFxUU9e/ZUTk6OIiMjNWPGDOfzXV1dtXTpUj333HMKDw+Xt7e3oqOjNWbMmBLVUeKmrnv37rLZbHI4iv5lfKUou7B56oy84q/D8leTde6cjh5Jdj62HzuqAz/9qMo+vgoKDpGvr59hvJurm/yrVtMtNWpJkoKCQwzHvbwqSpJCb75FAYHFn6sHivL2m2+o/T33KiQ0VCdSUzVz+lS5urqoy/1dVblyZVWvXkNjXxuluGEj5Ofnp7VrV2tz4jeaOuOfZV06LOpvfaPVr+9j+r/3ZqnzfV20a+cP+uQ/izXy1Yv/SPr5VZGfXxXDc9zc3FW1WjXVrHVrWZSMq1Beps4//PDDPz3u6emp6dOna/r06UWOqVGjhv773/9eUx0lbupCQkI0Y8YMdevWrdDj27dvV9OmTa+pKBjt27tbQ2N+v05x5rtvSpI63/+gRox6vazKApxSUux6aXic0tLSVMXfX3fe1VTzFy2Wv//FZU2mzXpP7056Wy/EPqtz586p+i3VNXb8BLVt176MK4dVNWzUWJPemaYp707Se7Om66abbtbwES8rquuDZV0aUGpsjj+L3Arx4IMPqkmTJkVGgjt27NCdd96p/Pz8EhVy5DeSOpQv1SpXKOsSAIOS/bYGbgyvMlzeb/DnpffNSO90q3/lQeVMiZO64cOHKzMzs8jjderU0ddff31NRQEAAKBkStzUtW3b9k+Pe3t7q317plQAAEDpcikfl9SVGyw+DAAATKm83ChRXvDdrwAAABZAUgcAAEyJ6VcjkjoAAAALIKkDAACmxCV1RiR1AAAAFkBSBwAATMmFqM6ApA4AAMACSOoAAIApkUwZ8XkAAABYAEkdAAAwJS6pM6KpAwAApsSNEkZMvwIAAFgASR0AADAlgjojkjoAAAALIKkDAACm5EJSZ0BSBwAAYAEkdQAAwJS4+9WIpA4AAMACSOoAAIApEdQZ0dQBAABT4kYJI6ZfAQAALICkDgAAmJJNRHV/RFIHAABgASR1AADAlLimzoikDgAAwAJI6gAAgCmR1BmR1AEAAFgASR0AADAlG6sPG9DUAQAAU2L61YjpVwAAAAsgqQMAAKbE7KsRSR0AAIAFkNQBAABTciGqMyCpAwAAsACSOgAAYErc/WpEUgcAAGABJHUAAMCUuKTOiKQOAACYkotspbZdrQkTJshms2nw4MHOfdnZ2YqJiVHVqlVVqVIl9ezZUykpKYbnJScnKyoqShUrVlRgYKCGDx+uCxculPDzAAAAwDXbtm2b/vnPf6px48aG/UOGDNGXX36pjz/+WOvXr9exY8fUo0cP5/G8vDxFRUUpNzdXmzZt0rx58zR37lyNGjWqRK9PUwcAAEzJZiu9raTOnj2rPn366P3331eVKlWc+9PT0zV79mxNmjRJHTp0UNOmTTVnzhxt2rRJmzdvliStXLlSe/bs0YIFC9SkSRN16dJFY8eO1fTp05Wbm1vsGmjqAAAALpOTk6OMjAzDlpOTU+T4mJgYRUVFKSIiwrA/KSlJ58+fN+yvX7++qlevrsTERElSYmKiGjVqpKCgIOeYyMhIZWRkaPfu3cWumaYOAACYkout9LaEhAT5+voatoSEhELr+PDDD/Xdd98Vetxut6tChQry8/Mz7A8KCpLdbneO+WNDd+n4pWPFxd2vAAAAl4mPj1dcXJxhn4eHR4Fxhw8f1t///netWrVKnp6eN6q8QtHUAQAAUyrNrwnz8PAotIm7XFJSklJTU3XXXXc59+Xl5WnDhg2aNm2aVqxYodzcXKWlpRnSupSUFAUHB0uSgoODtXXrVsN5L90de2lMcTD9CgAAcJU6duyonTt3avv27c6tWbNm6tOnj/O/3d3dtWbNGudz9u3bp+TkZIWHh0uSwsPDtXPnTqWmpjrHrFq1Sj4+PgoLCyt2LSR1AADAlMrD4sOVK1dWw4YNDfu8vb1VtWpV5/4BAwYoLi5O/v7+8vHx0aBBgxQeHq6WLVtKkjp37qywsDD17dtXEydOlN1u1yuvvKKYmJhipYWX0NQBAABTKs3p1+tp8uTJcnFxUc+ePZWTk6PIyEjNmDHDedzV1VVLly7Vc889p/DwcHl7eys6Olpjxowp0evYHA6H43oXfzWO/Fb8dViAG6Fa5QplXQJgUD5+WwNGXu5l99qztyaX2rkH3F291M5dWkjqAACAKZkkqLthuFECAADAAkjqAACAKZFMGfF5AAAAWABJHQAAMCUbF9UZkNQBAABYAEkdAAAwJXI6I5o6AABgSmZZfPhGYfoVAADAAkjqAACAKZHTGZHUAQAAWABJHQAAMCUuqTMiqQMAALAAkjoAAGBKLD5sRFIHAABgASR1AADAlEimjGjqAACAKTH9akSTCwAAYAEkdQAAwJTI6YxI6gAAACyApA4AAJgS19QZlZumLvdCflmXABjk5TvKugTAoO2Er8u6BKCA70Z1KOsS8P+Vm6YOAACgJLiGzIjPAwAAwAJI6gAAgClxTZ0RTR0AADAlWjojpl8BAAAsgKQOAACYErOvRiR1AAAAFkBSBwAATMmFq+oMSOoAAAAsgKQOAACYEtfUGZHUAQAAWABJHQAAMCUb19QZkNQBAABYAEkdAAAwJa6pM6KpAwAApsSSJkZMvwIAAFgASR0AADAlpl+NSOoAAAAsgKQOAACYEkmdEUkdAACABdDUAQAAU7KV4v9KYubMmWrcuLF8fHzk4+Oj8PBwLVu2zHk8OztbMTExqlq1qipVqqSePXsqJSXFcI7k5GRFRUWpYsWKCgwM1PDhw3XhwoUS1UFTBwAAcA1uvvlmTZgwQUlJSfr222/VoUMHdevWTbt375YkDRkyRF9++aU+/vhjrV+/XseOHVOPHj2cz8/Ly1NUVJRyc3O1adMmzZs3T3PnztWoUaNKVIfN4XA4rus7u0oHT2SXdQmAQZCvR1mXABi0nfB1WZcAFPDdqA5l9tprfjxZaufuWL/aNT3f399fb775pnr16qWAgAAtWrRIvXr1kiT9+OOPatCggRITE9WyZUstW7ZMXbt21bFjxxQUFCRJmjVrlkaMGKETJ06oQoUKxXpNkjoAAGBK5WX69Y/y8vL04YcfKjMzU+Hh4UpKStL58+cVERHhHFO/fn1Vr15diYmJkqTExEQ1atTI2dBJUmRkpDIyMpxpX3Fw9ysAAMBlcnJylJOTY9jn4eEhD4/CZ3F27typ8PBwZWdnq1KlSlqyZInCwsK0fft2VahQQX5+fobxQUFBstvtkiS73W5o6C4dv3SsuEjqAACAKdlspbclJCTI19fXsCUkJBRZS7169bR9+3Zt2bJFzz33nKKjo7Vnz54b+GmQ1AEAABQQHx+vuLg4w76iUjpJqlChgurUqSNJatq0qbZt26Z3331Xjz76qHJzc5WWlmZI61JSUhQcHCxJCg4O1tatWw3nu3R37KUxxUFSBwAATKk0r6nz8PBwLlFyafuzpu5y+fn5ysnJUdOmTeXu7q41a9Y4j+3bt0/JyckKDw+XJIWHh2vnzp1KTU11jlm1apV8fHwUFhZW7NckqQMAALgG8fHx6tKli6pXr64zZ85o0aJFWrdunVasWCFfX18NGDBAcXFx8vf3l4+PjwYNGqTw8HC1bNlSktS5c2eFhYWpb9++mjhxoux2u1555RXFxMSUqJGkqQMAAKbkUk6+Jiw1NVVPPPGEjh8/Ll9fXzVu3FgrVqxQp06dJEmTJ0+Wi4uLevbsqZycHEVGRmrGjBnO57u6umrp0qV67rnnFB4eLm9vb0VHR2vMmDElqoN16oAisE4dyhvWqUN5VJbr1G346XSpnbvdbf6ldu7SQlIHAABM6VrWk7MimjoAAGBKNno6A+5+BQAAsACSOgAAYEoEdUYkdQAAABZAUgcAAEzJhYvqDEjqAAAALICkDgAAmBI5nRFJHQAAgAWQ1AEAAHMiqjOgqQMAAKbEN0oYMf0KAABgASR1AADAlFjRxIikDgAAwAJI6gAAgCkR1BmR1AEAAFgASR0AADAnojoDkjoAAAALIKkDAACmxDp1RjR1AADAlFjSxIjpVwAAAAsgqQMAAKZEUGdEUgcAAGABJHUAAMCciOoMSOoAAAAsgKQOAACYEkuaGJHUAQAAWABJHQAAMCXWqTOiqQMAAKZET2fE9CsAAIAFkNQBAABzIqozIKkDAACwAJI6AABgSixpYkRSBwAAYAEkdQAAwJRY0sSIpA4AAMACSOoAAIApEdQZ0dQBAABzoqszYPoVAADAAkjqTGDn9iT9Z9FcHdi3V6dPndDI8ZPVql0H5/Eube4o9HkDnh+iXo/3U8rxo1o09z3t+G6rfjt1Sv7VAtQhMkq9n3ha7u7uN+ptwMKiIjvo+LFjBfY//Ojjin9llPOxw+HQoOcGatM3/9Pb70zTvR0jbmSZsLiAyhX094511KpOVXm6u+jw6SyN/mKv9h4/I0ka/WADPdgkxPCcTQdOKXbRDsO+NnWr6ul2NVU3sJJyL+Qr6dc0DV2884a9DxQfS5oY0dSZQHZWlm6tU0+do7pr3D/iChxf+Pkaw+NvN2/UOxNGq3X7i/9gHv71Fzkc+Ro0fKRCb6quXw8d0LtvvKbsrCw9HTv0hrwHWNuCD/6jvPw85+Of9+/XcwOfVKfISMO4hfPnycbtaigFlT3dNKd/U337S5oGLdqu386dV3X/ijqTfcEw7psDpzT6873Ox7l5+YbjHeoHaOQD9TVt7c/adug3ubrYVCew0g15D8C1oqkzgebhbdQ8vE2Rx/2rVjM83rxxnRrf1VwhN90sSWrWsrWatWztPB5y0806kvyLvlqymKYO10UVf3/D4zmz39fNt1RX02Z3O/ft+3GvFsybowUf/Ued7217o0uExfVrXUMpGTka/cXvDduxtOwC43Iv5OtUZm6h53C12TT8vrp6Z9UBfb79uHP/oZPnrn/BuC74G9GIa+os5rfTp7R10/8UGfXQn47LPHtWlX18b1BV+Cs5fz5Xy5Z+oW4P9XCmcllZWXp5xDC99I9RqlYtoIwrhBW1v62a9hzL0Bu9Gmr10DZa9HRzPXRnaIFxzWr6afXQNvr0+RaKv/82+Xr9nm3UD6mkIB9PORzSoqeba8WQ1pr6+B2qHeB9I98KTCghIUHNmzdX5cqVFRgYqO7du2vfvn2GMdnZ2YqJiVHVqlVVqVIl9ezZUykpKYYxycnJioqKUsWKFRUYGKjhw4frwgVj2vxnaOosZvWyL+RVsaJat+9Y5JhjR5L1xScfqEu3XjewMvxVfL1mjc6cOaMHu/3+h8XbExN0R5M7dU+Hon8ugWtxUxVP9Wp2kw6fPqeYhdv1n6SjGn5fXXVtHOwcs+nnUxr52V49O/97TVnzs5rWqKKpjzeRi+3SObwkSc+0r6X/+98vGvzhD8rIOq/3ou+UjycTW+WRrRS3kli/fr1iYmK0efNmrVq1SufPn1fnzp2VmZnpHDNkyBB9+eWX+vjjj7V+/XodO3ZMPXr0cB7Py8tTVFSUcnNztWnTJs2bN09z587VqFGjCnvJQpX4pzQrK0tJSUny9/dXWFiY4Vh2drYWL16sJ5544k/PkZOTo5ycnMv2OeTh4VHScnCZlV99pns7368KRXyWJ0+k6JWhz6vtvZ3U5cGeN7g6/BV8tuQ/atWmrQICgyRJ679eq21bt+iDjz8t48pgZS42m/YcO6Npaw9KkvbZz6p2gLd6NbtJS3+wS5JW7k51jj+Qmqn9KWf15Qut1KxmFW099Jtc/n+yPHvjL1r74wlJ0ugv9mr54NbqFBaoT74reDMQIEnLly83PJ47d64CAwOVlJSkdu3aKT09XbNnz9aiRYvUocPFGx3nzJmjBg0aaPPmzWrZsqVWrlypPXv2aPXq1QoKClKTJk00duxYjRgxQqNHj1aFChWuWEeJkrqffvpJDRo0ULt27dSoUSO1b99ex4//ft1Benq6+vfvf8XzJCQkyNfX17DNevfNkpSCQuza8Z2OJP+i+7r2KPT4qZOpemnQUwpreIdeeLH4nT9QXMeOHdXWzYl6qMfDzn1bt27WkcPJat/qbjVvcruaN7ldkjQ87gU93b9vWZUKizl5JlcHT2Qa9h06eU7BPp5FPudoWrZ+y8zVLf8/oTt59mLY8MfznM9z6EhaloJ9iz4PylB5ieouk56eLkny///XGyclJen8+fOKiPj9jv/69eurevXqSkxMlCQlJiaqUaNGCgoKco6JjIxURkaGdu/eXazXLVFSN2LECDVs2FDffvut0tLSNHjwYLVu3Vrr1q1T9erVi32e+Ph4xcUZ7+I8muEoSSkoxIqlS1S3XphurVuvwLGTJ1L00qCnVKdemIa8PEYuLsy84/r74rNP5e9fVW3atXfu6z/gaT3UwzjV/0iPBzX0xZfUrn2Hy08BXJXth9NUs1pFw74aVb10PL3gzRKXBFb2kG9Fd504e/HGib3HzijnQp5qVK2o7Ycv/qPs5mJTqK+XjqcfL/I8KDuluaRJYbOKHh4eV5xVzM/Pd/ZHDRs2lCTZ7XZVqFBBfn5+hrFBQUGy2+3OMX9s6C4dv3SsOEr0L/umTZuUkJCgatWqqU6dOvryyy8VGRmptm3b6uDBg8U+j4eHh3x8fAwbU69Fyzp3Tj/v/1E/7/9RkpRy/Kh+3v+jUu2//5LJzDyr/329UpEPFLxB4uSJFI0Y9JQCgkL0VGyc0tN+0+lTJ3X61Mkb9h5gffn5+frisyXq+mB3ubn9/vditWoBqlP3NsMmScHBobrp5pvLqlxYzMIth9XwJh892aaGbqnipfsaBqnHXTdp8bYjkiQvd1cNjqitRjf5KMTXU3fXqqLJjzbS4dNZSvz5lCQpMzdPn3x7TM/eU0stb/VXjaoVFX//xT+SV+1JLfK1YU2FzSomJCRc8XkxMTHatWuXPvzwwxtQpVGJkrqsrCzDL2ubzaaZM2cqNjZW7du316JFi657gZD2/7hbI154yvn4valvSZIiujyoof8YK0lav3q55JDuiehS4Pnfb9usY0eSdexIsvo+1NlwbNnGHQXGA1djy+ZNsh8/pm4PFT79D5SmPcfOaNjinYrtUFtPt6upY79l660V+7Vs18W7C/MdDtUNqqSud4SosqebTpzJ0eafT2vGuoM6n/f7TNE7qw/ogsOhsd3D5OHuol1HM/TM/O8LrHeH8qE0lzQpbFbxSgFUbGysli5dqg0bNujmP/zRGhwcrNzcXKWlpRnSupSUFAUHBzvHbN261XC+S3fHXhpzJTaHw1Hsec+7775bgwYNUt++Ba+DiY2N1cKFC5WRkaG8vLxCnv3nDp4oOiIHykKQL+kxype2E74u6xKAAr4bVXaXUeyzl94agvWCK1550P/ncDg0aNAgLVmyROvWrVPdunUNx9PT0xUQEKAPPvhAPXtevElx3759ql+/vhITE9WyZUstW7ZMXbt21fHjxxUYGChJeu+99zR8+HClpqYWa0azRNOvDz30kD744INCj02bNk2PPfaYStAjAgAAXLXycp9ETEyMFixYoEWLFqly5cqy2+2y2+3KysqSJPn6+mrAgAGKi4vT119/raSkJPXv31/h4eFq2bKlJKlz584KCwtT3759tWPHDq1YsUKvvPKKYmJiin2JWomSutJEUofyhqQO5Q1JHcqjskzqfirFpO62EiR1RX394Zw5c9SvXz9JF5d9Gzp0qD744APl5OQoMjJSM2bMMEyt/vrrr3ruuee0bt06eXt7Kzo6WhMmTDBc+vanddDUAYWjqUN5Q1OH8qhMm7qUUmzqgorf1JUXrGsBAABgAXzvCQAAMKXSXKfOjEjqAAAALICkDgAAmFJprlNnRjR1AADAlOjpjJh+BQAAsACSOgAAYE5EdQYkdQAAABZAUgcAAEyJJU2MSOoAAAAsgKQOAACYEkuaGJHUAQAAWABJHQAAMCWCOiOaOgAAYE50dQZMvwIAAFgASR0AADAlljQxIqkDAACwAJI6AABgSixpYkRSBwAAYAEkdQAAwJQI6oxI6gAAACyApA4AAJgS19QZ0dQBAACToqv7I6ZfAQAALICkDgAAmBLTr0YkdQAAABZAUgcAAEyJoM6IpA4AAMACSOoAAIApcU2dEUkdAACABZDUAQAAU7JxVZ0BTR0AADAnejoDpl8BAAAsgKQOAACYEkGdEUkdAACABZDUAQAAU2JJEyOSOgAAAAsgqQMAAKbEkiZGJHUAAAAWQFIHAADMiaDOgKYOAACYEj2dEdOvAAAAFkBSBwAATIklTYxI6gAAAK7Bhg0b9MADDyg0NFQ2m02fffaZ4bjD4dCoUaMUEhIiLy8vRUREaP/+/YYxp0+fVp8+feTj4yM/Pz8NGDBAZ8+eLVEdNHUAAMCUbKX4v5LIzMzUHXfcoenTpxd6fOLEiZoyZYpmzZqlLVu2yNvbW5GRkcrOznaO6dOnj3bv3q1Vq1Zp6dKl2rBhgwYOHFiyz8PhcDhK9IxScvBE9pUHATdQkK9HWZcAGLSd8HVZlwAU8N2oDmX22qcz80rt3P7erlf1PJvNpiVLlqh79+6SLqZ0oaGhGjp0qIYNGyZJSk9PV1BQkObOnavevXtr7969CgsL07Zt29SsWTNJ0vLly3X//ffryJEjCg0NLdZrk9QBAABTstlKb8vJyVFGRoZhy8nJKXGNhw4dkt1uV0REhHOfr6+vWrRoocTERElSYmKi/Pz8nA2dJEVERMjFxUVbtmwp9mvR1AEAAFwmISFBvr6+hi0hIaHE57Hb7ZKkoKAgw/6goCDnMbvdrsDAQMNxNzc3+fv7O8cUB3e/AgAAXCY+Pl5xcXGGfR4e5fuyHJo6AABgSqW5pImHh8d1aeKCg4MlSSkpKQoJCXHuT0lJUZMmTZxjUlNTDc+7cOGCTp8+7Xx+cTD9CgAAUEpq1aql4OBgrVmzxrkvIyNDW7ZsUXh4uCQpPDxcaWlpSkpKco5Zu3at8vPz1aJFi2K/FkkdAAAwpZIuPVJazp49qwMHDjgfHzp0SNu3b5e/v7+qV6+uwYMHa9y4capbt65q1aqlkSNHKjQ01HmHbIMGDXTffffp6aef1qxZs3T+/HnFxsaqd+/exb7zVaKpAwAAuCbffvut7r33XufjS9fiRUdHa+7cuXrxxReVmZmpgQMHKi0tTW3atNHy5cvl6enpfM7ChQsVGxurjh07ysXFRT179tSUKVNKVAfr1AFFYJ06lDesU4fyqCzXqcvIzi+1c/t4mu8KNfNVDAAAgAKYfgUAAKZUPq6oKz9I6gAAACyApA4AAJgTUZ0BTR0AADCl8rKkSXnB9CsAAIAFkNQBAABTKs2vCTMjkjoAAAALIKkDAACmRFBnRFIHAABgASR1AADAnIjqDEjqAAAALICkDgAAmBLr1BnR1AEAAFNiSRMjpl8BAAAswOZwOBxlXQSuj5ycHCUkJCg+Pl4eHh5lXQ4giZ9LlD/8TMKqaOosJCMjQ76+vkpPT5ePj09ZlwNI4ucS5Q8/k7Aqpl8BAAAsgKYOAADAAmjqAAAALICmzkI8PDz06quvcuEvyhV+LlHe8DMJq+JGCQAAAAsgqQMAALAAmjoAAAALoKkDAACwAJo6AAAAC6Cps5Dp06erZs2a8vT0VIsWLbR169ayLgl/YRs2bNADDzyg0NBQ2Ww2ffbZZ2VdEv7iEhIS1Lx5c1WuXFmBgYHq3r279u3bV9ZlAdcNTZ1FfPTRR4qLi9Orr76q7777TnfccYciIyOVmppa1qXhLyozM1N33HGHpk+fXtalAJKk9evXKyYmRps3b9aqVat0/vx5de7cWZmZmWVdGnBdsKSJRbRo0ULNmzfXtGnTJEn5+fm65ZZbNGjQIL300ktlXB3+6mw2m5YsWaLu3buXdSmA04kTJxQYGKj169erXbt2ZV0OcM1I6iwgNzdXSUlJioiIcO5zcXFRRESEEhMTy7AyACi/0tPTJUn+/v5lXAlwfdDUWcDJkyeVl5enoKAgw/6goCDZ7fYyqgoAyq/8/HwNHjxYrVu3VsOGDcu6HOC6cCvrAgAAuNFiYmK0a9cubdy4saxLAa4bmjoLqFatmlxdXZWSkmLYn5KSouDg4DKqCgDKp9jYWC1dulQbNmzQzTffXNblANcN068WUKFCBTVt2lRr1qxx7svPz9eaNWsUHh5ehpUBQPnhcDgUGxurJUuWaO3atapVq1ZZlwRcVyR1FhEXF6fo6Gg1a9ZMd999t9555x1lZmaqf//+ZV0a/qLOnj2rAwcOOB8fOnRI27dvl7+/v6pXr16GleGvKiYmRosWLdLnn3+uypUrO6859vX1lZeXVxlXB1w7ljSxkGnTpunNN9+U3W5XkyZNNGXKFLVo0aKsy8Jf1Lp163TvvfcW2B8dHa25c+fe+ILwl2ez2QrdP2fOHPXr1+/GFgOUApo6AAAAC+CaOgAAAAugqQMAALAAmjoAAAALoKkDAACwAJo6AAAAC6CpAwAAsACaOgAAAAugqQMAALAAmjoAAAALoKkDAACwAJo6AAAAC6CpAwAAsID/B5IyYnjCwcTuAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1kAAAK9CAYAAADWo6YTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdeVhUZRvH8e8w7KsCgogguOO+7/uSS5aVImqaW2pmlpmaZrZYZmWaVpqmqWnmmpZL6qvmbu77vu+iIMi+zpz3j9GhCVBA4MDM/bkurjnnOcv8BhHmnvOc59EoiqIghBBCCCGEECJXWKkdQAghhBBCCCHMiRRZQgghhBBCCJGLpMgSQgghhBBCiFwkRZYQQgghhBBC5CIpsoQQQgghhBAiF0mRJYQQQgghhBC5SIosIYQQQgghhMhFUmQJIYQQQgghRC6SIksIIYQQQgghcpEUWUIIAXzyySdoNJos7btgwQI0Gg3Xrl3L1nP07duXgICA7IcTFk+v11OlShUmTpyodhSRiVmzZuHv709SUpLaUYQQBYAUWUKIAu9xUaPRaNi9e3e67Yqi4Ofnh0ajoVOnTrn2vF988QV//PFHrp2vILp27Zrxe6vRaLCyssLd3Z0OHTrwzz//ZHrcnj17ePnll/H29sbOzo6AgAAGDx7MjRs3Mj3m2LFj9OrVCz8/P+zs7HB3d6dNmzbMnz8fnU6XpbyrV6+mQ4cOeHp6YmtrS4kSJejWrRt///13tl97YbJkyRJu3rzJW2+9lW7b6dOn6dWrF76+vtjZ2VGiRAleffVVTp8+rULS/NOiRQuTn10HBweqVavGtGnT0Ov1efa8mf1e6Nu3L8nJycyePTvPnlsIUXhIkSWEKDTs7e357bff0rXv2LGDW7duYWdnl6vPl9mbqd69e5OQkECpUqVy9fnU1KNHDxYtWsT8+fMZMmQI+/bto2XLlpw8eTLdvt9//z1Nmzbl5MmTDBs2jJkzZ9K1a1eWLVtGtWrV2Lt3b7pj5s6dS506ddi2bRuvvvoqM2fO5KOPPsLBwYEBAwbw1VdfPTGfoij069ePV155hXv37jFixAhmzZrF0KFDuXLlCq1bt87wec3F5MmT6d69O25ubibtq1atolatWmzdupV+/foxc+ZMBgwYwLZt26hVqxarV69WKXH+KFmyJIsWLWLRokVMmjQJe3t73n33XcaPH59nz5nZ7wV7e3v69OnD1KlTURQlz55fCFFIKEIIUcDNnz9fAZRXXnlF8fT0VFJSUky2Dxw4UKldu7ZSqlQp5fnnn8/Rc3z88cfKf38lOjk5KX369Mlp7HT69OmjlCpVKtfOlxuuXr2qAMrkyZNN2jds2KAAypAhQ0zad+/erVhZWSlNmzZV4uLiTLZdunRJ8fb2Vnx8fJSIiAhj+z///KNotVqlSZMmSnR0dLoMBw8eVObPn//EnJMnT1YAZfjw4Yper0+3feHChcr+/fuf9nKfSq/XK/Hx8c98ntx05MgRBVC2bNli0n7p0iXF0dFRqVixonL//n2TbWFhYUrFihUVJycn5fLly/kZN980b95cqVy5sklbQkKCUqpUKcXFxUVJTU3Nk+d90u+FQ4cOKYCydevWPHluIUThIVeyhBCFRo8ePXjw4AGbN282tiUnJ7Ny5Up69uyZbv/t27ej0WjYvn27SfvjLnILFizI9Lk0Gg1xcXH88ssvxu5Iffv2BTK/J2vDhg00b94cFxcXXF1dqVu3boZX3v7tm2++oVGjRnh4eODg4EDt2rVZuXJluv02b95MkyZNKFKkCM7OzlSoUIEPPvjAZJ/vv/+eypUr4+joSNGiRalTp85Tnz8zTZs2BeDy5csm7Z999hkajYZffvkFR0dHk21lypTh66+/5u7duyZdpj799FM0Gg2LFy/GxcUl3XPVqVPH+L3NSEJCApMmTaJixYp88803Gd4717t3b+rVqwdkfn9dRv9uAQEBdOrUiU2bNlGnTh0cHByYPXs2VapUoWXLlunOodfr8fX1pWvXriZt06ZNo3Llytjb2+Pt7c3gwYOJjIw0OfbQoUO0a9cOT09PHBwcCAwMpH///pm+7sf++OMPbG1tadasmUn75MmTiY+P56effqJYsWIm2zw9PZk9ezZxcXF8/fXXxvbH35tLly7Rt29fihQpgpubG/369SM+Pj7dc//666/Url0bBwcH3N3d6d69Ozdv3nxi3kOHDhl/Rv5r06ZNaDQa1q1bB0BMTAzDhw8nICAAOzs7vLy8aNu2LUeOHHnq9yUj9vb21K1bl5iYGO7fv5/t13Lx4kW6dOlC8eLFsbe3p2TJknTv3p2oqCjgyb8XAGrXro27uzt//vlnjvILIcyHFFlCiEIjICCAhg0bsmTJEmPbhg0biIqKonv37rn6XIsWLcLOzo6mTZsauyMNHjw40/0XLFjA888/T0REBGPHjuXLL7+kRo0abNy48YnPM336dGrWrMmECRP44osvsLa2Jjg4mPXr1xv3OX36NJ06dSIpKYkJEyYwZcoUXnzxRfbs2WPcZ86cObz99ttUqlSJadOm8emnn1KjRg3279+fo9f/uBApWrSosS0+Pp6tW7fStGlTAgMDMzwuJCQEOzs745vox8c0a9YMf3//HGXZvXs3ERER9OzZE61Wm6NzPMn58+fp0aMHbdu2Zfr06dSoUYOQkBB27txJaGhouix37twx+XkbPHgwo0aNonHjxkyfPp1+/fqxePFi2rVrR0pKCgD379/nueee49q1a4wZM4bvv/+eV199lX379j013969e6lSpQo2NjYm7WvXriUgIMBYEP9Xs2bNCAgIMPlZeqxbt27ExMQwadIkunXrxoIFC/j0009N9pk4cSKvvfYa5cqVY+rUqQwfPtz4b/nw4cNM89apU4fSpUuzfPnydNuWLVtG0aJFadeuHQBvvPEGP/74I126dGHmzJmMHDkSBwcHzp49+7RvS6Yef4hSpEiRbL2W5ORk2rVrx759+xg2bBgzZsxg0KBBXLlyxbhPVn4v1KpVy+T/phDCQql9KU0IIZ7mcXfBgwcPKj/88IPi4uJi7NIVHBystGzZUlEUJV13wW3btimAsm3bNpPzPe4i9+8uatnpLvg4z9WrVxVFUZSHDx8qLi4uSv369ZWEhASTff/dtS2j7oL/7ZqWnJysVKlSRWnVqpWx7dtvv1UAJSwsLP0355HOnTun6zqVFY+/F59++qkSFhamhIaGKrt27VLq1q2rAMqKFSuM+x47dkwBlHfeeeeJ56xWrZri7u6uKIqiHD9+PEvHPMn06dMVQFm9enWW9s/o31JR0v+7KYrhZwZQNm7caLLv+fPnFUD5/vvvTdrffPNNxdnZ2fjvtmvXLgVQFi9ebLLfxo0bTdpXr15t/BnOrpIlSypdunQxaXv48KECKJ07d37isS+++KICGLtpPv7e9O/f32S/l19+WfHw8DCuX7t2TdFqtcrEiRNN9jt58qRibW2drv2/xo4dq9jY2Jh0G01KSlKKFCli8txubm7K0KFDn3iuzDRv3lypWLGiEhYWpoSFhSnnzp1TRo0apQAmvwey+lqOHj2a7mc+I0/rRjxo0CDFwcEhR69JCGE+5EqWEKJQ6datGwkJCaxbt46YmBjWrVuXYVfB/LR582ZiYmIYM2YM9vb2JtueNiy8g4ODcTkyMpKoqCiaNm1q0l3q8Sfyf/75Z6ajphUpUoRbt25x8ODBHL2Gjz/+mGLFilG8eHGaNm3K2bNnmTJlikm3uJiYGIAMu/z9m4uLC9HR0QDGx6cd8yS5cY4nCQwMNF5Zeax8+fLUqFGDZcuWGdt0Oh0rV67khRdeMP67rVixAjc3N9q2bUt4eLjxq3bt2jg7O7Nt2zYg7d9w3bp1xqtbWfXgwQOTK4qQvX8LSPsePvbGG2+YrDdt2pQHDx4Y91u1ahV6vZ5u3bqZvK7ixYtTrlw54+vKTEhICCkpKaxatcrY9r///Y+HDx8SEhJibCtSpAj79+/nzp07TzxfZs6dO0exYsUoVqwYFStWZPLkybz44osmXYGz+loeDyqyadOmDLtOZlXRokVJSEh4pnMIIQo/KbKEEIVKsWLFaNOmDb/99hurVq1Cp9OZFAJqeHzfUpUqVbJ97Lp162jQoAH29va4u7tTrFgxfvzxR+M9IGB4w9q4cWNef/11vL296d69O8uXLzcpuN5//32cnZ2pV68e5cqVY+jQodnqsjRo0CA2b97M2rVreffdd0lISEg3rPrjN+yP3+BnJiYmxrivq6trlo55ktw4x5M8qevjnj17uH37NmC4x+/+/fsmRcLFixeJiorCy8vL+Gb/8VdsbKzxvqDmzZvTpUsXPv30Uzw9PencuTPz58/P8pxKyn9Gq8vOv8W/93/sv103Hxdxj+8ju3jxIoqiUK5cuXSv6+zZs8bXFRsbS2hoqPErLCwMgOrVq1OxYkWTInXZsmV4enrSqlUrY9vXX3/NqVOn8PPzo169enzyySdcuXLFuD2z8z8WEBDA5s2b2bRpEzNnzsTX15ewsDCTDzuy+loCAwMZMWIEc+fOxdPTk3bt2jFjxgyT/4tZ8fjfKqvz7gkhzJO12gGEECK7evbsycCBAwkNDaVDhw4m9178W2ZvcrI6J1Ne27VrFy+++CLNmjVj5syZ+Pj4YGNjw/z5800GrHBwcGDnzp1s27aN9evXs3HjRpYtW0arVq343//+h1arJSgoiPPnz7Nu3To2btzI77//bhwm/b/32mSkXLlytGnTBoBOnTqh1WoZM2YMLVu2pE6dOgCULVsWa2trTpw4kel5kpKSOH/+fLpjMhoKPqsqVqwIwMmTJ3nppZeeun92/93/fTXx30JCQhg7diwrVqxg+PDhLF++HDc3N9q3b2/cR6/X4+XlxeLFizM8x+MBKTQaDStXrmTfvn2sXbuWTZs20b9/f6ZMmcK+fftwdnbO9PV4eHikG0TDzc0NHx+fJ/5bAJw4cQJfX19jofpYZve2PS4Q9Ho9Go2GDRs2ZLjv47zffPONyc9XqVKljPfzhYSEMHHiRMLDw3FxcWHNmjX06NEDa+u0tx7dunWjadOmrF69mv/9739MnjyZr776ilWrVtGhQ4cnnh/AycnJ+HML0LhxY2rVqsUHH3zAd999l63XAjBlyhT69u3Ln3/+yf/+9z/efvttJk2axL59+yhZsmSG37P/ioyMxNHRMdOfKyGEhVC1s6IQQmTBv+/JUhRFiYmJURwcHBRAWbZsmXG//96T9fh+oP/ey7N169Ys3ZPl7OycpXuyVqxYkaV7hv57T9Y777yjODg4KImJiSb79ezZM8N7iv5t4sSJCqBs3rw5w+1JSUnK888/r2i12nT3if1bZkO4R0ZGKm5ubkq7du1M2tu2batotVrl2rVrGZ5v4cKFCqBMmjTJ2Pbcc88p1tbWyo0bN574mjITFxenFC1aVAkKCsrSsNyP7+GKjIw0aR8/fnyG92Q9adj/evXqKQ0aNFBSUlIUT0/PdD8Pb775pqLVanM07PvixYsVQJkzZ84T92vTpo1Ss2bNdO0DBw5UAGXXrl0ZHrdz504FUAYPHmxse/xz/t/7+/77M/31118rgHL+/PknZrt8+bKyefNm49fu3buN286cOaMAyqxZs4z3pP33/sj/unfvnuLr66s0btz4qefPaAh3RTH8P7O1tVWuX7+erdeSkT179iiAMm7cOGNbZr8XHmvTpo1Su3btbD+XEMK8SHdBIUSh4+zszI8//sgnn3zCCy+8kOl+pUqVQqvVsnPnTpP2mTNnZul5nJycnjiK2mPPPfccLi4uTJo0icTERJNtyhMmJdVqtWg0GpMrLNeuXUs30WlERES6Y2vUqAFg7G724MEDk+22trZUqlQJRVGyfQ8QGO6VGTx4MJs2beLYsWPG9g8//BBFUejbty8JCQkmx1y9epXRo0fj4+NjMuLaxx9/jKIo9O7dm9jY2HTPdfjw4QyH+37M0dGR999/n7Nnz/L+++9n+D399ddfOXDgAGAYSh4w+Xd/POx2doWEhLBv3z7mzZtHeHi4SVdBMFyJ0el0fPbZZ+mOTU1NNf78REZGpsv933/DzDRs2JBTp06l22/UqFE4ODgwePDgdP/+ERERvPHGGzg6OjJq1KisvFQTr7zyClqtlk8//TRdbkVRjM9XunRp2rRpY/xq3Lixcb+goCCqVq3KsmXLWLZsGT4+PibD0Ot0unRd8by8vChRooTxtT7p/JkZPXo0KSkpTJ06NVuvJTo6mtTUVJPtVatWxcrKyuR7/7TfC0eOHKFRo0ZPzSmEMG/SXVAIUSj16dPnqfu4ubkRHBzM999/j0ajoUyZMqxbty7d/DmZqV27Nlu2bGHq1KmUKFGCwMBA6tevn24/V1dXvv32W15//XXq1q1Lz549KVq0KMePHyc+Pj7TN/fPP/88U6dOpX379vTs2ZP79+8zY8YMypYta9INbMKECezcuZPnn3+eUqVKcf/+fWbOnEnJkiVp0qQJYCj0ihcvTuPGjfH29ubs2bP88MMPPP/88zkeMOKdd95h2rRpfPnllyxduhQwDAv+zTffMGLECKpVq0bfvn3x8fHh3LlzzJkzB71ez19//WUyUEOjRo2YMWMGb775JhUrVqR3796UK1eOmJgYtm/fzpo1a/j888+fmGXUqFGcPn2aKVOmsG3bNrp27Urx4sUJDQ3ljz/+4MCBA+zdu9f4vfD392fAgAGMGjUKrVbLvHnzKFasGDdu3MjW96Bbt26MHDmSkSNH4u7ubtI1DQz3Wg0ePJhJkyZx7NgxnnvuOWxsbLh48SIrVqxg+vTpdO3alV9++YWZM2fy8ssvU6ZMGWJiYpgzZw6urq507NjxiRk6d+7MZ599xo4dO3juueeM7eXKleOXX37h1VdfpWrVqgwYMIDAwECuXbvGzz//THh4OEuWLDEWndlRpkwZPv/8c8aOHcu1a9d46aWXcHFx4erVq6xevZpBgwYxcuTIp54nJCSEjz76CHt7ewYMGICVVdpnuzExMZQsWZKuXbtSvXp1nJ2d2bJlCwcPHmTKlCnZzvxYpUqV6NixI3PnzmX8+PFZfi1///03b731FsHBwZQvX57U1FQWLVqEVqulS5cuxvM/6ffC4cOHiYiIoHPnzjnOL4QwE2pdQhNCiKz6b3fBzGTU9SssLEzp0qWL4ujoqBQtWlQZPHiwcurUqSx1Fzx37pzSrFkzY9fEx12EMhoKXFEUZc2aNUqjRo0UBwcHxdXVValXr56yZMkS4/aMhnD/+eeflXLlyil2dnZKxYoVlfnz56fLsnXrVqVz585KiRIlFFtbW6VEiRJKjx49lAsXLhj3mT17ttKsWTPFw8NDsbOzU8qUKaOMGjVKiYqKeuL3LLPugo/17dtX0Wq1yqVLl0zad+7cqXTu3Fnx9PRUbGxsFH9/f2XgwIGZdiNUFEU5fPiw0rNnT6VEiRKKjY2NUrRoUaV169bKL7/8ouh0uifmfGzlypXKc889p7i7uyvW1taKj4+PEhISomzfvj3dc9WvX1+xtbVV/P39lalTp2Y6hPuTugsqiqI0btxYAZTXX389031++uknpXbt2oqDg4Pi4uKiVK1aVRk9erRy584dRVEU5ciRI0qPHj0Uf39/xc7OTvHy8lI6deqkHDp0KEuvu1q1asqAAQMy3HbixAmlR48eio+Pj2JjY6MUL15c6dGjh3Ly5Ml0+2a1u+Bjv//+u9KkSRPFyclJcXJyUipWrKgMHTo0y13vLl68qAAKYNLVT1EMXVpHjRqlVK9eXXFxcVGcnJyU6tWrKzNnzszSuTPrLqgoirJ9+3YFUD7++OMsv5YrV64o/fv3V8qUKaPY29sr7u7uSsuWLZUtW7aYnDuz3wuKoijvv/++4u/vbzJ1gxDCMmkU5Ql9WYQQQgihukWLFjF06FBu3LiR6UAvQl1JSUkEBAQwZswY3nnnHbXjCCFUJvdkCSGEEAXcq6++ir+/PzNmzFA7isjE/PnzsbGxSTcHmRDCMsmVLCGEEEIIIYTIRXIlSwghhBBCCCFykRRZQgghhBBCCJGLpMgSQgghhBBCiFwkRZYQQgghhBBC5CKLm4xYr9dz584dXFxc0Gg0ascRQgghhBBCqERRFGJiYihRooTJhOnPyuKKrDt37uDn56d2DCGEEEIIIUQBcfPmTUqWLJlr57O4IsvFxQUwfCNdXV1VTiOEEEIIIYRQS3R0NH5+fsYaIbdYXJH1uIugq6urFFlCCCGEEEKIXL+NSAa+EEIIIYQQQohcJEWWEEIIIYQQQuQiKbKEEEIIIYQQIhdJkSWEEEIIIYQQuUiKLCGEEEIIIYTIRVJkCSGEEEIIIUQukiJLCCGEEEIIIXKRFFlCCCGEEEIIkYukyBJCCCGEEEKIXCRFlhBCCCGEEELkIimyhBBCCCGEECIXSZElhBBCCCGEELlIiiwhhBBCCCGEyEVSZAkhhBBCCCFELpIiSwghhBBCCCFykRRZQgghhBBCCJGLpMgSQgghhBBCiFwkRZYQQgghhBBC5CIpsoQQQgghhBAiF0mRJYQQQgghhBC5SIosIYQQQgghhMhFUmQJIYQQQgghRC5StcjauXMnL7zwAiVKlECj0fDHH3889Zjt27dTq1Yt7OzsKFu2LAsWLMjznEIIIYQQQgiRVaoWWXFxcVSvXp0ZM2Zkaf+rV6/y/PPP07JlS44dO8bw4cN5/fXX2bRpUx4nFUIIIYQQQoissVbzyTt06ECHDh2yvP+sWbMIDAxkypQpAAQFBbF7926+/fZb2rVrl1cxhRBCCCGEECLLVC2ysuuff/6hTZs2Jm3t2rVj+PDhmR6TlJREUlKScT06Ojqv4gkhhBBCCJGnUnR6Vh+5TVhs0lP3TU7Vs/FUKJfCYvM0k8b2PlZ2d/P0OR7TOp3F2u0oipL9DnkaFDTGRwWA6GMxuZzQoFAVWaGhoXh7e5u0eXt7Ex0dTUJCAg4ODumOmTRpEp9++ml+RRRCCCGEEGboclgs287dz3CbXlFI0Smk6hR0ej0pegWdXiFFpydVp5CqV0jV6Q1tj5ZTTR4VUvX/Xv7XNr3pOSLjU56QUgcafY5en0Ybj12xTaBNzN5xmhSsnS/m6DmfhSaHr1N59AUaAGzLpK8fckOhKrJyYuzYsYwYMcK4Hh0djZ+fn4qJhBBCCCGEWm5GxNP06224Odhk67iohCcVN/lLY/0QrdMl6gUUNbbF6m9zNfUvFVNBdc/auX9SRY91xEU0qWlX7qyAwamOlNRrn3q4JjES65ibxvUU11KsiwyiScibaO2diY2JpQ7Ncj12oSqyihcvzr1790za7t27h6ura4ZXsQDs7Oyws7PLj3hCCCGEECKPRMYls/XcfVJ1WbuCoVfg4zWnKOJoa9IeFmN4s57Toql5+WK4O5meUwNYazVYa62wsdKgtbLCRqtBa/WvNq0GGysrtFaaR9ussNamLRuO02CjNbRrrTRYW2mI10VjY6Uxtm288TvLLs0D4GRyjl7CE1UoWoGQiiHZPq62V21KFymd+4GubIeFnZ/tHDaOUPllYst3YcSkBfz666+MSy3D559/nme3EhWqIqthw4b89Zdphb5582YaNmyoUiIhhBBCCPOXkKzjVmQ8E9ad4UpYnCoZbj9MyNFxj4uq/+pauyRDWpTJ1rm8XOxwtLVi843NhMeH5yjPY3og+dFXug2P6sivDn71xHOUL1oeHycf47pGo6FHhR7U8KqRo0xWGivsre1zdGyOnd8Al//OfHvULcNjEX9o/+TvR4a0NuBXn9OXbxLcNZizZ8+i1WpxdXXNWd4sUrXIio2N5dKlS8b1q1evcuzYMdzd3fH392fs2LHcvn2bhQsXAvDGG2/www8/MHr0aPr378/ff//N8uXLWb9+vVovQQghhBCiwNLrFa4+iOPivVhS9U++AnTydhS/H76Fq71pN7roxFTCszDIQn7xdLalhl/Rp+8IgEIpDydaVLZBp081tno42VLEyRaIzPLzXoi4wIf753LqwansBc4jv3X8jarFqqod49n9/jokZ2FgDjc/qNgxR0+xcOFChgwZQnx8PCVKlGDp0qU0bdo0R+fKKlWLrEOHDtGyZUvj+uN7p/r06cOCBQu4e/cuN27cMG4PDAxk/fr1vPvuu0yfPp2SJUsyd+5cGb5dCCGEEIVSYoqOf648ICU1ZzfxP6YAX244h5112ohrigK3IuOJS9Zl61zhsRn3QXOxs8bP3REPZ1tGtC2PlUbzLJFzxMPZlpJFHU3aknRJ/HnpTx4mPczwmBnHZrB857N9fzPTITDrUxHlVEX3ivSv0j93Txp1G67u5PEQEKp6XGA1GAq2Thnvo7GCyi9n+9QJCQkMGzaMn3/+GYC2bdvy66+/4uXlldO0WaZRFKUAfHfzT3R0NG5ubkRFReX5ZUIhhBBCWLZzodGERmU8WltEXDIjlh/P8wz2NlaU93bBwebpgwQkpugIqetPOW9nY5uDjZaSRR1wc7BBk0eF1f34+0Qmpl1VuhV7i28Pf4u15unXAy5HXc7y8zhaOz59pyeIT42nb+W+1PepTx3vOvnftS63zGkFtw+rncLU6Kvg6J6rpzx79iy1a9cmMTGRTz/9lA8++ACt1vT/QV7VBoXqniwhhBBCiNxwKzKeGxHxWdtZgRsR8ey9/IA72bgv6MTtKJKzcYWqpn+RLO+bEUUBT2c7+jUOMLZ5udgR6OmEtTb7cwrll6P3j9JnQx+UXLiq0qVclwzbPR08GVB1AA7WeTNcd4ETeR1SnvCzGnXb8FiyLti75U+mJ/FrkOsFFkBQUBDz58/H09OT1q1b5/r5n0SKLCGEEEIUWN9sOs+RG1m/byYrwmKSuHg/bydn/a/KJTL+hDwpVc8L1UrwduuyeXaVKCtuxdwiLCEs1873/dHvuRlzEw1Pf01349ImsfV08DQuJ6Um8VK5l2jp1zKjw0zYWNlQ1bMqWqunX60zewfmwF8js7Zvh6/ANw+GXVdJUlISI0eOpHv37jRu3BiAkJDsj5SYG6TIEkIIIUSeuvMwgQf/uc/nYUIys3ZcxuYJV1gi4pI5cSsqT7OV83J++k5AUUdbGpR2J8jHNVvFkLWVhgZlPHC2K3hvuSISI1h0ZhFH7h3hyP0jasehb+W+vFfnPbVjFH73ThserR3A9gndIz3KgVfl/MmUD65cuUK3bt04fPgwf/75JxcuXMDeXr3unAXvf7wQQgghCjRFUbj+IJ6kJ3SFi01K5cftlzl5+yH3op99ZLrvetR85nP8mwaoX9odL5dCek9NBlL1qRy7f4wkXcbf72lHpnE75raxSIxOTj8/UCnXUrmWx1Zry6cNP8VK8/SuitZW1pQrWi7Xntvi3NgHf74F0bfh8aS9TUdA89Hq5sonf/zxB3379iUqKgoPDw9mz56taoEFUmQJIYQQAgiNSiQhRYdOr2fmtsskP2HC13Un7ma67Ul83Ezf9CSk6KjtX5QOVX0yOcKgTqmiBHhmMuqYhYhKimL2idlEJWV+ZW/N5TU5OreXoxddy3elQ0AHAtwCcphQqOboYlj7Duj/NbmyxgqKV1MvUz5JSUlhzJgxTJ06FTDMqbts2TL8/PxUTiZFlhBCCGFRHsQmMX3rRWKT0uYMWnXkdo7P5+Fkm+m2pFQ9FYq7EFLXjzZB3rg/YV9zE50czcG7B9EphuHTr0Zd5YdjP2BtlbO3Xqn/muMpK4LcgzJsd7JxYnyD8carWQ7WDhR3Kp6jTCIX6VIh6gZEXIWIKxB5zfCY+JTusqlJcPuQYTnoBWg7ATRasHUGJ488j62m6Oho2rdvzz///APAe++9x6RJk7CxsXnKkflDiiwhhBCikJu/5yoX7sU8db81x+48dc4kFztrUvUKHs62vN4kMNP9ijrZ0qGKD7bWBXfUuqxI1mU8J1R2HL53mBUXVvDvWXG23NiS4b7ZLZb+y9vRm15BvTLd7mbnRofADoV3aHFzlpLwqHh6XEg9eoy4Cg9vgJK9+cxMNBsNLcaCVeH+/5gdLi4ulChRgiJFirBgwQI6d+6sdiQTUmQJIYQQBVBiio6kVD2nbkex6XRopmO03YiIZ9v57I8K52JvzbBWZf+1bkPnGiVwtLWctwbjdo/LcRe7rLLX2lPZ0zC4gKIodKvQjTredXJ0LlutLUXti+ZmPJFXzq413CeV+BAirhmKqZg7Tz7G2h6KBoB7aSgaCO6B4OgBTxtoxb00+FTPpeAFW2pqKklJSTg5OaHRaPj555+JiIggMDDzD4TUYjm/SYUQQgiVJKXqUJ4wBVBsUiqL990gNslwT8XBa5Ecu/kw288z8rnyT93H2c6aV2qXxNW+YHSpyWtxKXGExoUy7cg0klJNB4T45+4/ufpcfSr1wd/V37he3Kk4TX2bqjo0u1BBcjys6AsZXbW0czUUT8ZCqrRhvWgguPhY1JWo7Lpz5w49evTAx8eHJUuWoNFocHNzw82tAMzzlQEpsoQQQohcptcrXI+IZ/XR28zddYX4p3TRy4oe9fwo5myX6fbWQd5U9yvyzM9TWB0KPcT5yPMmbasuruJC5IWnHrvu5XV42D/b/St2WjtstJZRuJqd1GS4sg2Snt7lNkuS49IKrGajwLN8WlHl6P70K1MinS1bttCzZ0/CwsJwcXHh8uXLlC1b9ukHqkiKLCGEEOIZpej0rDh0i7CYJH47cD3HQ5YXdbShW13DqFi2WiuCa/tR3M0eaysNVlbyxuyx8IRw4zDlqfpU3t/5PqcfnH7qcfWL1+elci+ZtAW6BebqsOWiEDo4BzZ9kPvn1VhB8zGglbfbOaXT6fj888/59NNPURSF6tWrs2LFigJfYIEUWUIIIUSWhMUkseb4HZIzmBtq69l7HLoemeFxjcp4UDfAndcalsLORpvp+a2tNNg/YbsweP1/r7P/7v5Mt7cPaG+y7mLrwpDqQ/Bw8MjSfE3CzEXfhdQE07awc4ZH15KGrnu5pVxbKbCewb179+jVqxdbthgGkRk4cCDTp0/HwcFB5WRZI//yQgghxFNsO3effgsOZmnfV+v742irpW/jQDycbKVwykRoXCihcaF8+s+nWT7mbtxd4lLijOv2WsMIejpFR6BbILPbzsbTwTPXswozcWAO/DUy8+1VXobnPs+/PCJTiqLQqVMnDh06hKOjI7NmzaJ3795qx8oWKbKEEEKITPxz+QE95uwzafN3d6R+oHu6fa21Vrxa358qvgXzJuyCZMv1Lby7/d1nOsfu7rtxs5PvtciG0BOGR60taP9zf6OdM5Rrl/+ZRIY0Gg1TpkzhrbfeYunSpVSqVEntSNkmRZYQQgjxL9vO3efjNadJStWlu7dqVq9atK/io1KygudmzE0eJDxI156iT2Hc7nGZds+7HZs2+bGrrSt1vOvQI6hHlp5Tg4YqnlVwsnHKWWhRuD24DL+FQFz2py0gJd7w2Px9aPaEK1pCFQ8ePOD48eO0atUKgGbNmnHs2DGsCumIi1JkCSGEEMC3my+waN91IuLST047vlMletTzs6g5pDKz9vJaToWf4lT4KU6En3imc42sM5I+lfvkUjJhEa7tggcXn+EEGvCunGtxRO7Yt28f3bp1IyIigoMHDxIUFARQaAsskCJLCCGEmUtO1fP3ufuMW32SIo4ZD7F9OSwuXdu7bcrTppIXfu6OFjGnVERiBJuubWLFhRWExWd8lSAqKQqF9BN+lXQuma5NQaGSRyX6Ve6X4bnsre0pW6TgjxAmVLT9K7jxn7nMoh9N6BvYDJ6fmv1z2rmAS/FnzyZyhaIoTJs2jdGjR5Oamkq5cuXQ6Z59youCQIosIYQQZudhfDKHr0eSlKrnzcVHjO0PMrhK9V8/vlqLij6uBHqab3e0mOQYfjrxE5GJhhERFRTWXF6TrXMMqjYIaytrOgV2ws/VLy9iCkuWEAnbv8h8u3sZ8CyXf3lErnv48CH9+/dn9erVAISEhPDTTz/h6uqqcrLcIUWWEEKIQm3zmXt8tfEcTnZpf9KO33yY4b69G5SiU7WM76nSWmmoWtINO+uCPxqgoigcCzuW4f1Qv5z+heNhx7GxyvzqW7I+82KzecnmDKw2EGcb50z38Xfxl4l3RRq9Dg7Ng5i7uXfO5Pi05Zd/Mt2mtYGybXLvuUS+O3z4MMHBwVy9ehVbW1u+/fZbhgwZgsaMJmqWIksIIUSBl5ii48StKPSKaVe1+zFJvL3kaKbH+RZxwMPZlpp+RfjkxcqF9g/4wdCDLD+/HJ1i6Eaz784+YlJinnjMkwqpx4raFTW5J6pasWrULV732cIKy3Nt95OHRn8WNk5QPSRvzi1U8/vvv3P16lUCAwNZsWIFtWvXVjtSrpMiSwghRIF2MyKepl9ve+p+77UtT6USad1MAjydKFMs86sx+SUsPox9d/dleC9TVo3bPS7TbTW9aqZrs9PaMbbeWBxtHDM9ztrKWuaUEk+XGA3X9xiuVmXm9iHDo7M3VH4ld5+/TMvcPZ8oECZMmIC1tTUjRoygSJEiasfJE1JkCSGEKNAW/nPNuKzRQOn/3Cul0WjoXteP15uWztdc0cnRKI+urIXFh/Hd0e9I1qW/erTnzp5ce87mJZvTxLcJADZWNrT0b4m7ffo5u4TINavfgPPrs7avexno8GXe5hGF0okTJ/jqq6+YP38+tra2WFtbM2HCBLVj5SkpsoQQQhQYoVGJXLofy4K917C20hCTlMKeS4b7jiqXcGX9201VTgiXH17m5T9fzvaVqZLOJSnlVirHz1vcsThj6o3B3to+x+cQFiTmHuhTn/08D68bHj3Lg0PRzPfTaKHRW8/+fMKsKIrCvHnzeOutt0hMTKRs2bJ8+umnasfKF1JkCSGEKBC2nr3HgF8OZbp93PNB+ZjGVHxKPB/s/oCIxAiO3s/8HrAGPg14ocwL6dr9XPwy7NYnRJ7Y/BHsmZ6753xuIpR/LnfPKcxaXFwcb775JgsXLgSgQ4cODBs2TOVU+UeKLCGEEKpRFIWwmCR0isKh64bhxG21VugVhRYVvGhRoRgAjct6qjakelh8GK1WtErXHlw+mLH1xhoH09CgQWtV8EcmFBbg1mHDo0YLufEz6eoLvrWe/TzCYpw9e5auXbty5swZrKys+Pzzz3n//fcL9eTC2SVFlhBCiHxxMyKen3dfJVmnN7b9tv9Guv1eqlmCr7tWz5dMscmx3Iu/Z9K27+4+lp9fjrWV4U/khcgLxm3FnYozpu4YShcpTaBbYL5kFCJbtn8J13cblrv+DJVfVjePsDjr1q0jJCSE+Ph4fHx8WLJkCc2bN1c7Vr6TIksIIUSeSUrVERmXQoNJW5+6r41Wg721llYVvfIhGZyLOEfw2uAs79+sZDNmtJ6Rh4mEyAVHFqYte8hkvSL/VaxYEa1WS+vWrVm8eDHe3t5qR1KFFFlCCCFyVXKqHgWFqf+7wOydV9JtD/R04uWavsZ1Hzd7utQqiZVV3s1hpVf0LD+/nJ9O/ISd1g6AW7G3jNuL2pne0B+XEseIOiOMV6usNFZUL5Y/V9eEyFBiFGwaB3FhT94vLtzw2HMFFK+S97mEAKKionBzcwOgbNmy7N27l6CgILRay+1CLUWWEEKIZ3bjQTyrj97mp52XiUvOeD6dqr5urHqzETbavOmTr1f0/HrmV+7G3U237dezv2Z63LCawxhUbVCeZBIi11zcDEcXZX1/70p5l0WIf1mxYgUDBw5k5cqVtGnTBoAqVaTAlyJLCCFEjlwOiyVk9j+Ex6afG+rftoxohr+7E7bWeXfD853YO7T7vV2W9h1XfxxBHoaRCt3t3fFz8cuzXEI8k5REOPYrxD2A0BOGtmJB0PDNJx/nUQ7cSuZ9PmHRkpKSGDlyJD/88AMAs2bNMhZZQoosIYQQmdDpFdYev8O96EST9hsR8SzOYMAKgAal3akb4E6fRgHYWlvhYmdtHH0vr6y/sp4Pdn9g0jaw6sB0+xWxK0K3Ct1knilReJxbB+vfM23zLAu1XlMnjxCPXL16lW7dunHokGHajbFjx5r95MLZJUWWEEIIE3q9wsbToby5+EiW9u/doBTvtCmHk601Drb50//+8bDq1lbWpP5rwtUg9yCWdlqKlcZyhgkWhZwuFW7ug5SE9Ntu7jc8FvGHsm3AygZq983XeEL815o1a+jTpw8PHz7E3d2dRYsW0bFjR7VjFThSZAkhhDCxaN91Pl5z2qStSy3Trkd6RaFjVR+q+7nh5ZL7V4YURUGvGIZ6V1CYfWI2V6OuGrdvurYJwKTAerf2u3QM7CgFlihcdk+FbROfvI9PDej0bb7EEeJJDhw4QOfOnQFo0KABy5Ytw9/fX+VUBZMUWUIIIYhNSuWF73eTkKwj9F/dA4e0KMPodhXyvMvfvyWmJtLgtwbolIwH0Pi3xr6N+ajBRxRzKIaN1iYf0gmRy6JuGh5dfMA5g6GutbZQp1/+ZhIiE3Xr1uW1117Dw8ODL7/8EltbW7UjFVhSZAkhhAVLSNax9vgdRv9+It22XwfUp0k5z1x/zmRdMrtu72LlhZUZbt99e3emx46tN9a47O3kTSu/VvlaAAqRZ+q+Ds1Gqp1CiHQ2b95M7dq1cXd3R6PRMH/+fKyspMfA00iRJYQQFmzaFtO5rFzsrVkysAH+Ho642ufsylBiaiLnI89z+eFlUnQpJtvORZ7LtLj6Lzc7N9a9tA4AjUaDq62rFFRCCJFPUlNT+eSTT5g4cSKdOnXizz//xMrKSgqsLJIiSwghzNiRG5F8sf4sCSkZd727FZl2s/1HnSrRv4lh8t2opChC4xLQK3omHZhEdFJ0lp4vOjmaq1FXs9TVD2BQtUEZDqHuYuNCs5LNpAugMH+KonYCIdK5e/cuPXr0YMeOHQD4+/uj0+mkwMoGKbKEEMIM6fQKx25G8uP2yxy6Hmlst7K9j9b5HPDojZ0D2DjAK7V80RS5z/xT29l2cxtH7x99pud3t3enQtEKONk4pdumtdLSK6gX1YpVk0EqhLh/xvDo6KFuDiEe+fvvv+nRowf379/H2dmZOXPm0L17d7VjFTpSZAkhhJlJTtVT/sMNj9b0OPj/TFHnVNwcbLgVfynDY/66bfj6L2sraxRFoYRzCd6t/e5Tn9tOa0eFohXwcvSSrn1CZObwAri0FRQ93D4MGiuoIENgC3XpdDomTpzIJ598gqIoVK1alRUrVlChQgW1oxVKUmQJIUQhd+bBGbbd3IaiKNyMiOePY7exfTRehV2xvwGIUSAmPu2Y+j718XbMYCSzRxysHehXpR++zr55GV0Iy6PXGSYY/tf0A5RuCS6Z/38UIj/ExsYyf/58FEVhwIABfPfddzg6Oqodq9CSIksIIQq4h4kPuRV7K9PtPdb3MFm3zWRAwFltZgFQ0qUkpVxL5Vo+IUQ2KEpagdX2M7BzkatYokBwc3NjxYoVnD59mj59+qgdp9CTIksIIQqw8xHn6bq2a5b21SX4oUswTBpcuYQrlUq44mCjxdPBkz6V+2BvnfuTBgshnkGt3uBQVO0UwkLp9Xq++eYbihYtysCBAwGoU6cOderUUTmZeZAiSwgh8tnGqxuZcnhKuuHN/0uvQGTSA+O6HR5ogPgMRgrUJxXD+v4APnmhGs3KFaO4mxRUQhQIej3cOQLJcYb1LI68KUReioiIoE+fPqxbtw47OzvatGlDYGCg2rHMihRZQgjxjI6HHefPS3+iV/RZ2v/3i79n+zmS7rcl5kHrdO2fda4MQJlizjQqm/sTBwshntH+H2HTBxlvk9E1hQr2799Pt27duHHjBnZ2dvzwww8EBASoHcvsSJElhBBZFJUUxdH7R1EezWtzLvIcM4/NzPH5+lceSFMfQ+E0Yd0ZTt2JynA/O40LWp0boKNVRS8alfGgdDEnWlWUG+WFyHepSYavrAq/aHh09ADnf/2fDWgK9m65m02IJ1AUhe+++45Ro0aRkpJC2bJlWbFiBTVq1FA7mlmSIksIIZ5i+fnlHAo9xIZrG564X5dyXSjhXCJL54yItuXHPzyYnnrtUYvjoy/QWhmGPne01fJd95q0rOiVw+RCiFx1fS8segVSE56+73/V7getx+d+JiGyQFEUQkJCWLFiBQDBwcHMnTsXV1dXlZOZLymyhBDiCR4mPuSzfZ+ZtLnYuBDoZui7rlN09KrUixYlW+Bs65zpeRRFIVVvuAJ2PjSGTr/tznC/wx+2wcPZLpfSCyFy1a2DOSuwbBwhoHHu5xEiizQaDdWqVeOPP/5g6tSpDB06VOYyzGMa5XG/FwsRHR2Nm5sbUVFRUr0LYQH0ip55p+Zx5N6RHP1B2Xlrp3H5vdrvUbpIaZqVbJatc5y+E8XQxUe49iA+3ba+jQIY36kSkHYFSwhRAG2dYJhEOP4BVAuBF77L+rFWWtDa5Fk0ITKiKApRUVEUKVIEMIwmeO7cOSpVqqRusAImr2oDuZIlhDA7iqKw89ZObsfeZtKBSblyzrJFytK3St9sH3fyVhQv/JDxVavg2iUZ3Ly0FFdCFAZ7vwddsmHZoyzYyAieouCKiYlh8ODBnD59mn379uHg4ICVlZUUWPlIiiwhhFm5F3eP51c/T5Iu/Y3pnzT8BKscjOblYutC85LNc5Rn/9W0IdhXvNGQ8l4uADjYarG1lpHFhCg0Hnf8eXUllEk/0qcQBcXJkyfp2rUrFy5cQKvVsnPnTtq1a6d2LIsjRZYQotC7F3ePLTe2kKpP5ZtD35hsa+nXkia+TQguH5zv/c8X7LnK5+vPAtChSnHqBrjn6/MLIfKAVyWwkg9IRME0f/58hg4dSkJCAr6+vixbtozGjeV+QDVIkSWEKBQiEiOITooG4MyDM/x86me0Gi0AZyPOptu/llctfmj9Ay62LvmaEwzdFQctOszmM/fS8vgXzfccQohckBwPp1fJJMKiQIuPj2fo0KEsWLAAgPbt27No0SI8PWX+RLVIkSWEKPCWn1/OF/u/QPeUNzklnEpQ27s2VTyr0DOoZ57niopPofXUHdhqTa+Q3YtJQqdPG1NoYf96NCtfLM/zCCHywLHF8NfItHVrGf1TFDyPCywrKys+++wzxowZg5VccVWVFFlCiALtzIMzJkOoP74yFZcSx6Bqg6jmWQ0ATwdPgjyC8i3X2FUnWHLg5lP3O/RhGzxlSHYhCpaURLh7HMjCAMt3jxse3UtDvUHgJFcGRMEzYcIEDh06xPfff0+LFi3UjiOQIksIUYCdfXCWkHUhxvWDrx7E3lrdEb1CoxIZuPAQJ29HGdvKezvzTXD1dPuW83LBwVabn/GEEFmxpDtc2Za9Y8q0ggZD8iaPENmUmJjIX3/9xSuvvAKAn58fx48fl6tXBYgUWUKIAicqKYrvjnzHigsrjG0hFUJUKbAUReH0nWg++vMUKTrFpLgC2D6yBQGeTvmeSwjxBLoUUPSZb4+4bHh09YWs/F6xcYQqXXMnmxDP6NKlSwQHB3Ps2DH++OMPOnfuDCAFVgEjRZYQQnVXHl5h6fmlpOhTAFh5YaVxW2v/1lR0r0i3Ct3yPdfFezGsOX6H7/++lG5bOS9nlg9uSFEn23zPJYR4gmO/wZphoE99+r7dFkLJOnmfSYhc8vvvv9O/f3+io6Px9PTEyUk+5CuopMgSQqhCURRe/9/rnAw/SUJqQob7jKs/ju4Vu+dzMoMBCw6y9dx9k7bapYryVquy2GqtqBvgLvNcCVEQ/TMjawWWc3HDpMJCFALJycmMHj2a6dOnA9CkSROWLl2Kr6+vyslEZqTIEkLku7uxd+m+vjsRiREm7U18m1C9mOHeppIuJXk+8Hk14nH9QZxJgVW5hCvvtilPm0requQRQvxH1C1Y/QbER/xngwL3z4CVDbx9FOxdMz+HjRNo5W2QKPiuX79Ot27dOHDgAACjR4/m888/x8bGRuVk4knkt4sQIt/9fvF3kwJr7UtrKWJXhCL2RVTL9Ou+6+y4EMaJWw+5F51kbN83tjXF3dQdbEMI8R8XNsG1XZlvr/g8FPHLvzxC5KH9+/dz4MABihYtysKFC+nUqZPakUQWSJElhMgXKfoU9t3Zx/ILy7kUabjHydHakU1dNqlaXK04dJNt5+/z18nQdNu61i4pBZYQBdHjQS38G0GL9023abTgWzv/MwmRR7p168bt27d55ZVXKFWqlNpxRBZJkSWEyDFFUdhzZw+hcekLlH+7EHmBJeeWpGt/o/obqhZYAKNWnjBZ/6hTJVzsrWkd5I27DGohRMHm5AmlW6idQohcdevWLd555x1mzpyJt7ehm/q7776rciqRXVJkCSGyJD4lnvjUeADmnJjDpYeXnjhoxZP0q9KPSu6VaOHXIpdTZk1Cso6YpBRmbrtsbBvVrgINy3hQy7+oKpmEEJm4eRBCj5u2Xd+rThYh8timTZvo1asX4eHh6PV6Vq9erXYkkUNSZAkhMhSRGMH/rv2PZF0yl6Mus+riqifu/7SCSavR8mrQq9T0qom1lXq/eq6Fx9Hxu13EJ+tM2t9sUQaNRqNSKiFEhpJiYMHzoEvKeLu1Xf7mESKP6HQ6PvnkEyZOnIiiKNSoUYPJkyerHUs8AymyhBDp/HHpD8bvGZ/hNg0aFBQ0aPiq2VdoNVrq+9THzc4tn1PmzKJ9140FlrWVhherl+DLLtWkwBKioEhNMowQqCiG0QMfF1hBL5ruZ20HjYblfz4hclloaCg9e/Zk27ZtAAwePJhp06Zhby/3BBdmUmQJIUxsub7FpMBysHaglX8rrDXW9KjYg8qelVVMl3OKoqBX4PcjtwAY3Kw0YzsGqZxKCJHO4q5wdadpm5U1hCxSJ48QeejEiRM899xz3Lt3DycnJ2bPns2rr76qdiyRC6TIEkIAcOz+McbsGsPt2NvGtmktp9HKr1WhucoTl5TKzch4bkYkcDMinujEFOKTdZy9G82p21FExqcY9+3TKEC9oEKIzIUbRh/F2Ru0jwaf+e9VLCHMRGBgIEWKFMHT05OVK1dSsWJFtSOJXCJFlhCCu7F36b2ht0nbdy2/o6V/S5USZc+m06G8t/w4sUmpWdq/dDEnirnIvRxCFBgXt8Dy1yAlLq3t1RXgU129TELkkYcPH+Lm5oZGo8HFxYUNGzbg5eWFk5OT2tFELpIiSwgLdS/uHu9se4fwhHDuxd8ztg+pPoSXy76Mj7OPiukytul0KGfuRBMZn0xEXDKR8clExqVw5m60cZ8ijjaULOqAX1FH3J1ssbW2ory3C5VLuFKyqCMawNXBBq1V4bg6J4RFuLLNtMBy9oaigerlESKP7Nmzh5CQEEaMGMGIESMAw9UsYX6kyBLCQn139DtOPzht0talXBferPGmSokydi40mvbTdmVp32khNXippm8eJxJCPFVSDKx+A6JvP31fgKhH+9V9HZqPAXs3sJZ56oT5UBSFKVOmMGbMGHQ6HfPnz2fYsGHY2NioHU3kESmyhLBAZx+cZc3lNQC42Lgwt91cXGxd8HPxUzlZGkVRmL71ItO2XEy3bVirshR1tMXdyZYijja4O9lS3M0eLxcZiUmIAuH6P3BuXfaP8ywPzsVyP48QKoqIiKBv376sXbsWgB49ejB79mwpsMycFFlCWKC9d9Im8lzQYQHli5ZXMU3Gvt1yke+2phVYQ1qUoWvtkgR6OGElXf2EKJiibsP+H+H+OcO6R1loNylrx9o5g1+DvMsmhAoOHDhAt27duH79Ora2tnz33XcMGjSo0AwoJXJOiiwhLER8Sjw91vfgevR19IoegLal2haoAitFp+eNRYe5FBbL9QfxAHi52DG3Tx2qlSyibjghxNMdmA17v09bd/OD8s+pl0cIFYWHh9OqVSvi4uIoXbo0K1asoFatWmrHEvlEiiwhzJRe0ZOsSzauLzi9gCtRV0z2aeBTMD41vnQ/lqvhcfyy9xq7L4Ub2220Gta93US6AQpR0EXfgct/w52jhvVSjaF0S6j8srq5hFCRp6cnn332Gbt372bevHm4ubmpHUnkI42iKIraIfJTdHQ0bm5uREVF4erqqnYcIfJEYmoiXdZ04UbMjQy3/x38N7ZaW9zs1P2Ff+NBPGNWnWDv5Qfpti0Z2IAAT0d83BxUSCaEyJZ57eHGP2nrLT+E5qPUyyOESo4dO4a1tTVVqlQBDPcXA9I9sADLq9pArmQJYWaSdckM2DQg0wJrfrv5FHNU98byq+FxDF92jOM3H5q01/QvgpOtNeOeDyLIRz4EESLfJEZB1K2cH/94dMCS9aBoKagekju5hCgkFEVhzpw5vP3225QqVYpDhw7h4uIixZUFkyJLCDNz7P4xToSfAKCkc0l+f/F34zZbrS3WVur+t99w8i5DFh8xaQvwcGTFG41kgmAh1JAUA9OqGgqtZ/XcZ+BfMLohC5FfYmNjeeONN1i8eDEA5cqVIzU1VeVUQm1SZAlhJlL0KYTGhTLz+Exj24L2C3C0cVQxVZpUnZ5t58NMCqwqvq4s6FcPT2cproRQTUxoWoHl5JXz87gHQvFquZNJiELi1KlTBAcHc+7cObRaLV988QUjR47EyspK7WhCZVJkCWEGFEWh29puXHp4ydjm5+KHt5O3iqnSXLofS5upO0zaRrevQP/GgdjbaFVKJYQFSHgIc9vAw+uZ7/NotFHsi8Co9PPSCSEy9ssvvzBkyBASEhIoUaIEy5Yto0mTJmrHEgWEFFlCmIHD9w6bFFgA89rNUymNqbik1HQF1juty/Fmi7IqJRLCgoSegAdZLJxK1snbLEKYEb1ez8KFC0lISKBt27b8+uuveHk9w5VgYXakyBKiEFMUhdWXVvPx3o+NbUd6H8HGquDMIr/+xF3j8oAmgYzvVEnFNEKYuei7sP49iH80YufjboDuZaDPmicf61Iib7MJYUasrKxYvHgxixYtYsSIEWi10itDmJIiS4hC6krUFQ6FHuKzfZ8Z2/pW7lugCqxf913nwz9OAaDRIAWWEHnt/F9wfn369iL+4FYy//MIYUaWLl3K4cOHmTx5MgDFixdn1CiZqkBkTIosIQqZ9VfW88PRH7gVazrc8ps13qRHhR4qpUrvXnSiscAC+OLlqiqmEcICXNkOp1cblv3qQ6NhhmWNFZRqpFosIQq7xMRERowYwY8//ghAmzZtaNeuncqpREEnRZYQBVxUUhR77+xl7K6xaNCQqpgOCxvgGkD3it15NehVlRJmLDFFZ1ye2q06L9f0VTGNEBZg9RsQ86h7brEKEPSCunmEMANXrlwhODiYI0cMI+OOGzeO1q1bq5xKFAZSZAlRQN2KucWC0wtYdn5Zhtvfrvk2L5Z5scCMIAiGQS6WHLjBw/gUfthmGIjD2c6aV2pJNyUh8kzsfbi6ExIiDev1h0Cjt9TNJIQZWL16Nf369SMqKgoPDw8WLVpEhw4d1I4lCgkpsoQoAFL0KRy4e4DP9n1GaFwoGo2GVL3pFSt3e3e6VehGx8COlHQuiY224Nx79dg7S4+x5ew9kzY3h4KXUwizsrI/XNuVtt5giNx/JcQz+uSTT/j0008BaNiwIcuWLcPPz0/lVKIwkSJLCBUdvX+UxWcXs+naJtMNStpibe/aDKw6kMa+jfM3XDY9jE82KbD6NgrA3cmWoS1lqHYhnio1GR7eyNmxUTcNjz41ILCZYZALIcQzqVWrFhqNhhEjRjBp0iRsbOQDQ5E9UmQJoQKdXseeO3sYunVoum2t/Vszpt4YNGhwsHHA1dZVhYTZk5Sq49d9aZOd7hzVEn8PRxUTCVGIKArMaQX3Tj7bedpNhACZCFWInIqIiMDd3R2AF198kVOnTlGpkoyKK3JGiiwh8tHZB2eZfmQ6e+7sMWlv4NOAzmU709q/NQ7WDiqly7kJa8+weL/hU3hXe2spsITIrscFlp2rYb6D7CoaAD7VczWSEJYiNTWV8ePHM3fuXI4cOWLsFigFlngWUmQJkU+2XN/Cu9vfTdf+SrlXGF13NE42TiqkenZzdl4xFlgAn8tQ7UJkTXwELHjetJvg20fByVO9TEJYmDt37tCjRw927twJGAa7ePvtt1VOJcyBFFlC5LGopChe/ONFIhIjjG1dy3elgU8DGpdojLOts4rpns2FezFM/OuscX3j8KZULF7wuzcKUSDcOQL3z6StF/EHezf18ghhYTZv3syrr75KWFgYLi4u/PzzzwQHB6sdS5gJKbKEyEOJqYk0WWp6j8TkZpNpH9hepUS5Jz45lRd/2G1c//HVWlJgCfFYfAT8NQri7j9hn0dDrntWgB5LwNUXCuCooUKYG51Ox2effcaECRNQFIXq1auzYsUKypUrp3Y0YUakyBIij8SnxDPj2Azjup+LH0s7LS0UA1lkxbKDN0lM0QPQtXZJmlcopnIiIQqQi5vh1Mqs7Vu0FHiUyds8Qgij7777zjg8+8CBA5k+fToODoXvfmhRsEmRJUQuS0xNZOWFlXx18CuT9vUvr0eTkxvaC6DP151h7u6rxvVvguWGe2FhzqyB24cz3/64G2DxqtB4eOb7aaygdIvcTCaEeIo33niDlStXMmTIEHr16qV2HGGmpMgSIptik2O59PCSSdv5iPPMPD4TB2sHYpJjiE6ONm7zcfJhbL2xZlNg/X74lkmBtaBfXRXTCKGChIewog8o+qfv61EWqnbN80hCiMzp9XqWLl1KSEgIWq0WBwcHdu/ebTZ/l0XBJEWWENmw9vJaPtj9wVP383L0oo1/G5r4NqFpyab5kCz/LD2YNhLaumFNqOIrN+oLCxF2Hu6fhcSHaQVWw7cy319rAzV750s0IUTGHjx4wGuvvcZff/3F5cuXGT9+PIAUWCLPSZElRBZ8deArfj37q0mbu707jtZp80El65J5rfJr1PGuQ5kiZbC3ts/vmPni8R+mcR2DpMASliMxCmY1BV1SWpvWzjABsBCiQPrnn38ICQnh5s2b2Nvb4+vrq3YkYUGkyBLiKc5HnE9XYP3Q6gea+zVXKZF6IuOSOXDVMBR9iSJyk7CwELoUuHfmUYGlAf+GhvaKz6saSwiRMUVRmDZtGqNHjyY1NZVy5cqxcuVKqlWrpnY0YUGkyBIiE7dibtHrr148SHxgbFvYYSFVPKpgY4HDLCuKwvw9afdiuTvZqphGiHyiKPBTC7h3yrBu4wj9N6gaSQiRuYcPH9KvXz/++OMPAEJCQvjpp59wdTWPkX1F4SFFlhAZSExNpMuaLsSnxhvbegX1oqZXTRVTqScyLpman202rttqragf6K5iIiHyiS45rcCytpdBLIQo4K5fv86GDRuwtbXl22+/ZciQIXL/lVCFFFlCACn6FPbc3kN0cjSLzy7mzIMzxm0t/VryYYMP8XL0UjGheg5fj6DLj/+YtE0OroaVlfzREhbgwE9pyyMvgL3chyhEQVa9enUWLFhA2bJlqVOnjtpxhAWTIksIYP2V9YzfMz5de41iNZjecrpFfQqWnKonWWcYOe3krSh6zNln3Na4rAcL+9dHKwWWsBSnV6ct2zqrl0MIkaHo6GiGDh3KsGHDqFevHgDdu3dXOZUQUmQJQXxKvEmB1di3MY7Wjrxb+118nX0tqsA6FxrNyzP2kpCiS7dtctdqBNfxUyGVECrYPQ2u7Ybwi4b1rvPBSqtqJCGEqePHjxMcHMzFixfZv38/Z86cwdpa3tqKgkF+EoXFm3p4qnF5fIPxdKvQTcU06lEUhfbTdqVrt9LAJy9WlgJLWI6kWNjysWlb0VLqZBFCpKMoCvPmzeOtt94iMTERPz8/fvnlFymwRIEiP43CYt2OvU3vv3oTlhAGgKO1o8UWWIDJ1as3W5Th7dblALDSaLC1tlIrlhB579puuLozbT01MW35xe+hSCkoUSv/cwkh0omLi2PIkCEsWrQIgI4dO7Jw4UI8PDxUTiaEKSmyhMV6f+f7xgIL4IfWP6iYRl3XH8Tx0ow9xvW3WpXF3ka6RgkLsbSnYbLh/7K2h+o9QSt/KoUoCO7fv0/Lli05c+YMVlZWTJw4kdGjR2NlJR8EioJH9Z/KGTNmEBAQgL29PfXr1+fAgQNP3H/atGlUqFABBwcH/Pz8ePfdd0lMTHziMUL815WHVzgedhwAfxd/9vTYQ93idVVOlf90eoX1J+7SfPJ2IuNTAKjg7YK9tRRYwowpCtw8COc3GL4Sow3tNV6FugPTvl6ZIwWWEAWIp6cngYGB+Pj4sG3bNsaMGSMFliiwVP3rsWzZMkaMGMGsWbOoX78+06ZNo127dpw/fx4vr/TDZf/222+MGTOGefPm0ahRIy5cuEDfvn3RaDRMnTo1g2cQImNXo9Mm1f2lwy+42lreJIUP45OpMWGzSVvHqsWZ3r2mDM8uzNvFzfBbcPr2thPAyTP/8wghMpWQkICiKDg6OmJlZcXChQtJTU3N8H2iEAWJquX/1KlTGThwIP369aNSpUrMmjULR0dH5s2bl+H+e/fupXHjxvTs2ZOAgACee+45evTo8dSrX0JkpkaxGng6WOabqonrz5qsv9WyLDN61sJGK58KCjMX+ehDFns38K1t+GowVAosIQqYixcv0rBhQ9544w0URQHA3d1dCixRKKh2JSs5OZnDhw8zduxYY5uVlRVt2rThn3/+yfCYRo0a8euvv3LgwAHq1avHlStX+Ouvv+jdu3emz5OUlERSUpJxPTo6OvdehCi05p3MuJC3FIqisOl0KAB21lac+6y9RQ1VLyxYchxsGG1YDmgK3Rerm0cIkaEVK1YwYMAAYmJiuHPnDnfv3qVEiRJqxxIiy1T7yDo8PBydToe3t7dJu7e3N6GhoRke07NnTyZMmECTJk2wsbGhTJkytGjRgg8++CDT55k0aRJubm7GLz8/GYbakoXFh/HVga84EX4CwCILi23n7xM49i+iE1MB+OylKhb5fRAWKupW2nL59urlEEJkKCkpiWHDhtGtWzdiYmJo1qwZx44dkwJLFDqF6o7e7du388UXXzBz5kzq16/PpUuXeOedd/jss88YP358hseMHTuWESNGGNejo6Ol0LJQKboURu0cxeF7h41tnzT6RL1AKvl0zWmT9dYVpduFMFP3zsDvr0Piw7Q2nWGAFxzcoVbmvSCEEPnv6tWrdOvWjUOHDgGG93ATJkyQ+a9EoaTaT62npydarZZ79+6ZtN+7d4/ixYtneMz48ePp3bs3r7/+OgBVq1YlLi6OQYMGMW7cuAxHmLGzs8POzi73X4AoNPSKnhNhJ+i9wfQN1ZTmUyjtVlqlVPnv0v0YNpwM5dqDeABeqeXLV12qyT1Ywnxd3AT3T2e8rViF/M0ihHginU5Hhw4dOH/+PO7u7ixatIiOHTuqHUuIHFOtyLK1taV27dps3bqVl156CQC9Xs/WrVt56623MjwmPj4+XSGl1RqGmn58Q6QQ/3Y16ip9NvQhMinSpH3lCyup4G45b7J2Xwyn18/7Tdreb19RCixhvu6fgy2fGJbLd4AWY0y3ewXleyQhROa0Wi0zZszgo48+YsmSJfj7+6sdSYhnour11xEjRtCnTx/q1KlDvXr1mDZtGnFxcfTr1w+A1157DV9fXyZNmgTACy+8wNSpU6lZs6axu+D48eN54YUXjMWWEAA6vY741HgOhh40KbAGVBnAkBpDsNNaztVNRVFMCqzKJVwZ1qos3q72KqYSIo8dnJO2XKwClKihWhQhRMZu3rzJhQsXaN26NQCtW7emVatWcp+wMAuqFlkhISGEhYXx0UcfERoaSo0aNdi4caNxMIwbN26YXLn68MMP0Wg0fPjhh9y+fZtixYrxwgsvMHHiRLVegiiAwhPCabm8pUlb/eL1mdFmhkUVV499sPqUcfnjFyrRr3GgimmEyCe6ZMOjRzloNlLdLEKIdDZs2EDv3r1JSUnh8OHDlC1bFrDMAamEeVL9TsK33nor0+6B27dvN1m3trbm448/5uOPP86HZKIgOh1+mm8OfYNe0We6z5H7R0zWrTRWNPdrbpEF1oV7MSw5cMO43rdRgHphhFBD9e5g56J2CiHEI6mpqXz88cd88cUXANSqVUt6IwmzpHqRJURW/XnpTz7c82GW929RsgVTW0wFDdhY2eRhsoJDp1e48zDBuD5yxXHj8tb3mssnhMJ8pSTAzf2g1xnWo++om0cIkc7du3fp0aMHO3bsAODNN99kypQp2NtL93VhfqTIEoWCoihsvLbRuN6pdCda+bfKdP+idkWp5V0LK435D+yQkKwjJtEwLHXw7H+4/mj0wH9rWNqDMsWc8zuaEPnnjzfh9Kr07RbwO0CIwuDvv/+mR48e3L9/H2dnZ+bOnUtISIjasYTIM1JkiUJh1vFZ7L69G4A3qr/B0BpDVU5UMNx+mEC7b3cSm5SabpuDjaH7RUKKjm+6Vc/vaELkH0WB0JOG5SL+YOdmWLZ3g6AX1cslhDBau3Yt9+/fp2rVqqxcuZLy5curHUmIPCVFlijwQuNCOXjvoHG9mW8zFdMULBfuxRgLLK2VoStg9ZJurHijkXFdCLO3oi88uGhYbv8lVHxe1ThCiPS++uorihUrxrvvvouDg4PacYTIc1JkiQLtXMQ5uq3thoJhHrTxDcZTtVhVlVMVPFV8XVk3rKnaMYRQx7Xdacs+NVSLIYRIs2vXLn744QcWL16MtbU1tra2fPDBB2rHEiLfSGd1UWBN3DeR4LXBxgKrkkclGpVopHKqgkFRFJYeuEG/+QefvrMQlmLIXnDzVTuFEBZNr9fz1Vdf0bJlS5YvX863336rdiQhVCFXskSBFBYfxtLzS43rIRVC+LBB1kcWNFeKorDm+B3eWXrMpL1haQ91AglRkMggF0Ko6sGDB/Tp04f169cD0KtXL4YMGaJyKiHUIUWWKJBWXlxpXF7UYRHVilVTMU3BcfJ2VLoCa8uI5pT1kpEDhYVRFNjxFYSdh6RotdMIYfH2799Pt27duHHjBnZ2dvzwww8MGDBApg4RFkuKLFGg6BU9Uw9NNRZZ5YqWo4ZXDXVDqWzb+fuMWHaMVJ2CTlGM7SPaluft1uVUTCaEisIvwPZJ/2rQgH0RtdIIYdEWL15Mv379SElJoWzZsqxYsYIaNWqoHUsIVUmRJQqUq1FX+eXMLwD4u/gzsfFElROp42ZEPHsuhXPhXizz9lxNt/2VWr5SYAnLkxAJp343TDwcfdfQZucKLceBV0Vw9VE3nxAWqlatWtja2vLSSy8xd+5cXF1d1Y4khOqkyBIFyrab2wBwt3dn7ctrLWIy4f86fD2CLj/+k669e10/BjYrjVajoZSHowrJhFDZ7mmwZ5ppm6M7NHhDjTRCWLTw8HA8PT0BCAoK4siRI5QrV066BwrxiBRZosCYtH8Sv537DYCopCiLLLAOXYug66y0AivAw5Hy3i6E1PWjdZC3ismEyEd6Hdw+Arok0/b7Zw2P3lXBuzJoNFD5lfzPJ4QFUxSF2bNn89577/HXX3/RvHlzAJlcWIj/kCJLFAiRiZHGAgvgxzY/qphGPa8vPGRcHtAkkA+fD5JPBYXl2fop7Jme+fYqL0PT9/IvjxACgJiYGAYPHsySJUsAw71Yj4ssIYQpKbKE6hJSE3h3+7vG9T87/0npIqVVTJT/IuOS6TprLw/jUwAY3Kw0YzsGqZxKCJWEXzI8OnmBQxHTbfZuULFTvkcSwtKdPHmSrl27cuHCBbRaLV999RUjRoxQO5YQBZYUWUJ1P534icP3DgPg6+xrUQWWTq8w5vcTrDh8y9imtdIwoGmgiqmEUNHtw3DeMMcOzUdDvYHq5hFCMH/+fN58800SExMpWbIky5Yto1GjRmrHEqJAkyJLqGrFhRXMPTnXuD695RO6CJkZRVFYffS2SYFVw68I34bUwMvFXsVkQqjoVlqXWUrWUS+HEAKALVu20L9/fwDat2/PokWLjANeCCEyJ0WWUMUfl/5g/qn5XIm6Ymyb2XomFdwrqJgqfy09eJOxq04a1zcNb0aF4i4qJhJCRWuHw41/ID7CsB70ApSoqWokIQS0bt2aHj16ULVqVd5//32srCxvUCohckKKLJHvknRJTD00lcikSGPbF02+oGnJpiqmyl+KopgUWB8+HyQFlrBc8RFweL5pm0dZdbIIIfj9999p06YNbm5uaDQaFi9eLIMwCZFNUmSJfKHT6zj94DTnIs7x2b7PjO3TWk7Dz8WPckUsa2LdCevOGJfHdKjI600t5z40IdJRlLTlPmvB2h58a6uXRwgLlZiYyPDhw5k9ezavvPIKK1euRKPRSIElRA5IkSXy3LmIcwSvDU7X3q18N1r7t1YhkbrWHL/D/D3XjOt9GgaolkWIAiegqWH+KyFEvrp06RLBwcEcO3YMjUZDlSpVUBRFCiwhckiKLJEnQuNCOR9xnsikSMbvGW+yraRzSV4NepWeQT1VSqeus3ejjcsb3mmKg61WxTRC5KPwi3B5W/r25Nj8zyKEMPr999/p378/0dHReHp6snjxYp577jm1YwlRqEmRJXJdqj6Vbmu7mdxzBRBSIYT36ryHg7WDSskKlgFNAgnycVU7hhD5Z1lvCDub+Xatbf5lEUKQnJzMqFGj+O677wBo0qQJS5cuxdfXV+VkQhR+UmSJXJesSzYWWEHuhgl1gysEE1w+fZdBS6T/9/0nQlgKvT6twCrTyjCp8H+VbStdBYXIRzExMaxatQqA0aNH8/nnn2NjY6NyKiHMgxRZItf9e1j2Xzr8Ileu/iUuKZXZO648fUchzM22iWnLz30O3pXVyyKEAMDDw4Nly5YRERFBp06d1I4jhFmRIkvkugn/TDAu21jJJ2L/djU8zrhcL9BdxSRC5LPw82nLnpYzH54QBUlKSgrjxo2jcuXK9OnTB4BGjRqpnEoI8yRFlsg1KfoU3tv+HmcjDF2Cni/9PNZW8iMWm5TKsoM3+WzdGbRWhq5QRR1taFe5uMrJhMgnf0+Es2sNyx0mg1Z+LwiR327dukVISAh79+7F0dGR9u3b4+3trXYsIcyW/KUTueZU+Cm23UwbOWx4reHqhSkgklP1VPl4k3Fdpzfcj9WgtIdakYTIfxfT/g/gW0u9HEJYqE2bNtGrVy/Cw8NxdXVl/vz5UmAJkcekyBK5JlWfalze0nUL3k6W/Qs8MUXHd1svGtetNPDlK9VoUaEYxVzsVEwmRD7a8x3cPW5YDvkVStZRN48QFkSn0/HJJ58wceJEFEWhZs2arFixgjJlyqgdTQizJ0WWyBWp+lRWXTSMUFTarbTFF1gAyw7eZOb2ywDYaq24MLGDyomEUMGuKWnLHuXUyyGEhUlNTaV9+/Zs3boVgCFDhjB16lTs7e1VTiaEZbBSO4AwD3vv7GXdlXUA2FvLL3CAiLhk4/K07jXUCyKEGq7/A2uHQ/KjwV66LwGviqpGEsKSWFtb07BhQ5ycnPjtt9+YOXOmFFhC5CO5kiWeSURiBMvOL+NU+Clj25h6Y1RMpD6dXmHv5XAu3Y8FoFcDfzpW9VE5lRD5bNNYuHP00YpGugkKkQ/0ej2RkZF4eBju+/3kk0/o168fpUuXVjmZEJZHiizxTJadW8bM4zON6y39WlLTq6aKidSl1ytU+HADqfq0CYetreSCsbAAidFwfgOkJhjWo+8aHmv2ggrPg7OXetmEsABhYWH07t2b8PBw9uzZg52dHVqtVgosIVQiRZZ4JkvPLwWgikcVGpRowItlXlQ5kbq++/uiSYHVokIxutXxUzGREPlk52TY+1369pqvgX/9/M8jhAXZs2cPISEh3L59GwcHB44cOULDhg3VjiWERZMiS+RIki6Jrmu6EpEYAUAr/1YMrDZQ5VTqUhSFaVvSRhO88kVHrB7NiyWE2Xt4w/BYrCK4Pxq5rGgA+NZWLZIQ5k5RFKZMmcKYMWPQ6XRUqFCBlStXUqVKFbWjCWHxpMgS2ZaiS+Htv9/mWvQ1Y1tIxRD1AhUAKTo9X244Z1yf0bOWFFjCcigKnPnDsFy9BzQZrmYaISxCREQEffv2Ze1aw0TfPXv2ZPbs2Tg7O6ucTAgBUmSJbLoUeYmX17xsXHewdmBPjz3YWNmomEp9w5cdY/2Ju8b1VhXl/hNhoWSACyHyxcCBA1m7di12dnZMnz6dQYMGodHIh3tCFBRSZIksuxt716TAsrayZmmnpRZfYN2PTjQpsJYMbICDrVbFRELko79GwcGf09aLBamXRQgL8s0333Djxg1++uknata03AGnhCioZNgzkWVTD081Lrfya8XR3kcp7SajFq05fse4vG5YExqW8VAxjRD57MwaUHSGZc/yYO+mbh4hzFRUVBTLly83rgcGBnLgwAEpsIQooORKlsiSFF0KG69tBMDZxpkJjSeonKjgmLPrCgBeLnZULuGqchohctHNg7D1U0hNzHyf+HDDY+/VENAUtPJnRYjcdvToUYKDg7l8+TKurq60b98eQLoHClGAyV9DkSVJuiTj8rx283Czk0+rATadDuVetOF781JNX/mDJ8zLkV/g2q6n76fRgncV0Fp212EhcpuiKPz000+88847JCUlUapUKdzd3dWOJYTIAimyRLaVLiJdBAEexiczeNFh4/qQ5mVUTCNEHji/wfBYvQcEPWEOPI+yMtmwELksNjaWwYMH89tvvwHQqVMnfvnlFymyhCgkpMgSWbLywkq1IxQoyal6akzYbFz/8PkgijrZqphIiDzwuCugdxWo2FHdLEJYkFOnThEcHMy5c+fQarVMmjSJ9957DysruZVeiMJCiizxVKsvrmbK4SnGdTutnYpp1BeXlErljzcZ1+sHutO/caCKiYTIA3p92nJQJ/VyCGGBDh8+zLlz5/D19WXZsmU0btxY7UhCiGySIks80c5bO/lo70fG9S+bfqliGnUlJOtYdvAGn6w9Y2xzd7Jl2eCGKqYSIo9c2pK2LCMGCpGv+vTpQ1RUFD169KBYsWJqxxFC5IBcdxZP9PXBr43L37X8jo6BlttlaO2JOyYFVgk3ew580FrFRELkMr0ewi9B2HkIPZ7W7lBUvUxCWIDz58/TsWNHwsLCjG1vv/22FFhCFGJyJUtkav/d/VyPvg7A2zXfpqV/S5UTqSs6IcW4/G1IdV6uWVLFNELkgbXD4Oivpm3l2qmTRQgLsWTJEgYNGkRsbCwjRoxg0aJFakcSQuQCKbJEpj7e+7FxuZ5PPRWTFAzHbj4E4KUaJaTAEubp3mnDo62LYTh2rS1U6aJuJiHMVGJiIu+++y6zZs0CoEWLFkyePFnlVEKI3CJFlshQeEI4d2LvAIarWNU8q6mcSF03HsSz7sRdAGytpZetMBN/vgWnfk9bT0kwPHb9GcrLFSwh8srly5cJDg7m6NGjAHz44Yd8/PHHWFvL2zIhzIX8bxYZ2nZzGwoKVTyqMLDaQLXjqOrivRjafrvTuN5PRhIU5uLkSkhNMG2zdoBiFdTJI4QF2Lt3Lx06dCA6OhoPDw9+/fVX2rdvr3YsIUQukyJLZGjr9a0AtC5luQM76PUKOy6G0W/+QWNbmyBvgnxcVUwlRA7smgKX/k7fnppoeOy3AVxLGJYd3MFefsaFyCuVK1fG09OTKlWqsHTpUvz8/NSOJITIA1JkiXSik6PZH7ofgNb+llFkJabo2H81gr9O3OXwjUhstVacuRttsk+XWiX57KXKKiUUIodSk2HrZ4CS8XZre8Nkw1JYCZFn7t+/T7FixdBoNLi5ubF161Z8fX2xsbFRO5oQIo9IkSXS2XlrJ6n6VEq7lSbQzfy7xp25E03H73Y9cZ8POlZkULMy+ZRIiNykYCywXvoRbBxMN3tVkgJLiDy0bt06XnvtNT7//HPefPNNAAICAtQNJYTIc1JkCRNJuiRmH58NQNtSbVVOk/e2nb9v0h0QoHQxJ4a3KU8RBxtsra2oXaooNloZ7EKYgYqdpKASIp+kpqby4Ycf8tVXXwHw22+/8cYbb2BlJX9PhLAEUmQJE3NPzuVa9DU8HTx5rfJrasfJU5FxySYF1oi25RnWqiwajUbFVELkMkWvdgIhLM7t27fp0aMHu3YZekkMGzaMyZMnS4ElhAWRIksYXY26ytyTcwEYU28Mrrbm/Yn33+fuG5e/fKUq3ev5q5hGiDxyYVPaspVWvRxCWIjNmzfz6quvEhYWhouLCz///DPBwcFqxxJC5DMpsgQAOr2OD3Z9QKo+laa+TXmu1HNqR8pz8/ZcBcDexoqQujK6kzAjyXEQ++hDhLDzae22TurkEcJC3Lx5k+eff56UlBSqV6/OihUrKFeunNqxhBAqkCLLgoXFh7Hq4iriUuNYc2kNDxIfYK2xZmTdkWbfZS4xRcfpO4bRA9tXLm72r1dYkPgI+K4GJEaZtge9oEocISyJn58fn376KdeuXWPatGk4ODg8/SAhhFmSIstCbby2kVE7RqVrH1pzKKXdSquQKH+l6tOGsx7dvqKKSYTIZQ+vpxVYts6GR60tBL2oXiYhzNiOHTvw8vIiKCgIgDFjxsgHd0IIKbIs1ZpLa4zLIRVCcLJxoku5Lvi7mu99SQnJOmbtuEx4bBKL998wtrs72aqYSohckBQLv3SCiKug1xnaXEvCiNPq5hLCjOn1er788kvGjx9PpUqV2L9/P46OjlJgCSEAKbIs1rXoawB81PAjgsub9w25iqIQn6xj85l7TN960WSbvY0VdtYy2pMo5EJPwp2jpm3Fq6iTRQgLEB4eTu/evdm4cSMAtWrVUjmREKKgkSLLAl2Pvs7NmJsA2GvtVU6Td5JT9Szad53P1p0xaS/l4cjLNX3xdLajWx0/+dRRFH4HDHPb4eYPvX4HjQbczb/brxBq2Lt3LyEhIdy6dQt7e3tmzJhBv3795G+JEMKEFFkWIkWfwnMrnyMqKYoUfYqxvWGJhiqmylu7LoalK7CsNNC7QSlebypvQIUZOb3a8GjvCsXKq5tFCDOlKApTp05lzJgxpKamUq5cOVauXEm1atXUjiaEKICkyLIQrZa34mHSQ5O2LuW64OngqU6gPJSq07Pq6G1GrzxhbJvevQbtKhdHowE7a5krSBQSd0/A2TWgKE/fF+ClH/M2jxAWTKfT8ccff5CamkpISAg//fQTrq7mPZ+kECLnpMiyAD+d+MmkwNrcdTMaNHg5eqkXKg/tufzApMAa1Kw0nWv4qphIiBxa+3b6e60yo7GCIuY7cI0QarO2tmbp0qWsX7+egQMHSvdAIcQTSZFlxuJT4vnywJesvrTa2Hbw1YPYW5vvfVgAey6FG5fHd6rEgCaBKqYRIoei76QVWEEvgmuJJ+9fsi44FMnzWEJYCkVRmDlzJjdu3OCrr74CwNfXl0GDBqmcTAhRGEiRZcYOhh40KbCmtphq9gVWbFIqP+28AkCz8sWkwBKF18/PpS03GgZ+9dTLIoSFiY6O5vXXX2fFihUAvPjiizRu3FjlVEKIwkSKLDOWqk8FwN/Fn/frvU/jEub/B+Lvc/eNy++0LqdiEiFyKDkeEh9C1C3DeukWUKKmmomEsCjHjx+na9euXLp0CWtrayZPnkyjRo3UjiWEKGSkyDJjl6MuA+Dh4EGzks1UTpP3bkbEM3rlcQAGNy9N7VJFVU4kRDZF34UZ9SApOq3t5dmgtVEvkxAWQlEU5s6dy7Bhw0hKSsLPz4/ly5fToEEDtaMJIQohKbLM2PdHvwcgSZekcpK8pSgKM7dfZvKm88Y2f3dHFRMJkUPh59MKLCsb8KsPTuY5QI0QBc1bb73FzJkzAejYsSMLFy7Ew8ND5VRCiMLKSu0AIm8cuHvAuNy5TGcVk+S9gQsPmRRYbYK8aVvJW8VEQuTAwZ9hZX/Dsldl+Cgc+q0HK/k1LUR+aNGiBVqtli+//JK1a9dKgSWEeCZyJctMjdwx0rj8SrlXVEyS97acTbsPa92wJlTxdVMxjRA5dHwJxD8wLBeroG4WISzEvXv38PY2fCgXHBxMrVq1KFOmjMqphBDmQD4iNUMRiRFEJkUChgmHzX1EQa2VYa6SHaNaSIElCqeIK3DroGG5w9fQZa66eYQwcwkJCQwaNIhq1apx584dY7sUWEKI3CJFlhn6/cLvxuXhtYarFyQfnL0bjU6vAOBgo1U5jRA5dOy3tOUStcBKfpaFyCsXL16kYcOGzJkzh7CwMLZs2aJ2JCGEGZIiywwtPbcUgOJOxSliX0TdMHnowr0YOkzfBUAFbxeKudipnEiIHLiyHa4afo7xqgQl66gaRwhztnz5cmrXrs3x48cpVqwY//vf/3jttdfUjiWEMENyT5aZWXN5DfcTDPcovVT2JXXD5LFpWy4Yl6d0q45Go1ExjRA5kJIIv4VAaqJhvWInkJ9jIXJdUlISI0eO5IcffgCgWbNmLFmyhBIlSqicTAhhrqTIMjP77+43LvcK6qVikrz318lQAOoFuMu9WKJgUhS4ewziwjPenhyXVmA1eBPq9M+3aEJYki+//NJYYI0dO5YJEyZgbS1vgYQQeUd+w5iZMw/OADCs5jDc7My38Ji3+6px+YPng1RMIsQTXN4Kv3bJ2r5tPgFr6fIqRF4YOXIkW7duZcyYMXTs2FHtOEIICyBFlhkJTwjn0sNLANhpzfPN2s2IeH7Ze42t59KGba8mV7FEQRXx6MMAO1dwD8x8v7JtpMASIhelpKSwcOFC+vXrh5WVFU5OTuzYsUO6lQsh8o0UWWYkMjHSuNwuoJ2KSfLO7J2X+XXfDeP6V12qYmUlfzRFAZSSAH89mq8uoCn0+O3J+wshcsXNmzcJCQnhn3/+ISIiglGjRgFIgSWEyFdSZJkhd3t3ijsVVztGnohP0gHQuKwHbYK8eaG63LQsCqioW2nL5dqql0MIC7JhwwZ69+7NgwcPcHNzo1y5cmpHEkJYKBnC3YzMOTEHAEVRVE6SN+5HJ7Lq6G0AmpUrRr/GgTjayucEooDa8ZXh0d4N6vRTN4sQZi41NZVx48bRsWNHHjx4QO3atTly5AgvvfSS2tGEEBZK3qGakZsxNwGwtjK/f9YHsUnU+2Krcb26XxH1wgiRFZce/bya6f2RQhQUd+/epUePHuzYsQOAoUOHMmXKFOzs5P+eEEI95vdu3ELturWLUw9OAfBu7XdVTpO7IuOSqf35FuN6u8reNCjtoWIiYdGu7YGDc0HRPXm/5FjDY8+leZ9JCAt269Yt9u7di7OzM3PnziUkJETtSEIIIUWWObgbe5c3t75pXK/jXUfFNLlHURT+Pnef7efDjG31AtyZ3ds8Xp8opLZPgmu7srizBlzkvkEh8lLdunVZuHAhtWrVonz58mrHEUIIQIoss3Dw3kHj8pLnl+Dj7KNimtzz2rwD7LqYNolr6WJOLH+joYqJhEW4vA3uHs98e+Q1w2PtvuBd5cnnKlYRXM3j/6MQBcX9+/d5/fXXmTBhAjVq1ACge/fu6oYSQoj/kCLLDMw8NhOAJr5NqOL5lDd9hUBcUir9Fxxk/9UIY1unaj70rOevYiphERIewuKuoE99+r5BLxjmtxJC5Jtdu3bRvXt37ty5w40bNzh69KgMzS6EKJCkyDIDMckxADhYO6icJHccv/nQpMA6/vFzuDnYqJhImL3UJLh1CGJDHxVYGqjRM/P9XUtAQLN8iyeEpdPr9UyePJlx48ah0+kICgpi8eLFUmAJIQosKbIKudPhp4lOjgZgaI2hKqfJHbN2XjEuHx3fVgoskffWDIMTy9LWre3gpZnq5RFCGD148IA+ffqwfv16AHr16sWPP/6Is7OzysmEECJzUmQVcnvv7DUu+zgV/ns/jt98yM4LhoEuKpdwpaiTrcqJhEWIeFTYu5YEOxeo/JKqcYQQBjdu3KBp06bcuHEDOzs7fvjhBwYMGCBXsIQQBZ4UWYXY3zf+5ruj3wHQMbAjjjaOKid6NkmpOjrP2GNc/7lPXRXTCIuRmgS3Hg0e0+FLw71WQogCwdfXlwoVKmBnZ8eKFSuoXr262pGEECJLpMgqxP59FauBTwMVkzw7RVHo+uM/xvWhLctQ3M1exUTCYkTdSlv2kTdwQqgtKioKW1tbHBwc0Gq1/Pbbb9ja2uLq6qp2NCGEyDIrtQOI7NErenbc3MHis4tZdt5wD0mvoF68XO5llZM9m3l7rnHydpRxfUTbCiqmERbj4hb47dHEpbbOUERGsBRCTUeOHKFWrVq88847xjZPT08psIQQhY5cySpkDt87zFt/v2XS1qxk4R7lLClVx2frzhjXD45rg9ZK+tuLfHBsMTy4aFj2KKNuFiEsmKIozJo1i+HDh5OcnIxeryciIgJ3d3e1owkhRI5IkVXIRCZGAuBm50Ytr1q09GtJwxKFe4LeoPEbjcsTOlemmIudimmE2UtJhO1fQPTdtHuxGrwJLcepm0sICxUTE8OgQYNYunQpAC+++CILFiygaNGiKicTQoice6YiKzExEXt7uW8mP628sBKAMm5l+K7VdyqneXbLD95ErxiWHW21dKvjp24gYf6u7YI9003bfGuDnQwHLUR+O3nyJF27duXChQtYW1vz5ZdfMmLECBk9UAhR6GW7yNLr9UycOJFZs2Zx7949Lly4QOnSpRk/fjwBAQEMGDAgL3IK4Mi9I/xz1zA4RKqSqnKa3HHmbrRx+dhHz2FrLbcJijwQEwpn1xomGr53ytDm5g8N3gBHDwh6Ud18Qlig5ORkOnbsyK1btyhZsiTLli2jUaNGascSQohcke13tJ9//jkLFizg66+/xtY2bQ6jKlWqMHfu3FwNJ0wN3zbcuPxB/Q/UC5KLUvV6AIa1KisFlsg7mz6Av0bCxjFw9FdDm3sANBwK1buDtczHJkR+s7W1Zfbs2XTs2JGjR49KgSWEMCvZvpK1cOFCfvrpJ1q3bs0bb7xhbK9evTrnzp3L1XDCVExKDAD9KvejknslldM8m/vRiXz390V+3XdD7SjCXOlS4O5xw9Wrx5MNl6xnGEHQSgt1+qubTwgLdPbsWe7cuUPr1q0B6NixIx06dJDugUIIs5PtIuv27duULVs2XbteryclJSVXQon0dtzcQare0EXw1aBXC/UfpKiEFOp9sdWkrX6gh0pphNla+45h9MB/qzcIqgWrk0cIC7d48WIGDx6Mra0tR44cISAgAKBQ/z0TQojMZLt/VqVKldi1a1e69pUrV1KzZs1cCSVMpehSTIZtL2JfRL0wuWDNsdvG5QreLvwxtDFNynmqmEiYFV0KpCbDg0uGdWdvcC8N/o0gsHBPdyBEYZSYmMjgwYPp1asXcXFx1KxZEwcHB7VjCSFEnsr2layPPvqIPn36cPv2bfR6PatWreL8+fMsXLiQdevW5UVGixebEmtcnvPcHOy0hXeI8+jEFMb/eRoADydbNr0rb3pFLvr7c9g52bSt42So1FmdPEJYuEuXLhEcHMyxY8fQaDSMHz+ejz76CK1Wq3Y0IYTIU9m+ktW5c2fWrl3Lli1bcHJy4qOPPuLs2bOsXbuWtm3b5kVG8S/1i9dXO0KOnb4TRbVP/mdcf++5CiqmEWbp0hbTdXs3KF5NnSxCWLiVK1dSq1Ytjh07RrFixdi4cSOffvqpFFhCCIuQo3mymjZtyubNm3M7izBjey6F8+rc/cb1aiXd6FFP5sQSeSR4AZRpBdYOMnKgECr5+++/iYmJoUmTJixduhRfX1+1IwkhRL7J9pWs0qVL8+DBg3TtDx8+pHTp0rkSSpiXsatOmBRYA5sGsuatJnKzs8g7Nk6Gq1hSYAmhmqlTp/Ltt9+ybds2KbCEEBYn21eyrl27hk6nS9eelJTE7du3MzhCPKt/35NVGO28EG5cfrNFGUa1k26CIpecXQsXNqatR15XL4sQFm7NmjUsWrSIpUuXotVqsbe3Z/jw4WrHEkIIVWS5yFqzZo1xedOmTbi5uRnXdTodW7duNQ7HKnKPXtHTcVVHtWPkWKpOz+2HCQCseKMhdQPcVU4kzMqfb0Hiw/TtDkXyO4kQFislJYVx48YxebJh0Jk5c+aYzKMphBCWKMtF1ksvvQQY5rPo06ePyTYbGxsCAgKYMmVKroYTcDXqqnG5jnedQtfFbtG+tCsL9tZys7N4BhFX4Mp2UJS0tuRHV3kbDzd0DwRw84OSdfM7nRAW6datW4SEhLB3714Ahg8fTv/+MtG3EEJkucjS6/UABAYGcvDgQTw9c2deoxkzZjB58mRCQ0OpXr0633//PfXq1ct0/4cPHzJu3DhWrVpFREQEpUqVYtq0aXTsWHiv9mTmYeJDbsXcMq7PfW6uimlyJjQ60bhcqYSriklEobfsNbh3MuNtDd4EF+/8zSOEhdu0aRO9evUiPDwcV1dX5s+fzyuvvKJ2LCGEKBCyfU/W1atXn75TFi1btowRI0Ywa9Ys6tevz7Rp02jXrh3nz5/Hy8sr3f7Jycm0bdsWLy8vVq5cia+vL9evX6dIkSK5lqmgOBl2ktc2vEaqkgqAp4MnWqvCeyXo9SaBaK0K11U4UUDEPYCH1yHmjmE9sFnaVSuAErWkwBIin82YMYNhw4ahKAo1a9ZkxYoVlClTRu1YQghRYORoCPe4uDh27NjBjRs3SE5ONtn29ttvZ/k8U6dOZeDAgfTr1w+AWbNmsX79eubNm8eYMWPS7T9v3jwiIiLYu3cvNjY2AGZ7H9ilh5dIVVLRarQ4WjvyQukX1I6ULVfD4/hyw1lO3Y5WO4oozBIewrSqkBKX1tbuCyheVbVIQgho1qwZ9vb29O3bl6lTp2Jvb692JCGEKFCyXWQdPXqUjh07Eh8fT1xcHO7u7oSHh+Po6IiXl1eWi6zk5GQOHz7M2LFjjW1WVla0adOGf/75J8Nj1qxZQ8OGDRk6dCh//vknxYoVo2fPnrz//vuZTm6YlJREUlKScT06unC96W/s25gZrWeoHSNbFEWh5TfbTdq8XO3UCSMKt5i7jwosDbj6QrEKUKyi2qmEsEh3797Fx8cHgKpVq3LmzBmz/aBTCCGeVbbnyXr33Xd54YUXiIyMxMHBgX379nH9+nVq167NN998k+XzhIeHo9Pp8PY27ebj7e1NaGhohsdcuXKFlStXotPp+Ouvvxg/fjxTpkzh888/z/R5Jk2ahJubm/HLz08mwM1rF++nDTlfsbgLc16rQ59GAeoFEoXL76/DJ26Gr5kNDG2OHjDiNPReBVobdfMJYWH0ej2ff/45gYGB7Nu3z9guBZYQQmQu20XWsWPHeO+997CyskKr1ZKUlISfnx9ff/01H3zwQV5kNNLr9Xh5efHTTz9Ru3ZtQkJCGDduHLNmzcr0mLFjxxIVFWX8unnzZp5mFJCi0xuX/xjamLaVvLGTkQVFVp1dl77Nv0H+5xBCEBYWRseOHRk/fjxJSUkm07kIIYTIXLa7C9rY2GBlZajNvLy8uHHjBkFBQbi5uWWrgPH09ESr1XLv3j2T9nv37lG8ePEMj/Hx8cHGxsaka2BQUBChoaEkJydja2ub7hg7Ozvs7ApfV7XpR6arHSHHHo+w7e1qh72NFFciC1KT4Y83IOIqpD4akXLQdnAtaVh2yp3RTIUQWbd79266d+/O7du3cXBw4Mcff0w3hYsQQoiMZftKVs2aNTl48CAAzZs356OPPmLx4sUMHz6cKlWqZPk8tra21K5dm61btxrb9Ho9W7dupWHDhhke07hxYy5dumQcTh7gwoUL+Pj4ZFhgFWbJesOAIq62hWvY87CYJDp9vxswnc5IiCe6ewxO/Q53jgAK2DiCR1lwLmb4KmTzwwlRmOn1eiZPnkyLFi24ffs2FStW5MCBA1JgCSFENmS7yPriiy+MN75OnDiRokWLMmTIEMLCwpg9e3a2zjVixAjmzJnDL7/8wtmzZxkyZAhxcXHG0QZfe+01k4ExhgwZQkREBO+88w4XLlxg/fr1fPHFFwwdOjS7L6PAUhSFoVuHEpMcA8CgaoNUTpR1Sak62k/baVwP8ilcBaJQyd0T8M8PhmUXH+i5HN78B+xc1M0lhIX6448/GD16NDqdjp49e3Lw4MFsfYgqhBAiB90F69SpY1z28vJi48aNOX7ykJAQwsLC+OijjwgNDaVGjRps3LjROBjGjRs3jF0TAfz8/Ni0aRPvvvsu1apVw9fXl3feeYf3338/xxkKmmR9MjtvGQoVFxsXijtl3HWyoNlxIYw+8w4Y10t5OPJL/8wnlRbCaOuncGmLYdnFB8q3UzePEBbu5Zdfpnv37rRs2ZKBAweikSvJQgiRbRpFyZ1OXUeOHOGjjz5i3boMblovQKKjo3FzcyMqKgpX14J3pWXS/kn8du43AHaF7KKIfRF1A2VBYoqOiuNNi+0j49vi7mReXThFHriyA9aPgAeXoPLL0GwUeFdWO5UQFkVRFBYsWEDXrl1xcXExtklxJYSwBHlVG2Sru+CmTZsYOXIkH3zwAVeuXAHg3LlzvPTSS9StW9fkXimRfeEJ4cYCC8DNzk3FNFmz/8oDkwJrSnB1rn35vBRY4ulCT8HCFw0FFkDVYCmwhMhnUVFRBAcH079/fwYNGsTjz12lwBJCiGeT5e6CP//8MwMHDsTd3Z3IyEjmzp3L1KlTGTZsGCEhIZw6dYqgoKC8zGrWzj44S7d13Yzrm7psKhR/5CZtOGdcbl6+GF1ql1QxjSg0FAXuHDUs2zpD1a4Q2FzdTEJYmKNHjxIcHMzly5exsbHJdNApIYQQ2ZflK1nTp0/nq6++Ijw8nOXLlxMeHs7MmTM5efIks2bNkgLrGX2wO22OsU6lO1HCuYSKabLmXnQix24+BOCVmr4s6FdX3UCicNClwKKXYc1bhvWiAfDCdLBzVjWWEJZCURRmz55Nw4YNuXz5MqVKlWL37t28/fbbheLDPSGEKAyyfCXr8uXLBAcHA/DKK69gbW3N5MmTKVlSrlzkBgdrBwB6VOzBB/XzdlLn3BKTmGJcfrdtefnjLLJmyydwZRtY2YCjO9R4Ve1EQliM2NhYBg8ezG+/Gbqmv/DCCyxYsAB3d3eVkwkhhHnJcpGVkJCAo6MjYOirbWdnZxzKXeSeRiUaqR0h24o42uDn7qh2DFEYnP4jbbj24AUQ1EnNNEJYnNjYWLZu3YpWq+XLL7/kvffekw/IhBAiD2RrCPe5c+fi7Gzo0pOamsqCBQvw9PQ02eftt9/OvXSiQHsQm6x2BFGYhF2APx/Nadf4HSmwhFBB8eLFWb58OVqtlsaNG6sdRwghzFaWiyx/f3/mzJljXC9evDiLFi0y2Uej0UiRlUO3Ym6pHSHbPvrzNADJqTKqpHiKlERY3huSY6FUE2j1kdqJhLAI8fHxvPXWWzz33HN0794dgGbNmqmcSgghzF+Wi6xr167lYQzLdvrBaSKTIgHQUPi6bbQJ8lY7gijoTi6HsHPg5AVd54E22/OgCyGy6fz583Tt2pVTp06xatUq2rdvT5EiRdSOJYQQFiFb82SJ3KcoCpuubjKu1/KupWKarLsWHsf5ezEAhNT1UzmNKNAUBfbPNiw3GgYuUpQLkdeWLFlCnTp1OHXqFN7e3qxevVoKLCGEyEdSZKns7xt/M//0fADqF6+Pi62LyomyZv3Ju8bl4m72KiYRBd71PXDvFNg4Qq3eaqcRwqwlJiYyZMgQevbsSWxsLC1atODYsWO0bNlS7WhCCGFRpM+Oyu7E3TEu9wjqoWKSrFMUhcmbzgNQ078IZYrJ/EYiE7pUWD3EsFwtBByKqptHCDOWmJhIkyZNOHz4MBqNhnHjxvHJJ5+g1WrVjiaEEBZHiiyVKYoCQIfADrT2b61ymqe7G5XA20uOGtebliumYhpR4P1vHETdMCzXH6xuFiHMnL29PS1btuT69ev8+uuvtGvXTu1IQghhsaS7oIqSdElMPjRZ7RjZsvb4HQ5eizSuv9mijIppRIF2ZTvsn2VYbvgWeAWpGkcIc5ScnExYWJhx/YsvvuD48eNSYAkhhMpyVGRdvnyZDz/8kB49enD//n0ANmzYwOnTp3M1nLlbem6pcbl80fIqJsm6H7dfBkCjgR2jWmBvI91QRCbWv2d4rDMA2k1UN4sQZuj69es0bdqUzp07k5KSAoCNjQ0lSpRQOZkQQohsF1k7duygatWq7N+/n1WrVhEbGwvA8ePH+fjjj3M9oDl7kPjAuPx61ddVTPJ0yal6Tt2OIjLe8Id8cLMylPJwUjmVKNAirhgem45QN4cQZmjdunXUrFmTAwcOcO7cOc6dO6d2JCGEEP+S7SJrzJgxfP7552zevBlbW1tje6tWrdi3b1+uhrMUfSr1UTvCEyWm6Gj5zXY6fb/b2DakuXQTFFlkZaN2AiHMRmpqKmPGjOGFF14gMjKSunXrcuTIEapWrap2NCGEEP+S7SLr5MmTvPzyy+navby8CA8Pz5VQluBBwgMWnVmkdowsuR+dxO2HCQBorTR0q1MSN0d54yyEEPnp9u3btGzZkq+++gqAt99+m927dxMQEKBuMCGEEOlke3TBIkWKcPfuXQIDA03ajx49iq+vb64FM3dTDk0hVZ8KgJ21ncppssbRVsuZCe3VjiEKstQkw71YD2+Aolc7jRBmpW/fvuzevRsXFxfmzZtH165d1Y4khBAiE9m+ktW9e3fef/99QkND0Wg06PV69uzZw8iRI3nttdfyIqPZiUqKYu2Vtcb1buW7qZjm6aZtuaB2BFFY3DwARxfB1R2GdRtHsCscE2wLUdDNmDGDZs2aceTIESmwhBCigMt2kfXFF19QsWJF/Pz8iI2NpVKlSjRr1oxGjRrx4Ycf5kVGs3M37q5x+Y/Of+Dt5K1imsxdC4/jx+2X2XPZ0A1Uq9GonEgUeBc2Gh5dS0KXn2HgNrB1VDeTEIXUvXv3+O2334zr5cuXZ8eOHZQtW1bFVEIIIbIi290FbW1tmTNnDuPHj+fUqVPExsZSs2ZNypUrlxf5zJqXgxdlihTMASQSU3S0+Ga7Sdvs12qrE0YUDrpU+OcHw7KTB1SVT9qFyKnt27cbp0nx8fGhZcuWakcSQgiRDdkusnbv3k2TJk3w9/fH398/LzKZvatRV9WO8FRrjt8xLvsWcaBbHT/qBbirmEgUSAmRcG234f4rXUpae9sJ6mUSohDT6/V8+eWXjB8/Hr1eT+XKlfHx8VE7lhBCiGzKdpHVqlUrfH196dGjB7169aJSpUp5kctsXYq8xOidowHQFODud1HxaW+Yt49qgY02R/NWC3P3+0C4tDl9u69c9RQiu8LDw+nduzcbNxq63fbt25cZM2bg6ChdboUQorDJ9jvnO3fu8N5777Fjxw6qVKlCjRo1mDx5Mrdu3cqLfGbnk38+MS73q9JPvSBZ9EpNXymwROYiH12V9aoE/o0MX83fl8EuhMimvXv3UrNmTTZu3IiDgwPz5s1j/vz5UmAJIUQhle13z56enrz11lvs2bOHy5cvExwczC+//EJAQACtWrXKi4xmIzo5muNhxwGoVqwarwa9qnKijK08fIuJf51VO4Yo6BIewoNLhuV2E6H/BsNXyw9UjSVEYXTq1Clu3bpFhQoV2L9/P/36FfwP4YQQQmQu290F/y0wMJAxY8ZQvXp1xo8fz44dO3Irl1lqt7KdcXlCo4J5z4perzByxXHjeikPJxXTiAIt8lrask8NtVIIYRYGDhyITqejV69euLjIlWAhhCjsctwPbM+ePbz55pv4+PjQs2dPqlSpwvr163Mzm9lRUADwd/EvsKMKbjwdalx+t015hrWSoYLFI0cWwjcV4Osyhq+FLxraXUqAowyKIkR2HDx4kFatWhEZGQkY7tEdMmSIFFhCCGEmsl1kjR07lsDAQFq1asWNGzeYPn06oaGhLFq0iPbt2+dFRrOQpEsiLiUOgJltZqqcJnN3oxKNy683DcTKquAOziHy2YnlEBsK8eGGr8QoQ7u3DH4jRFYpisIPP/xA48aN2bZtG+PGjVM7khBCiDyQ7e6CO3fuZNSoUXTr1g1PT8+8yGSWOq3uZFy2tbJVMcmTRcQlAdC5Rgmc7J6pN6korGLvw//GQ0KEafu9U4bHtp9BubaPGjXgIVc7hciK6OhoXn/9dVasWAHAyy+/zBdffKFyKiGEEHkh2++i9+zZkxc5zFqSLonQOEM3PDutHT7OBXPOk8QUHTO2XQZArl9ZsLNr4MTSzLeXqAleQfmXRwgzcOzYMYKDg7l06RLW1tZ88803vP322wV6Kg8hhBA5l6Uia82aNXTo0AEbGxvWrFnzxH1ffPHFXAlmLqKSolh/Je1eta3BW1VMk7m4/7d332FNXX8YwN8QNjJEGSIIuLeCuOumxVG3goqz2lrrqlat1tbVqq2tu6itVbFKRbFa+1PrQq111IW4cANuUERANiTn90dqEBkChlwg7+d58uTcc9ebGDBf7r3npmVi5eHb6uk+7o4SpiGtEkJ1KmCsqsDGg3Oq58pNAI+R2Zc1twdc3tFuPqJSbt++fejVqxfS0tJQpUoVbN26FS1atJA6FhERFaMCFVm9evVCVFQUbG1t0atXrzyXk8lkUCgUmspW6j1JfoKuO7oiTZGm7jMzKHmj9e2+9AjjfruQra9tTRuJ0pDWPb0B7PwoZ79tXcCtZN5mgKg0adq0Kezs7NCgQQNs3LgRFSpUkDoSEREVswIVWUqlMtc25S0mJQadgjqppw31DLG0w1Lo65Ws65z+ufU0R4G1bXRLidKQJNISVM9GFkBDb1Vb3xhoOjLvdYgoXw8ePEDlypUhk8lQoUIFnDhxAg4ODtDT483diYh0QaF/2//6669IS0vL0Z+eno5ff/1VI6HKgnNR59Tt9o7tcX7IebR1bCthopwyFUoMWXdGPb3xg2aI/LYbmrlyOG6dZFoB6LZY9fCaD1hXlToRUan066+/olatWtiwYYO6z9HRkQUWEZEOKfRv/BEjRiA+Pj5H/4sXL3iH+le8vCeWqb4plrRfInGa3MWlZKjby3waox1PESQiKrKUlBSMGjUKw4YNQ3JyMv744w8IIaSORUREEih0kSWEyHU0pAcPHsDS0lIjocqSBhUbwEBuIHWMHJLSMuHxzSH1dC+3yhKmIUld+f2/Br8MEhXVzZs30aJFC6xbtw4ymQxz5szBzp07OXogEZGOKvAFQm5ubpDJZJDJZOjUqRP09bNWVSgUiIiI4M2ISwmlUqDe7P3qaXPjknWdGGlZRorqOSVO0hhEpdXWrVsxatQoJCYmwtbWFgEBAfD09JQ6FhERSajA365fjioYGhoKLy8vlCtXTj3P0NAQLi4u6Nu3r8YDkubFv3KaoGtFMxyYVLKuFSMt2D0JuPlfoZ3yXPXcapx0eYhKqRs3bmDQoEFQKpVo27YttmzZAgcHB6ljERGRxApcZM2ePRsA4OLiAh8fHxgbGxdbqLLgh3M/SB2hQIInt4OeHk9n0SmKTODc+pz9FWtqPwtRKVerVi3Mnj0bqampmDdvXrazPIiISHcV+n+DYcOGFUeOMmXL9S14kvwEAGBpxOvUqAQb+idgbAEYW3I0QaIC+uOPP1C/fn1Ur14dADBr1iyJExERUUlToCLL2toaN2/eRMWKFVG+fPl8L+SNjY3VWLjSatHZRer21KZTJUxC9Ab2DQBTDtlPVBAZGRmYPn06lixZAjc3N5w8eZJndRARUa4KVGQtXboU5ubm6jZHS8pfpjITALCswzLYm9lLnCaLEAITA0Nx8s4zqaMQEZUq9+7dg4+PD/79918AQIcOHXjfKyIiylOBiqxXTxEcPnx4cWUpcxrZNJI6QjYPnqfgz4uP1NPVbMzAepmIKH979+7FkCFDEBsbC0tLS/j7+6sHgyIiIspNoa/JCgkJgYGBARo0aAAA2LVrFzZs2IC6detizpw5MDQ01HhI0oxv9oSp27vHv4PqtuV4VLIsEwJ4dAFIjcver1RKEoeotMnMzMSsWbOwcOFCAECTJk2wbds2VK3K6xeJiCh/hS6yRo8ejenTp6NBgwYIDw+Hj48P+vTpg6CgICQnJ2PZsmXFELP0iE+LlzpCnhLTVKcxNqhsifqVOSBHmXd1B7D9g/yXkfF0J6K8KJVKBAcHAwDGjh2LxYsXw8jISOJURERUGhS6yLp58yYaN24MAAgKCkK7du3w22+/4cSJExgwYIDOF1lbrm9Rt43kJec/4/uxyTgXqbof0vQutSVOQ1oRd1/1bGwFWDrlnO/yDmBipc1ERKWKoaEhtm3bhtOnT8Pb21vqOEREVIoUusgSQkD53+lGhw4dwvvvvw8AcHJyQkxMjGbTlUKJ6YkAAFsTW5gbmkucBlh68CZO3onB2f8KrNr25mhVrYLEqUgrji9VPdfqAvReI20WolJAoVDgm2++QVpaGhYsWAAAcHZ2hrOzs8TJiIiotCl0keXh4YFvvvkGnp6e+Pvvv7F69WoAQEREBOzs7DQesLTqVrWb1BGQkq7A8uBb2fo8XPIfgp/KkHK2quuxDMtJnYSoxIuOjsbgwYNx6NAhAMCAAQPQsGFDiVMREVFpVegia9myZfD19cUff/yBmTNnqm/GuH37drRq1UrjAanolEKo28sHNEY5I320qlZRwkSkNZHHgZibqna9XpJGISrpjh07hgEDBuDx48cwNTXFmjVrWGAREdFbKXSR1bBhQ1y+fDlH//fffw+5XK6RUKVVmiING8M2Sh0Dh8KiseXMPaRkKNR9XvXsYWyg2/8+OuXy9qy2VRXpchCVYEqlEosWLcLMmTOhVCpRp04dbN++HXXr1pU6GhERlXKFLrJeOn/+PK5duwYAqFu3Ltzd3TUWqrRaeHqhul2nQh1JMlx6EIdRv57L1telPgssnXN1p+q5yQgWWUR5GDhwILZt2wYAGDJkCFavXg0zMzOJUxERUVlQ6CLryZMn8PHxwd9//w0rKysAQFxcHDp06IDAwEDY2NhoOmOp4H/FH7/f+h0AYKBngC6uXSTJcftJorr9cbtqaOhoiXfr8lo5nfPy3lgssIjy1L17d/z5559YuXIlRo4cyetViYhIYwp9k5zx48cjMTERV69eRWxsLGJjY3HlyhUkJCRgwoQJxZGxVDj28Ji6/ct7v0iYRKVtTRtM71IbXRtUgoGc90LSKRFZn0XU7SldDqISRgiB+/fvq6cHDx6MW7duYdSoUSywiIhIowr97Xvfvn1YtWoV6tTJOh2ubt268PPzw19//aXRcKXRvFbz4G7HUydJIilxwKbeWdPGVlIlISpR4uLi0LdvXzRv3hxPnjxR9zs6OkqYioiIyqpCF1lKpRIGBgY5+g0MDNT3z9I1yRnJOBt1FgBgYmAiaZbg60/evBCVTU9vAuFHAWWmarrL94AZ74lGdP78ebi7u2Pnzp2IiYnBv//+K3UkIiIq4wpdZHXs2BETJ07Eo0eP1H0PHz7EpEmT0KlTJ42GKy18dvuo27YmtpLlyFQosefSYwCAoZynvuiUiGOAX1MgaJhqWt8EaP6RtJmIJCaEwKpVq9CqVStERETAxcUFJ06cQI8ePaSORkREZVyhi6wff/wRCQkJcHFxQbVq1VCtWjW4uroiISEBK1euLI6MpYa1sTXcbN0k2//DuBR1e2KnmpLlIAnE/HfTaQMzoGJNoNV4afMQSezFixcYOHAgxo4di/T0dPTs2RMhISFo2rSp1NGIiEgHFHp0QScnJ4SEhCA4OFg9hHudOnXg6emp8XClzdL2SyW9eHrJwZvqdg27cpLlIC27dRDYM1nVdm0LDAqUNg9RCTB79mxs3boV+vr6+O677zBp0iQObkFERFpTqCJr69at+PPPP5Geno5OnTph/Hj+tfxx4mNEJkRKHQMAkJSmuvlwy6oVeF8sXXL3RFbbta10OYhKkDlz5uDixYv4+uuv0apVK6njEBGRjinw6YKrV6/GwIEDce7cOdy6dQtjx47F1KlTizNbqXDiUdYXXIdyDpLl+GzbRRy6Fg0A6NlYuhwkoSYjgJafSJ2CSBJJSUlYtWoVhBAAAAsLCwQHB7PAIiIiSRS4yPrxxx8xe/Zs3LhxA6Ghodi4cSNWrVpVnNlKBQHVf+h1K9SFvZm9JBkyFEr8HvJAPc1TBXWUxCNbEknl2rVraN68OcaOHavz1wYTEVHJUOAiKzw8HMOGDVNPDxo0CJmZmXj8+HGxBCtt7E2lKbAAICktU90+NLktmjhbS5aFtCTuPrBnCrBzDHBzv9RpiCQTEBCApk2b4urVq7C3t0fDhg2ljkRERFTwa7LS0tJgZmamntbT04OhoSFSUlLyWatsOxB5APNOzZM0w7PENDT55pB62s7CWMI0pDXn1gNn12bvMykvTRYiCaSmpmLixIn4+eefAQCdOnVCQEAA7OzsJE5GRERUyIEvvvrqK5iamqqn09PTMX/+fFhaWqr7lixZorl0JViGMgOf/f2ZerpOhTqS5DgV/kzdblHVGubGOW8UTWWAUgFc3wMkqq67wwPVza/h0gao8S5gaAY06C9dPiItun37Nvr374/Q0FDIZDLMmjULX331FeRyDvhDREQlQ4GLrLZt2+LGjRvZ+lq1aoXw8HD1tC4Nj5uuSFe3v2vzHbpW7SpJDqXqkjDYmBsh8KOWkmQgLQg/CmwbkrPf5R2g9UStxyGSUnR0NC5fvgwbGxsEBATg3XfflToSERFRNgUuso4ePVqMMUqfO3F31O2OVTpKmESlhi0HuyiThACirwAPzqmmzWwA59aqtpE50NhXumxEEmndujUCAgLwzjvvoHLlylLHISIiyqHQNyMmlT9u/6Fu6+vxbaRi8s9i4PDXWdN29QHvjdLlIZJAZGQkRowYgR9//BH16tUDAPj4+EicioiIKG8FHl2QslMKJQDAy8WLRRYVn2f/HTE1tgSsqwFug6XNQ6Rlf/75J9zc3HD06FGMHj1afR8sIiKikozVwVuqYVVDkv0mp2di0b4buHA/TpL9k5Zc/E313OYzXntFOiUjIwNffPEFfvjhBwBA8+bNERAQoFPX/hIRUenFIquUOn4rBv4nI9XT1maG0oWh4vHqX+zLu0qXg0jLHjx4AB8fH5w8eRIA8Omnn+K7776DoSF/zxERUenAIquUSleoTld0rWiG0W2rolMd3humzHk5XDuQNdgFURl3/fp1vPPOO3j27BksLCywYcMG9OnTR+pYREREhVKka7L++ecfDB48GC1btsTDhw8BAJs2bcLx48c1Go7ezM7CCAOaVYGNuZHUUUjTbgdntY04eiTphurVq6N+/fpwd3dHSEgICywiIiqVCl1k/f777/Dy8oKJiQkuXLiAtLQ0AEB8fDwWLFig8YCUO177rQMehaie7RsC+iyiqeyKjo5W/1+ir6+P7du348SJE6hWrZrEyYiIiIqm0EXWN998gzVr1mDt2rUwMDBQ97du3RohISEaDUd5G7/lAgAWW2Xa3VOqZwNTaXMQFaMjR46gUaNGmDJlirqvYsWKMDY2ljAVERHR2yl0kXXjxg20bds2R7+lpSXi4uI0kYkKoZ6DpdQRqDg8jwSeXFW16/WWNApRcVAqlfjmm2/g6emJ6Oho/P3330hKSpI6FhERkUYUusiyt7fH7du3c/QfP34cVatW1Uio0uBB4gOpIwAAPunA02nKpEDfrHZ5F8liEBWHp0+fokuXLvjqq6+gVCoxcuRI/PvvvzAzM5M6GhERkUYUusj68MMPMXHiRJw+fRoymQyPHj1CQEAApkyZgjFjxhRHxhInPi0epx+fBgDI9eQSp6EyJ/4BkPBI1XZqDrjmPHJMVFodP34cbm5uOHDgAExMTODv749ffvkFpqY8LZaIiMqOQg/hPn36dCiVSnTq1AnJyclo27YtjIyMMGXKFIwfP744MpYYQgiMOTQGJx6dUPd5VvGUMBGVOeFHgV97Zk13WwIY8ssnlQ2JiYno1asXnj17htq1ayMoKAj169eXOhYREZHGFbrIkslkmDlzJqZOnYrbt28jMTERdevWRblyZX+I6XPR57IVWG0qt4GLpYvWc8SnZGh9n6QlMbdUz3IjwLklYFNL2jxEGlSuXDmsXbsWv//+O9asWaMT/28QEZFuKvLNiA0NDVG3bl1NZinxniQ/Ubf39d0HBzMHrWeISUyDxzeH1NMGekW61RmVNOc3AvumAxkpqulaXQDvjdJmItKAM2fOIDExER07dgQA9O7dG717czAXIiIq2wpdZHXo0AEymSzP+YcPH36rQKVBi0otULlcZUn2fTYiVt1uV9MGlqYG+SxNpcbNfUBGcta0Y1PpshBpgBACK1euxJQpU2BpaYkLFy7A0dFR6lhERERaUegiq3HjxtmmMzIyEBoaiitXrmDYsGGaykV5eHlbLAdLY2z8oJmkWegt7fsCeHBG1Y65qXp+92ugsS9gVkG6XERvKT4+HiNHjsTvv/8OAGjXrh3Mzc0lTkVERKQ9hS6yli5dmmv/nDlzkJiY+NaBKH8rD6uGz3csz8EQSrUX0cC/fjn7beuywKJS7cKFC+jfvz/u3LkDAwMDLF68GOPGjcv3DAgiIqKypsjXZL1u8ODBaNasGX744QdNbZJe8SI1A5//fgnXHicAAMyMOHR8qSUEcGqlqi2TAz6bVG0zG54mSKWWEAI///wzJk6ciLS0NDg7O2Pbtm1o1oxH3ImISPdorMg6deoUjI2NNbU5eoVSKbD2WDj2Xo5S9y31aSxdIHo7j0OBk/8VWSZWQO1uUqYh0giZTIZ///0XaWlp6N69O/z9/WFtbS11LCIiIkkUusjq06dPtmkhBB4/foxz587hq6++0lgwyrLs0E2s+O80QQA4NrUDrEwNJUxERZb4BLi+J2vae5N0WYg0QAihPhXQz88PrVu3xsiRI3l6IBER6bRCF1mWlpbZpvX09FCrVi3MmzcP7733nsaCUZa7sVmjzi3zaYwqFXg9VqmUkQps7A48va6atq0HuLSWNhPRW/D398fu3buxbds26OnpwdTUFKNGjZI6FhERkeQKVWQpFAqMGDECDRo0QPny5YsrE+Xhq/fropebNEPH01tQKoHYcOD0GlWBZVIeqOwBNOFonFQ6JScnY9y4cdiwYQMAIDAwEIMGDZI4FRERUclRqCJLLpfjvffew7Vr11hkaVFiaqbUEeht/G88cGFz1nSvNUCtztLlIXoLN27cQL9+/XDlyhXo6elh3rx5GDBggNSxiIiIShS9wq5Qv359hIeHF0cWykVETBKCrz+ROga9jeirqmcjC+CdSSywqNTasmULPDw8cOXKFdjZ2eHQoUOYOXMm9PQK/V8JERFRmVbo/xm/+eYbTJkyBbt378bjx4+RkJCQ7UGadSv6hbrdqhrvn1Sq9f0F8JwjdQqiIvn6668xaNAgJCYmon379ggNDUWHDh2kjkVERFQiFbjImjdvHpKSktC1a1dcvHgRPXr0gKOjI8qXL4/y5cvDysqKpxAWI7cqVqhTyULqGESko7p16wZjY2N8+eWXOHToEOzt7aWOREREVGIV+JqsuXPn4uOPP8aRI0eKM0+J9jjpsdQRqLSIfwjs+xxIiQNibkmdhqhI7t69C2dnZwCAu7s77ty5AwcHB4lTERERlXwFLrKEEACAdu3aFVuYku7HCz8CADKUGVrZ35OEVKz++45W9kUadu1/qserzPmXfyod0tPTMW3aNKxZswYnT56Eu7s7ALDAIiIiKqBCjS6oyzeXTFekQyEUAID3nIv/fmCHwqIx6tdz6mlTQ3mx75M06Nx61XOVlkCzjwBLR6BSI2kzERXA3bt34e3tjTNnzgAAjhw5oi6yiIiIqGAKVWTVrFnzjYVWbGzsWwUqqfZG7FW3Wzq0LPb9vVpg1bY3x4wudYp9n6QhMbeAmBuqtm1doH4fafMQFdDu3bsxdOhQPH/+HOXLl8fGjRvRvXt3qWMRERGVOoUqsubOnQtLS8viylKixaXGqdsuFi7Fvj9jAz2kZijxXd8G8Glapdj3Rxr09HpWu81k6XIQFVBGRga+/PJLLFq0CADQrFkzbN26FS4uLtIGIyIiKqUKVWQNGDAAtra2xZWlVOhRrYdWT5tsXb2i1vZFGrJtmOrZ3EF1miBRCffbb7+pC6yJEydi0aJFMDQ0lDgVERFR6VXgIkuXr8ciylfiEyA9KWtaTw4oFIDHB9JlIiqEIUOGYN++fejXrx/69u0rdRwiIqJSr9CjCxLRK678DmzPo5hq5KPdLEQFpFAo4Ofnh1GjRsHU1BR6enrYsmWL1LGIiIjKjAIXWUqlsjhzEJVONw+onuWGgJ5BVn9ld8CisjSZiPIRHR2NQYMG4fDhwwgNDcX69euljkRERFTmFOqaLNKOTIUSqRksaku83z8ELm9Ttfv7A7W7SRqH6E2OHj2KgQMHIioqCmZmZvD09JQ6EhERUZmkJ3UAymlF8C11W67Ha+FKpIzUrAILABybSZeF6A2USiUWLFiATp06ISoqCvXq1cO5c+cwaNAgqaMRERGVSTySVQI9jEtVt+0tjCVMQgUy6SpQzkbqFES5iomJUQ9sAQDDhw+Hn58fTE1NJU5GRERUdrHIKmHiUzLwe8gDAMCMLrU5qmNpYGQhdQKiPKWmpuLcuXMwMTGBn58fRowYIXUkIiKiMo9FVgmRnqnEgr3X4H8yUt1XsZyRdIEod3H3gNAtQEay1EmI8iSEUP+BxtHREUFBQahQoQIaNGggcTIiIiLdUCKuyfLz84OLiwuMjY3RvHlznDlzpkDrBQYGQiaToVevXsUbUAvORcZmK7CaupRHj8YO0gWi3B1ZABxdAJxYpprWMwDkBvmuQqRNz58/R+/evbFz5051X/v27VlgERERaZHkR7K2bt2KyZMnY82aNWjevDmWLVsGLy8v3LhxA7a2tnmuFxkZiSlTpqBNmzZaTFt80hVZownu+KQV3KuUlzAN5SntherZpQ1gWxdwbgUYmEibieg/Z8+ehbe3NyIjI3Hq1Cl07twZJib8fBIREWmb5EeylixZgg8//BAjRoxA3bp1sWbNGpiamuZ77xaFQgFfX1/MnTsXVatW1WLa4lfPwYIFVmlQvy/QdRFQr5fUSYgghMCPP/6I1q1bIzIyElWrVsVff/3FAouIiEgikhZZ6enpOH/+fLZ7tejp6cHT0xOnTp3Kc7158+bB1tYWI0eOfOM+0tLSkJCQkO1BVCiKDCDhkeqRkSJ1GqJs4uPj4ePjg/HjxyMjIwN9+vRBSEgI3N3dpY5GRESksyQ9XTAmJgYKhQJ2dnbZ+u3s7HD9+vVc1zl+/DjWrVuH0NDQAu1j4cKFmDt37ttGJV2lyAB+bAo8j5A6CVEOCQkJ8PDwwO3bt6Gvr48ffvgBEyZM4KikREREEpP8dMHCePHiBYYMGYK1a9eiYsWKBVpnxowZiI+PVz/u379fzCmLZkrQRakjUG6Sn2UVWHr6qod5JdW1WEQSs7CwQOfOnVGlShUcP34cEydOZIFFRERUAkh6JKtixYqQy+WIjo7O1h8dHQ17e/scy9+5cweRkZHo3r27uk+pVA0Yoa+vjxs3bqBatWrZ1jEyMoKRUckeCn33pUeISUwHAFSx5g1CS4z0ZGB9Z1VbpgfMeiZtHiIAiYmJSE5OVg8M9MMPP2Du3LmwtraWOBkRERG9JOmRLENDQzRp0gTBwcHqPqVSieDgYLRs2TLH8rVr18bly5cRGhqqfvTo0QMdOnRAaGgonJycii3r3w/+LpbtCiEw/ffL6umlPo2LZT9UBFGXso5i2dSWNgsRgKtXr6JZs2bw9vZGZmYmANUfklhgERERlSySD+E+efJkDBs2DB4eHmjWrBmWLVuGpKQkjBgxAgAwdOhQVK5cGQsXLoSxsTHq16+fbX0rKysAyNGvSUIInIs+BwCQy+Qa2258Sga+/es6EtNUX5ZmdKkNYwPNbZ/e0rkNWe0Pj0iXgwjAr7/+ijFjxiA5ORnx8fG4e/dujiP3REREVDJIXmT5+Pjg6dOnmDVrFqKiotC4cWPs27dPPRjGvXv3oKdXci4d863jq5HtJKRmoNHcA9n6+jVx1Mi2SUMuBaqebesBBsbSZiGdlZKSgvHjx2PdunUAgHfffRebN2/O9z6CREREJC2ZEEJIHUKbEhISYGlpifj4eFhYWBRonQxlBtw3qYZD/tvnb1gbv/2pOX1WnUDIvTgAgLmRPn4e6oGW1Sq89XZJQzLTgW9sVO2PjgIObpLGId108+ZN9O/fH5cuXYJMJsPcuXPxxRdfQC7nEW8iIiJNKEptUBCSH8kqDd7f8b66ranTBW8/SQQAVLI0xqkZnTSyTdKg2wez2uVdpctBOksIgaFDh+LSpUuwtbXFb7/9hk6d+LuCiIioNCg55+GVULGpsXiU9AgAYKpvCksjy7feZnqmEgmpquuw/Ec0e+vtkYY9vQHcPZk1bWIlWRTSXTKZDOvXr0fXrl0RGhrKAouIiKgU4ZGsfCiFEvP/na+ePupz9K23GRWfihYLs0ZTNNRnnVuixNwC/F4pfGt2li4L6Zzw8HCcOnUKvr6qaz/r1q2LPXv2SJyKiIiICotFVj5uPb+FA3dVg1PYmtrCRN/krbZ3+UE8uv94XD1d3tQALhV4X6wSJe6u6lnfGLCrD3iMlDYP6YydO3dixIgRSExMhLOzM9555x2pIxEREVERscjKR6YyU91e77X+rbf3e8gDdbtXYwcs9WkMmUz21tslDVFkApv7qtoVqgMfBue/PJEGpKenY/r06Vi6dCkAoFWrVnB2dpY4FREREb0NnqtWAJXMKsHZ4u2+9GQolPA/GQkA6NHIAcsGuLHAKmkij2W1eZogacG9e/fQrl07dYE1ZcoUHD16tFhvrE5ERETFj0eytOTSgzh1u5nr2w8BTxq0aywQcQxIjVdNNxkBdPpK2kxU5u3duxdDhgxBbGwsrKys4O/vj549e0odi4iIiDSARZaWZCqybkfm05R/pS4xUhOAC5tf6ZAB7kMki0O6486dO4iNjYWHhwe2bdsGV1feKoCIiKisYJGlJb+duQcAqGZjBgM5z9KURNoLIHgekPgkq0+RkdX+YD9gXgkoz+thqHgIIdSnCY8bNw5mZmbw9fWFkZGRxMmIiIhIk1hkaUHQufvYFaq615ZCKd6wNBWbWweAMz/nPs/YEnBsCuhp5mbTRK87dOgQ5syZg71798LCwgIymQwffPCB1LGIiIioGLDI0oKrjxLU7V+GNZUwiY57Fq56rlgLaPZh9nlOzVhgUbFQKBT4+uuvMW/ePAghsGDBAnz77bdSxyIiIqJixCJLCxLTVEPBj+tQHdVty0mcRodd3aF6Nimfs8giKgbR0dHw9fVFcLDqdgAfffQRZs+eLXEqIiIiKm4ssorZ5K2h2HHhodQxCABMK6ienVtJm4N0wrFjxzBgwAA8fvwYpqam+OmnnzB48GCpYxEREZEWsMgqZifuxKjbzaty6PYSwb6B1AmojNu2bRsGDhwIpVKJunXrIigoCHXr1pU6FhEREWkJiywt2TW2NRo5WUkdQzcJAaQnAcpMqZOQjmjfvj3s7e3RqVMnrF69GmZmZlJHIiIiIi1ikaUl+nKZ1BF0kxCA//vA3eNSJ6EyLjw8HFWrVgUA2NraIiQkBLa2tuoh24mIiEh38IZNVLYpM7MXWCbWgENjyeJQ2SOEwNKlS1GrVi1s3px1Y2s7OzsWWERERDqKRRaVbRcDs9qf3QCm3AKsq0qXh8qUuLg49OnTB5MnT0ZmZiaOHDkidSQiIiIqAVhkUdkW8mtW27QCIOcZsqQZ586dg7u7O/744w8YGhrCz88Pv/zyi9SxiIiIqATgN04q2x6cUT339APkBtJmoTJBCIFVq1Zh8uTJSE9Ph6urK4KCgtCkSROpoxEREVEJwSNZ+bj34p7UEehtPI/MaleoLlkMKltCQkIwbtw4pKeno1evXggJCWGBRURERNnwSFY+NoVtAgAkZiQWaf34lAwkpqqGDZfr8QJ4rUt+ltV2ai5dDipTmjRpgi+//BLly5fHpEmTOLgFERER5cAiKx+GckMAwPtV3y/S+pv/vYukdAVcK5qhmk05TUajgriyQ/UsNwT4RZiKSAgBf39/dOjQAS4uLgCAr7/+WtpQREREVKLxdMEC8LDzKPQ6mQolvt9/AwDQub49DOR8q7VO9t97bukobQ4qtZKSkjB8+HB88MEH8PHxQXp6utSRiIiIqBTgkaxicvVRgrpdydJYwiSEWl2lTkCl0LVr19CvXz+EhYVBT08PvXr1gr4+f2USERHRm/EbQx6epTzD+ejzRV4/UynU7YHNqmgiEhWEIhPAf++9UEoahUqvzZs3Y/To0UhOToa9vT0CAwPRrl07qWMRERFRKcEiKw+Xnl5St6tZVSvydpwrmPJUQW35dw2w/wtAKKROQqVUamoqJkyYgLVr1wIAOnXqhICAANjZ2UmcjIiIiEoTfvt/A1dL1yIVWUeuPymGNJSvO8E5Cyw9A6BKC2nyUKl07tw5yGQyzJ49G/v372eBRURERIXGI1lvYG5oXqT1fjujusdWRiZPWSs2T64DuycBaf9d//byvlhdfwAa9Fe15YaAoakk8aj0EEJAJpPB2NgYQUFBCA8Px7vvvit1LCIiIiqlWGTl4XHS47da30hfdZBwRtc6mohDuQnbBdw7mbPfpjZgYqX1OFT6pKWlYcqUKahQoQLmzJkDAKhWrRqqVSv6KcJERERELLJyEZMSg4VnFgIA0hVvN2Sza0UzTUSiV53+CYi6DDy+qJqu2QVo/pGqbWYL2NeXLhuVGhEREfD29sa5c+cgl8sxZMgQFldERESkESyycvH3/b/V7QG1BkiYhHKIuw/8NS17n109oFpHafJQqbRr1y4MHz4ccXFxKF++PDZt2sQCi4iIiDSGRVYu0hRpAIBKZpXQt2ZfidNQNpmpqmd9Y6DdNMDADGjoLW0mKjUyMjIwY8YMLF68GADQokULbN26FVWq8DYLREREpDkssnLx8lTBuhXqSpyE8qRvDLT5TOoUVIoIIdClSxcEBwcDACZNmoRvv/0WhoaGEicjIiKisoZDuOfCRN8EAFC/Iq/tKXEy06ROQKWUTCbDoEGDYGlpiR07dmDJkiUssIiIiKhYsMjKRxfXLlJHoNcFDlQ9CyFtDioVMjMzERkZqZ4eMWIEbty4gd69e0sXioiIiMo8FllUuqQnq55d20ibg0q8x48fw9PTE23btkVsbCwA1dEs3lyYiIiIihuLLCo9QjYByTGqdoeZ0mahEu3w4cNo3Lgx/v77bzx//hyXLl2SOhIRERHpEBZZGpaWqcCIDWfwOD5V6ihlz60DWW0rjgZHOSkUCsybNw+enp548uQJGjRogHPnzqF9+/ZSRyMiIiIdwtEFNeza4xc4cuMpAMBQrgd7S2OJE5VBXgsBo3JSp6AS5smTJxg8eDAOHjwIABg5ciRWrFgBU1NTiZMRERGRrmGRpWHilQEZ/vm8AyqWM5IwTRklN5A6AZVAM2fOxMGDB2FiYoLVq1dj2LBhUkciIiIiHcUiq5g4ljeBnQWPYhFpy6JFi/Dw4UMsWrQI9evz9gtEREQkHV6TRUSlUmxsLJYtW6Y+ely+fHns3buXBRYRERFJjkeyqHRIfAJc+1PqFFRCnD59Gt7e3rh37x5MTEwwevRoqSMRERERqfFI1muSM5KRkpkidQx63c6Ps9pyQ+lykKSEEFixYgXatGmDe/fuoXr16mjWrJnUsYiIiIiy4ZGs1wRcC1C3DfX4ZV5SybHAiyhVO+6e6rmcHVC7m3SZSDLx8fEYOXIkfv/9dwBAv3798Msvv8DS0lLiZERERETZsch6zbnocwCAWuVrwcbURuI0OizxCbCsIfD6UcVeqwCzitJkIslcuHAB/fr1Q3h4OAwMDLB48WKMGzcOMplM6mhEREREObDIeoUQAldirgAA5raeK3EaHff8rqrAkukBphVUfZZOQGUPaXORJOLi4hAZGQlnZ2ds27aNpwgSERFRicYi6xWJGYlISE8AAFS1rFqkbZyJiNVkJN1z7zSwdTCQGqeatqoCTLwoaSSShhBCfaSqQ4cOCAwMhKenJ8qXLy9xMiIiIqL8ceCLPMhl8iKtt/afcABAWqZSk3F0R/gRIOkJoEhXTVduIm0eksTly5fRvHlz3Lx5U93Xv39/FlhERERUKrDI0jAjfVVxNvndmhInKYUy04CjC1XtBt7ApKtA33XSZiKt8/f3R/PmzXH27Fl8+umnUschIiIiKjQWWcWkbiULqSOUPg/PZ7Ur1gQsHQEObKAzkpOT8cEHH2DEiBFISUmBl5cXNm7cKHUsIiIiokLjNVkkrdhw4PxGQJEBJDzI6m89UbpMpHXXr19H//79ceXKFejp6WHevHmYMWMG9PT4dyAiIiIqfVhkkbQOzQHCdmXvc2wG6PMeZbri/PnzaNeuHZKSkmBnZ4ctW7agQ4cOUsciIiIiKjIWWSSN+AfAvX+B+2dV040GAub2qiHb6/WWNhtpVcOGDdGwYUMYGRlhy5YtsLe3lzoSERER0VthkUXS+LUX8OxW1vS7XwPlePNnXREZGYnKlSvDwMAABgYG+N///gcrKyvI5UUb1ZOIiIioJOEFDxqUlqnAw7gUqWOUDi8LLMdmQMevWGDpkN9//x2NGjXCF198oe6rUKECCywiIiIqM3gkS4M2nbqrbuvLOSpenp7eyGr3XgNUqCZdFtKa9PR0TJs2DcuXLwcAnD59Gunp6TA05PV3REREVLbwSNYrzkeff/NC+Xj6Ik3drmPPIdzz9GqRVd5FshikPXfv3kWbNm3UBda0adMQHBzMAouIiIjKJB7J+k9yRjLGHx6vnpbLin7q0kdtq0JPj0eysom7D2zuA7yIBhTpqr4qLQE9niJW1u3evRtDhw7F8+fPUb58efz66694//33pY5FREREVGxYZP0nKilK3V7Wfhnk/PKvWff+BWJuZu+zbyhNFtKa2NhYDBo0CC9evECzZs2wbds2ODs7Sx2LiIiIqFixyPpPulJ1dMXSyBKdnDtJnKYMOjxP9ezUHOi1WnUEy4pftss6a2trrF27FidPnsT333/P0wOJiIhIJ7DI+s/BuwcBALXK15I4SRn0IgqIu6dql3flQBdl3IEDB2BkZIR27doBAHx8fODj4yNxKiIiIiLt4cAX/wl7FgYA8HLxkjhJGfTgbFa76yLpclCxUigUmDVrFjp37owBAwYgOjpa6khEREREkuCRrNcYynk6k8btz7ofEowtpctBxSYqKgqDBg3CkSNHAAC9evWCpSX/rYmIiEg3scgizctIASKOAZn/DWmfnqx67jBTukxUbI4ePYqBAwciKioKZmZm+PnnnzFo0CCpYxERERFJhkUWaV7w18C/fjn7a7yr/SxUbIQQWLBgAWbNmgWlUol69eph+/btqF27ttTRiIiIiCTFIos0KyMFeHZb1S7vAphXUrUrVOOQ7WXQ1atXoVQqMXz4cPj5+cHU1FTqSERERESSY5FFmpOaAKxoDCQ/U023GAs0/0jSSKR5QgjIZDLIZDL89NNP6NmzJ0cPJCIiInoFRxf8T4YyQ+oIpV/cvawCy9wBcHlH2jykUUII/PDDD/D29oYQAgBgbm7OAouIiIjoNTySBSAmJQanH5+WOkbpdnl71iiCZrbAZ9ekzUMa9fz5cwwfPhx//vknAGDPnj14//33JU5FREREVDKxyAJwJ+6Out3QhtcNFcnl7UDif/dFsq0jbRbSqLNnz8Lb2xuRkZEwNDTEihUr0K1bN6ljEREREZVYPF3wFdUsq6GqZVWpY5RON/9SPXeYCQz+XdospBFCCKxcuRKtW7dGZGQkqlatilOnTmH06NGQyWRSxyMiIiIqsVhkvYJfHIsoNT6rbd8AkBtIl4U05tNPP8WECROQkZGBPn36ICQkBO7u7lLHIiIiIirxWGTR27sYmNWu7ildDtKogQMHwtTUFMuXL8f27dthaWkpdSQiIiKiUoHXZNHbibkF/DVN1dY3AWRyafNQkQkhcOvWLdSsWRMA0KJFC9y9excVK1aUOBkRERFR6cIjWVR0GSnAncNZ031/AfT4kSqNEhMTMXToUDRq1AiXLl1S97PAIiIiIio8fiPWoDtPE6WOoF17p2QdxSrvCtThkN6l0dWrV9G0aVNs3rwZGRkZOHfunNSRiIiIiEo1FlkacudpIg5dewIA0NOVATTiH6qey7sC70ySNgsVycaNG9G0aVNcv34dDg4OOHr0KD744AOpYxERERGVaiyyNGToujPqdi83BwmTSKDDF0CTYVKnoEJITk7GyJEjMXz4cKSkpODdd9/FhQsX8M4770gdjYiIiKjUY5GlIS8vRerjXhm17S2kDUP0BuvXr8f69eshk8kwb948/PXXX7C1tZU6FhEREVGZwNEFNWxIC2epI2jH8aVA+BGpU1ARjRkzBqdOncLIkSPRsWNHqeMQERERlSk8kqUB92OTcT82ReoY2nXeP6tdoZpkMahgUlNTsXDhQqSmpgIA5HI5AgICWGARERERFQMeydKAoHP31W1rM0MJk2hBShwQPBd4Ea2a7u8PVG4iZSJ6g/DwcPTv3x8hISG4f/8+Vq1aJXUkIiIiojKNR7I04EVaJgCgtr05nCuYSZymmN3cD5xbD2T+d+SuUiNp81C+du7cCXd3d4SEhKBChQro0aOH1JGIiIiIyjweyXpLu0IfYsOJSADAO9XL2I1bw/8GHr52z6RHF1TPtnWBzgsB66raz0VvlJ6ejunTp2Pp0qUAgFatWiEwMBBOTk4SJyMiIiIq+1hkvYVDYdGYGBiqnm5b00a6MJqWngwE9AcUabnPr1gTqNpeq5GoYO7fvw9vb2/8+++/AIApU6ZgwYIFMDAwkDgZERERkW5gkfUWzt19rm5v/agFmletIGEaDUp5DkQezyqwGg8GXr3BstwQaDpKmmz0RgqFAjdu3ICVlRX8/f3Rs2dPqSMRERER6RQWWUWUkq7Amr/vAACGt3IpOwUWAKx7D4i5+d+EDOixAtCTSxqJ8ieEgOy/QtjFxQU7duyAs7MzXF1dJU5GREREpHs48EURvEjNQJ1Z+9TTzVytJUxTDF4WWBVrAm0ms8Aq4R49eoQOHTpgz5496r727duzwCIiIiKSCI9kAUjL67qjPHy8+by67VLBFF0bVNJ0JOn8szirPXgHYMWBEkqygwcPwtfXF0+fPsXdu3fx3nvv8dorIiIiIonxSBaA789+DwBQCMUbl30Ul4ITt5+pp49MaV9csaQReTyrbV6GiscyRqFQYM6cOfDy8sLTp0/RqFEjHDhwgAUWERERUQnAI1kAjPWNAQC1ytd647IJqRnq9j/TOqivgykT/l0N3Dmsavf+CZDz41ESRUdHw9fXF8HBwQCAjz76CMuWLYOJiYnEyYiIiIgIYJGVTe/qvQu8bMVyRnCyNi3GNBI483NWm/e/KpGePn0KNzc3PH78GKampvjpp58wePBgqWMRERER0StYZBVC2KME9PQ7/uYFS5P4h8Cx74G0F8CLaFVf758Bp2bS5qJc2djY4P3338fJkycRFBSEOnXqSB2JiIiIiF7DIqsQ9l+NQoZCAABcK5aRo1ihvwHnN2Tvq9xEmiyUq2fPnkGpVMLGRnWz6+XLl0OpVMLMzEziZERERESUGxZZhSD+e67nYIFNI5tLmkVjoi6qnqu0Aur2AKyrARWrS5uJ1E6dOgUfHx/UqlUL+/btg1wu57VXRERERCUci6wicK9SHsYGZeTeUdf+p3q2qQW0GCNtFlITQmDp0qX4/PPPkZmZCWNjY0RHR8PBwUHqaERERET0BhzCXZclx2a1q3tKl4Oyef78OXr37o3PPvsMmZmZ8PHxwblz51hgEREREZUSPJKlq5RKYHXrrOnyLpJFoSznzp2Dt7c3IiIiYGhoiKVLl2LMmDFl61YBRERERGUciyxdlZkKvHikaldtD9jUljQOAUqlEsOHD0dERARcXV0RFBSEJk04CAkRERFRacPTBXVRRgrwo0fWtM9m3ni4BNDT08PmzZsxYMAAhISEsMAiIiIiKqVYZOmi55FAwkNVu7IHYFhO0ji67OLFi9i8ebN6unHjxtiyZQusrKykC0VEREREb4WHL3RNajywua+qrW8MjDoE8HofrRNCYN26dRg/fjwUCgVq1aqFpk2bSh2LiIiIiDSARZauuXsy6yiWXT0WWBJISkrCmDFjsGnTJgBA165dUbVqVYlTEREREZGm8HTBArr0IA4rgm9JHePtJMcC+2ZkTQ/dJV0WHRUWFoZmzZph06ZNkMvlWLhwIf73v/+hQoUKUkcjIiIiIg0pEUWWn58fXFxcYGxsjObNm+PMmTN5Lrt27Vq0adMG5cuXR/ny5eHp6Znv8poya9dVdbuccSk9AHh1B/A8QtWu8R5gZC5tHh0TEBCApk2bIiwsDJUqVcLhw4cxffp06OmViB9DIiIiItIQyb/dbd26FZMnT8bs2bMREhKCRo0awcvLC0+ePMl1+aNHj2LgwIE4cuQITp06BScnJ7z33nt4+PBhseZMTs8EALSqVgEftHYt1n0Vm4zUrHbXH6TLoaMePXqE5ORkeHp6IjQ0FG3btpU6EhEREREVA8mLrCVLluDDDz/EiBEjULduXaxZswampqZYv359rssHBATgk08+QePGjVG7dm388ssvUCqVCA4O1krecR2rw8bcSCv7KjYNvIHyzlKn0AlCCHX7s88+w+bNm7Fv3z7Y2tpKmIqIiIiIipOkRVZ6ejrOnz8PT09PdZ+enh48PT1x6tSpAm0jOTkZGRkZsLa2znV+WloaEhISsj10jlIJPL4IxD+QOolO2bZtG1q2bImkpCQAqs+2r68v5HK5xMmIiIiIqDhJWmTFxMRAoVDAzs4uW7+dnR2ioqIKtI3PP/8cDg4O2Qq1Vy1cuBCWlpbqh5OTU7b58WnxuB57Pd99pGYocDM6sUB5SqR904Gf2gKnV6umOaJgsUpLS8P48ePh4+OD06dPY8WKFVJHIiIiIiItkvx0wbfx7bffIjAwEDt37oSxsXGuy8yYMQPx8fHqx/3797PNP/nopLptY2qTY/3ohFT0X5N1VM1IvxS8ZUKojl69fDz7b1RE0wpAxZpAQ29p85VhEREReOedd/Djjz8CUH3+pk6dKnEqIiIiItImSYfJq1ixIuRyOaKjo7P1R0dHw97ePt91f/jhB3z77bc4dOgQGjZsmOdyRkZGMDLK+xqqTKVqQItyBuVQo3yNHPMnbwvF5Yfx6unGTuXzzSW5pBjgp3ZAQi6nBnotABoN0H4mHbFr1y4MHz4ccXFxsLa2xqZNm9C1a1epYxERERGRlkl6WMbQ0BBNmjTJNmjFy0EsWrZsmed6ixYtwtdff419+/bBw8NDI1ka2uReqD1LTAcAVDAzxKHJbSHXK+Gn2kVdyr3AMjAD7PMuRunt/Pzzz+jVqxfi4uLQokULXLhwgQUWERERkY6S/IZPkydPxrBhw+Dh4YFmzZph2bJlSEpKwogRIwAAQ4cOReXKlbFw4UIAwHfffYdZs2bht99+g4uLi/rarXLlyqFcuXLFlnPFQDdUty3B95VSKoFdY4H7/6qmbeoAw/dkzTc0BQxMpMmmA7p3745Zs2bB19cXCxcuhKGhodSRiIiIiEgikhdZPj4+ePr0KWbNmoWoqCg0btwY+/btUw+Gce/evWw3a129ejXS09PRr1+/bNuZPXs25syZo9FsQghcj3qh0W0Wm9g7wMXfsqbLuwBmFSSLowuuXbuGOnXqAAAqVaqEsLCwPEe5JCIiIiLdIXmRBQDjxo3DuHHjcp139OjRbNORkZEa3fcXx7/Ic96OkKwbHOuV9BH5Xg7PbmQB9PcHqrSQNE5ZlpmZidmzZ2PhwoXYunUr+vfvDwAssIiIiIgIQCkfXfBtHbx7UN02kuccHONRXIq67VbFShuRiu7mftVzWgJQvRNgaCZtnjLq8ePH8PT0xIIFCyCEwPnz56WOREREREQlTIk4kiWV+y+yhnNf0n5JnssNbFYFxgYl8Aay6UnAjb9UzzE3VH2ubaXNVIYFBwdj0KBBePLkCczNzbF27Vr4+PhIHYuIiIiIShidLrJe6lmtJ/T1SuFbcfJH4OiC7H2OzaTJUoYpFArMnz8fc+bMgRACDRs2RFBQEGrWrCl1NCIiIiIqgUphZaE5MSkxUkcoOiGAyH9UbetqqpsMG5UD3HylzVUGHT9+HLNnzwYAjBo1CitWrICJCUdqJCIiIqLc6WyRJYTA7ju7AQDVrarnusy6ExHajFQ4B77MKrIa9Ac6zJA2TxnWrl07fPHFF6hVqxaGDh0qdRwiIiIiKuF0tshSCAWepz0HAHSv1j3H/IdxKYhLzgAAWJkaaDVbgTy9ntWu6SVdjjJIqVRi+fLl6N+/PxwdHQEA8+fPlzgVEREREZUWOltkZSoz1e3cRhZMy1Co2x+3raaVTAUSNAK49ifwMn+vNUBld2kzlSHPnj3DsGHDsGfPHuzYsQNHjhyBvr7O/pgQERERURHo7LfHNEWaum2sb5zncubG+rAsSUeywv4AhFLV1jcG7OtLGqcs+ffff+Ht7Y379+/DyMgIQ4cOhVxeAkeVJCIiIqISTWeLrNTMVACAgZ5B6RhZMOYW8NfnWQXW6GOAdVXAyFzaXGWAEALLly/H1KlTkZmZierVqyMoKAiNGzeWOhoRERERlUKloLooHi+LrLyOYimFNtMUwJXfgTvBqrZhOaBCDcDQVNpMZUBCQgKGDx+OnTt3AgD69euHX375BZaWlhInIyIiIqLSSk/qAFJ5ebqgsTz3ImvTqUgAQDmjElKHRh5XPVd/F/j4OAssDdHX18fNmzdhYGCAlStXYtu2bSywiIiIiOitlJAKQvtSFfkfyToTqRp5sI97Za1lytfDENWzuT1g7SptllJOCNVhSplMBlNTU2zfvh0vXrxA06ZNJU5GRERERGWBzh7JetPpgi81d62gjThvZmKleq7bS8oUpd6LFy8waNAgfPvtt+q+2rVrs8AiIiIiIo3R+SLLRG6SY17gmXu49jhB25EKxqyEFH2l0OXLl+Hh4YHAwEDMnTsXjx8/ljoSEREREZVBOltkqa/Jeu1IVlxyOqbvuKyedqlgptVceUqJkzpBqbZhwwY0a9YMN2/eROXKlREcHIxKlSpJHYuIiIiIyiCdLbJeXpP1+o2If/knQt3+7cPmqFKhBAwwEXcfyEiSOkWplJSUhOHDh+ODDz5AamoqvLy8cOHCBbRu3VrqaERERERURnHgi9eOZAVff6Jut6pWUauZ8vTsdlbbtq50OUoZhUKBdu3a4fz589DT08O8efMwY8YM6Onp7N8WiIiIiEgLdLbISstUnS5oop/9miz5f9+/V/m6aztS3q7vVj3b1gP0jfJfltTkcjk++OADPHz4EFu2bEH79u2ljkREREREOkBn/6SvHl0wj/tkmRrKtRknfy+vx3rBgRreJDU1FXfu3FFPjxkzBmFhYSywiIiIiEhrdLfIesN9skoUmUz13HaKtDlKuNu3b6Nly5Z47733EB8fD0B1L6zy5ctLnIyIiIiIdAmLrNJQZKnJpA5QYm3fvh3u7u4IDQ1FQkICbt26JXUkIiIiItJROltkpSvSAeR9uiCVDmlpaZgwYQL69++PFy9e4J133kFoaCg8PDykjkZEREREOkpni6yUzBQApe1IFr0qMjISbdq0wcqVKwEA06ZNw+HDh1G5cmWJkxERERGRLtP50QVLRZH1PFLqBCXSjBkzcPbsWZQvXx6//vor3n//fakjERERERHpbpH1ptEFSwylEnhwVuoUJdLKlSuRnp6OJUuWwNnZWeo4REREREQAdPh0wVSlqsh6/T5ZkkuJUx25evmIzRqOHNU6SpOphHjw4AF++OEH9XTFihXx+++/s8AiIiIiohJFZ49kvTxd0EiedXPfnRce4MrDBKkiAVFXgJ/bA8qM3OdbVNJqnJJk//79GDx4MGJiYmBra4uhQ4dKHYmIiIiIKFc6eyTr9YEvImKSMGnrRfX8ckYS1J/hR1QFlkwOGJhlf9TsAhhZaD+TxBQKBb766it06dIFMTExcHNzQ+vWraWORURERESUJ509kvVyCPeXpwuev/tcPW9O97pwryLBDWyfXFM9t/scaP+59vdfwjx+/BiDBg3C0aNHAQAff/wxli5dCmPjEn4dHRERERHpNJ0tslIzUwF51sAXofdVRdaHbVwxvLWrNKGehKmebetIs/8S5OjRoxgwYACio6NhZmaGtWvXYuDAgVLHIiIiIiJ6I50tstIUaaoi67/TBa89fgEAaOBopf0wSgWwdyrw6IJq2rau9jOUMKmpqXjy5Anq16+PoKAg1K5dW+pIREREREQForNFVooiBXLI1UVWhkIJAChnJNd+mMehwLl1qrZpBaC8i/YzlABKpRJ6eqrLBDt37ozff/8dXl5eMDU1lTgZEREREVHB6ezAFy9Jfp+szHTg1Kqs6Q/2A3Ldq31PnDiBRo0aITw8XN3Xu3dvFlhEREREVOrofJFlpG/05oWK0+2DwJXtqrZdA6BiDWnzaJkQAj/88APatWuHK1euYObMmVJHIiIiIiJ6K7p3yOQV+jJ9GOgZSBvicdaw8ei2WLocEoiNjcXw4cPxv//9DwAwcOBA/PTTTxKnIiIiIiJ6OzpdZMlkMmkDpL0A/v5O1a7xHlClubR5tOjMmTPw9vbG3bt3YWRkhOXLl+Ojjz6S/t+EiIiIiOgt6XSR9dLZyFhcehCv/R2nZN2bC81Ha3//Ejl69Cjee+89ZGRkoFq1aggKCoKbm5vUsYiIiMoshUKBjIwMqWMQScLQ0FA9uJq26HyRlZSWif5rTqmnK1maaG/ntw+pnvWNgeqe2tuvxFq2bImGDRvCxcUF69atg6WlpdSRiIiIyiQhBKKiohAXFyd1FCLJ6OnpwdXVFYaGhlrbp04XWRaGFnienK6entO9LupUstBegBdRqufMVO3tUyLXrl1DjRo1oK+vDyMjIxw6dAiWlpY8PZCIiKgYvSywbG1tYWpqyv93SecolUo8evQIjx8/RpUqVbT2M6DTRZZDOQd120hfD8Nbu2pv5zf2ZV2P1XSU9varZUIIrF27FhMmTMCUKVPwzTffAACsrKykDUZERFTGKRQKdYFVoUIFqeMQScbGxgaPHj1CZmYmDAy0M+idTg/hXsmsknQ7v7ojq21TW7ocxSgxMRFDhgzB6NGjkZaWhsuXL0OhUEgdi4iISCe8vAaL95wkXffyNEFtfg/V6SLr1SNZWieE6tnjA6DZh9LlKCZXr15F06ZNERAQALlcju+++w47d+6EXC6XOhoREZFO4SmCpOuk+BnQ6dMFbU1tpY4AWFeTOoHGbdy4EWPGjEFKSgocHBywdetWvPPOO1LHIiIiIiLSCp0+kiWXSXhU5d6pNy9TCj169AiffPIJUlJS8N577yE0NJQFFhEREWmcTCbDH3/8IXWMQnn27BlsbW0RGRkpdZQyY/r06Rg/frzUMXLQ6SJLMkoFEH9f1dYrW6fPOTg4YM2aNZg3bx727t0LGxsbqSMRERFRKRMVFYXx48ejatWqMDIygpOTE7p3747g4GCpowFQDew1a9YsVKpUCSYmJvD09MStW7feuN78+fPRs2dPuLi45Jjn5eUFuVyOs2fP5pjXvn17fPrppzn6/f39cwwmlpCQgJkzZ6J27dowNjaGvb09PD09sWPHDoiXl6sUg6NHj8Ld3R1GRkaoXr06/P3937jO/v370aJFC5ibm8PGxgZ9+/bNUYCmpaVh5syZcHZ2hpGREVxcXLB+/Xr1/ClTpmDjxo0IDw/X8Ct6OzpfZC05eBMAUHwfuVykJ2a1a3XR5p6LRWBgIE6ePKmeHjJkCL766itef0VERESFFhkZiSZNmuDw4cP4/vvvcfnyZezbtw8dOnTA2LFjpY4HAFi0aBFWrFiBNWvW4PTp0zAzM4OXlxdSU/O+LU9ycjLWrVuHkSNH5ph37949nDx5EuPGjctWQBRWXFwcWrVqhV9//RUzZsxASEgIjh07Bh8fH0ybNg3x8fFF3nZ+IiIi0K1bN3To0AGhoaH49NNPMWrUKOzfvz/fdXr27ImOHTsiNDQU+/fvR0xMDPr06ZNtOW9vbwQHB2PdunW4ceMGtmzZglq1aqnnV6xYEV5eXli9enWxvLYiEzomPj5eABB1VtcRAWEBouePx4Xz57tF/Vn7tBcicLAQsy1Uj5Q47e1Xw1JSUsSYMWMEAFG5cmURExMjdSQiIiL6T0pKiggLCxMpKSlCCCGUSqVISsuQ5KFUKgucu0uXLqJy5coiMTExx7znz5+r2wDEzp071dPTpk0TNWrUECYmJsLV1VV8+eWXIj09XT0/NDRUtG/fXpQrV06Ym5sLd3d3cfbsWSGEEJGRkeL9998XVlZWwtTUVNStW1fs2bMn13xKpVLY29uL77//Xt0XFxcnjIyMxJYtW/J8XUFBQcLGxibXeXPmzBEDBgwQ165dE5aWliI5OTnb/Hbt2omJEyfmWG/Dhg3C0tJSPT1mzBhhZmYmHj58mGPZFy9eiIyMjDzzvY1p06aJevXqZevz8fERXl5eea4TFBQk9PX1hUKhUPf9+eefQiaTqf/d/vrrL2FpaSmePXuW7/43btwoHB0d85z/+s/Cq17WBvHx8fnuo7B0euCLVy31aay9nT27rXq2rgoYW2pvvxoUHh6O/v37IyQkBAAwYsQIWFqWztdCRESkC1IyFKg7K+8jC8UpbJ4XTA3f/LUzNjYW+/btw/z582FmZpZjfn732TQ3N4e/vz8cHBxw+fJlfPjhhzA3N8e0adMAAL6+vnBzc8Pq1ashl8sRGhqqvmfS2LFjkZ6ejmPHjsHMzAxhYWEoV65crvuJiIhAVFQUPD091X2WlpZo3rw5Tp06hQEDBuS63j///IMmTZrk6BdCYMOGDfDz80Pt2rVRvXp1bN++HUOGDMnzteZGqVQiMDAQvr6+cHDIOYJ2Xq/nZbYuXfI/u+qnn36Cr69vrvNOnTqV7f0AVKc/5naK40tNmjSBnp4eNmzYgOHDhyMxMRGbNm2Cp6en+t/lzz//hIeHBxYtWoRNmzbBzMwMPXr0wNdffw0TExP1tpo1a4YHDx4gMjIy11MxpcAiS9uu7QaehKna782XNksR7dy5EyNGjEB8fDwqVKiAzZs3o3PnzlLHIiIiolLu9u3bEEKgdu3C30P0yy+/VLddXFwwZcoUBAYGqouse/fuYerUqept16hRQ738vXv30LdvXzRo0AAAULVq1Tz3ExUVBQCws7PL1m9nZ6eel5u7d+/mWvwcOnQIycnJ8PLyAgAMHjwY69atK3SRFRMTg+fPnxfpvfPw8EBoaGi+y7z+el8VFRWV6/uRkJCAlJSUbAXRS66urjhw4AC8vb0xevRoKBQKtGzZEnv37lUvEx4ejuPHj8PY2Bg7d+5ETEwMPvnkEzx79gwbNmxQL/fyfb179y6LLJ314ExW26GxZDGKIjMzE9OmTcPSpUsBAK1atUJgYCCcnJwkTkZERERvYmIgR9g8L8n2XRDiLQZm2Lp1K1asWIE7d+4gMTERmZmZsLCwUM+fPHkyRo0apT5a0r9/f1SrprqVzoQJEzBmzBgcOHAAnp6e6Nu3Lxo2bFjkLLlJSUmBsbFxjv7169fDx8cH+vqqr+UDBw7E1KlTcefOHXW+gnib987ExATVq1cv8vpFERUVhQ8//BDDhg3DwIED8eLFC8yaNQv9+vXDwYMHIZPJoFQqIZPJEBAQoD5jasmSJejXrx9WrVqlLt5ePicnJ2v1NeRH5we+0LpTq1TPLccBFhLeDLkI5HI57t69C0A1ksvRo0dZYBEREZUSMpkMpob6kjwKejPYGjVqQCaT4fr164V6badOnYKvry+6du2K3bt348KFC5g5cybS09PVy8yZMwdXr15Ft27dcPjwYdStWxc7d+4EAIwaNQrh4eEYMmQILl++DA8PD6xcuTLXfdnb2wMAoqOjs/VHR0er5+WmYsWKeP78eba+2NhY7Ny5E6tWrYK+vj709fVRuXJlZGZmZhsAw8LCItdBK+Li4tTFh42NDaysrAr93gGq0wXLlSuX7yMgICDP9e3t7XN9PywsLHI9igUAfn5+sLS0xKJFi+Dm5oa2bdti8+bNCA4OxunTpwEAlSpVQuXKlbNdklKnTh0IIfDgwQN1X2xsrPo9KClYZGmTIgMQClW7XN6HXEsapVIJQPXLef369di7dy++//579fmyRERERJpgbW0NLy8v+Pn5ISkpKcf8uLi4XNc7efIknJ2dMXPmTHh4eKBGjRrqPwy/qmbNmpg0aRIOHDiAPn36ZDvlzMnJCR9//DF27NiBzz77DGvXrs11X66urrC3t882nHxCQgJOnz6Nli1b5vna3NzcEBYWlq0vICAAjo6OuHjxIkJDQ9WPxYsXw9/fHwqF6ntjrVq11NfBvyokJAQ1a9YEAOjp6WHAgAEICAjAo0ePciz78uhebl6eLpjfo0ePHnm+tpYtW+YYXv/gwYP5vh/JycnQ08teirwcmfrld8/WrVvj0aNHSEzMGpn75s2b0NPTg6Ojo7rvypUrMDAwQL169fLcn9ZpdBiNUiCv0QUPXo0q/p3vmZo1quArI6mUVBkZGWL69OliwIABhRoViIiIiKSX34hqJdmdO3eEvb29qFu3rti+fbu4efOmCAsLE8uXLxe1a9dWL4dXRhfctWuX0NfXF1u2bBG3b98Wy5cvF9bW1uqR95KTk8XYsWPFkSNHRGRkpDh+/LioVq2amDZtmhBCiIkTJ4p9+/aJ8PBwcf78edG8eXPh7e2dZ8Zvv/1WWFlZiV27dolLly6Jnj17CldX13zf60uXLgl9fX0RGxur7mvUqJH4/PPPcywbFxcnDA0Nxe7du9XvibGxsRg/fry4ePGiuH79uli8eLHQ19cXf/31l3q9Z8+eidq1awtHR0exceNGcfXqVXHz5k2xbt06Ub169WyjM2pSeHi4MDU1FVOnThXXrl0Tfn5+Qi6Xi337skbvXrlypejYsaN6Ojg4WMhkMjF37lxx8+ZNcf78eeHl5SWcnZ3Voyu+ePFCODo6in79+omrV6+Kv//+W9SoUUOMGjUq2/5nz56dbduvk2J0QRZZ2iqy0pOzCqx1eQ9nWVI8fPhQtGnTRkB1CzHx999/Sx2JiIiICqG0FllCCPHo0SMxduxY4ezsLAwNDUXlypVFjx49xJEjR9TL4LUh3KdOnSoqVKggypUrJ3x8fMTSpUvVRVZaWpoYMGCAcHJyEoaGhsLBwUGMGzdO/d6MGzdOVKtWTRgZGQkbGxsxZMiQfG9No1QqxVdffSXs7OyEkZGR6NSpk7hx48YbX1ezZs3EmjVrhBBCnDt3TgAQZ86cyXXZLl26iN69e6unz5w5I959911hY2MjLC0tRfPmzbO9/pfi4uLE9OnTRY0aNYShoaGws7MTnp6eYufOncX6R/MjR46Ixo0bC0NDQ1G1alWxYcOGbPNnz54tnJ2ds/Vt2bJFuLm5CTMzM2FjYyN69Oghrl27lm2Za9euCU9PT2FiYiIcHR3F5MmTcwxxX6tWrXyHz5eiyJIJUYy3fi6BEhISYGlpiTqr6+DLdl9i22FnhN6Pwy9DPeBZV4On8CXHAld+BzL+uwAvMw048t9oguPOAxW1e3FhYRw8eBC+vr54+vQpzM3NsW7dOvTv31/qWERERFQIqampiIiIgKura64DLpD27dmzB1OnTsWVK1dynCpHRfPXX3/hs88+w6VLl9SDh7wuv5+Fl7VBfHx8toFS3pbOjy4Y9iiheDZ8YhlwYnnOfj0DoLxz8ezzLSkUCsybNw9ff/01hBBo3LgxgoKCtD7aDBEREVFZ1K1bN9y6dQsPHz7k4GEakpSUhA0bNuRZYEmlZKXRsmuPE5CuUI1WorE/JsRGAPEPgCf/jexi3wCwa5A1v2o7QF4yB4wYPnw4Nm/eDAD46KOPsGzZsjxHhCEiIiKiwsvvBr1UeP369ZM6Qq50usiKS85Qt5u6WL/9BmPDgRXuUF3G9J96vYE2n739trXgww8/xP/+9z/4+fnleUdvIiIiIiLKn04XWbZG1QEo0dutMsyNNXB0Ke4+AAHIDQHrqoCxJVC7+9tvt5golUqEhYWhfv36AIC2bdsiMjISVlZW0gYjIiIiIirFdPaKu/JG5VHJuJZmN3o5SPVsXRUYexoYeQCwqanZfWhITEwM3n//fbRo0QLXrl1T97PAIiIiIiJ6OzpbZJnom8D/ZKRmN6r4767iKc/zX05iJ0+ehJubG/766y8oFIpsRRYREREREb0dnS2yFEqBB89TAABWphoeiKLVeM1uT0OEEFiyZAnatWuHBw8eoGbNmjh9+jT69OkjdTQiIiIiojJDZ6/J0tfLKqwmdKyhmY2+PIJlYKqZ7WnQ8+fPMWLECOzatQsAMGDAAPz8888wNzeXOBkRERERUdmis0eyEpLlAAADuQzlzQw1s9GXw7bb1tHM9jRozZo12LVrFwwNDbFq1Sr89ttvLLCIiIiIiIqBzhZZikxVYWWsL9fMBpUKIP6eqm1dTTPb1KApU6Zg8ODBOHnyJMaMGQOZTCZ1JCIiIqIik8lk+OOPP6SOUSjp6emoXr06Tp48KXWUMmPAgAFYvHix1DFy0NkiSyaMAACLvRu93YYenAf+XQOcXpPVVwJuNpyQkIBZs2YhPV01GIeBgQE2bdqEJk2aSJyMiIiIKH9RUVEYP348qlatCiMjIzg5OaF79+4IDg6WOhoAYMeOHXjvvfdQoUIFyGQyhIaGFmi9NWvWwNXVFa1atcoxb/To0ZDL5QgKCsoxb/jw4ejVq1eO/qNHj0ImkyEuLk7dl56ejkWLFqFRo0YwNTVFxYoV0bp1a2zYsAEZGRk5tqEply5dQps2bWBsbAwnJycsWrQo3+X9/f0hk8lyfTx58kS93NGjR+Hu7g4jIyNUr14d/v7+2bbz5ZdfYv78+YiPjy+Ol1VkOntNlp4wefuNZKYDG7sDGUmvdMokL7IuXryI/v3749atW0hMTMSSJUskzUNERERUUJGRkWjdujWsrKzw/fffo0GDBsjIyMD+/fsxduxYXL9+XeqISEpKwjvvvANvb298+OGHBVpHCIEff/wR8+bNyzEvOTkZgYGBmDZtGtavX4/+/fsXKVd6ejq8vLxw8eJFfP3112jdujUsLCzw77//4ocffoCbmxsaN25cpG3nJyEhAe+99x48PT2xZs0aXL58GR988AGsrKzw0Ucf5bqOj48POnfunK1v+PDhSE1Nha2tLQAgIiIC3bp1w8cff4yAgAAEBwdj1KhRqFSpEry8vAAA9evXR7Vq1bB582aMHTtW46+tqHS3yILR228kPTGrwKrbE9DTB6q0BIykudZJCIF169Zh/PjxSE1NhZOTE7y9vSXJQkRERCWMEEBGsjT7NjAFCnipwieffAKZTIYzZ87AzMxM3V+vXj188MEHea73+eefY+fOnXjw4AHs7e3h6+uLWbNmwcBA9cfvixcv4tNPP8W5c+cgk8lQo0YN/PTTT/Dw8MDdu3cxbtw4HD9+HOnp6XBxccH333+Prl275rqvIUOGAFAVhAV1/vx53LlzB926dcsxLygoCHXr1sX06dPh4OCA+/fvw8nJqcDbfmnZsmU4duwYzp07Bzc3N3V/1apV0b9/f/UZTpoWEBCA9PR0rF+/HoaGhqhXrx5CQ0OxZMmSPIssExMTmJhkHfR4+vQpDh8+jHXr1qn7Xh75e3k6YJ06dXD8+HEsXbpUXWQBQPfu3REYGMgiqyTQyJGsP8ZktXv/DBgYv/02iygpKQljxozBpk2bAABdu3bFr7/+igoVKkiWiYiIiEqQjGRggYM0+/7iEWBo9sbFYmNjsW/fPsyfPz9bgfWSlZVVnuuam5vD398fDg4OuHz5Mj788EOYm5tj2rRpAABfX1+4ublh9erVkMvlCA0NVRdgY8eORXp6Oo4dOwYzMzOEhYWhXLlyRXutefjnn39Qs2bNXAceW7duHQYPHgxLS0t06dIF/v7++Oqrrwq9j4CAAHh6emYrsF4yMDBQv97X3bt3D3Xr1s1321988QW++OKLXOedOnUKbdu2haFh1mByXl5e+O677/D8+XOUL1/+jdl//fVXmJqaol+/ftm26+npmW05Ly8vfPrpp9n6mjVrhvnz5yMtLQ1GRho4kKIBOlxkaaAgSnioerauJmmBdePGDfTp0wdhYWGQy+WYP38+pk6dCj09nb3kjoiIiEqh27dvQwiB2rVrF3rdL7/8Ut12cXHBlClT1KfgAapCYurUqept16iRdQufe/fuoW/fvmjQoAEA1ZEfTbt79y4cHHIWubdu3cK///6LHTt2AAAGDx6MyZMn48svvyz0QGW3bt1C+/btC53NwcHhjdeVWVtb5zkvKioKrq6u2frs7OzU8wpSZK1btw6DBg3KdnQrKipKvZ1Xt5uQkICUlBT1sg4ODkhPT0dUVBScnZ3fuC9t0N0iC295JCs9GYi6rGp3zf/CvuIml8vx4MEDVKpUCYGBgWjbtq2keYiIiKgEMjBVHVGSat8FIIQo8i62bt2KFStW4M6dO0hMTERmZiYsLCzU8ydPnoxRo0Zh06ZN8PT0RP/+/VGtmmpE6AkTJmDMmDE4cOAAPD090bdvXzRs2LDIWXKTkpICY+Ocf5Rfv349vLy8ULFiRQCqs5FGjhyJw4cPo1OnToXaR1HfP319fVSvXr1I62rCqVOncO3aNfUZWYX1sthKTpbodNhc6OyhDj3xlocSY+9ktW3rvd22ikCpVKrb1atXx65duxAaGsoCi4iIiHInk6lO2ZPiUcAjMjVq1IBMJiv04BanTp2Cr68vunbtit27d+PChQuYOXNmtmuQ5syZg6tXr6Jbt244fPgw6tati507dwIARo0ahfDwcAwZMgSXL1+Gh4cHVq5cWagMb1KxYkU8f/48W59CocDGjRuxZ88e6OvrQ19fH6ampoiNjcX69evVy1lYWOQ6el5cXBzkcrn61MqaNWsWaWCQe/fuoVy5cvk+FixYkOf69vb2iI6Oztb3ctre3v6N+//ll1/QuHHjHKNg57VdCwuLbEe8YmNjAQA2NjZv3Je26GyRJdPUSzexBiwqaWZbBXTz5k14eHhkG8a0ffv26pFYiIiIiEoja2treHl5wc/PD0lJSTnmvzpU+atOnjwJZ2dnzJw5Ex4eHqhRowbu3r2bY7maNWti0qRJOHDgAPr06YMNGzao5zk5OeHjjz/Gjh078Nlnn2Ht2rUae10A4ObmhuvXr2c72rR37168ePECFy5cQGhoqPqxZcsW7NixQ/16a9WqhatXryItLS3bNkNCQuDq6qq+1mrQoEE4dOgQLly4kGP/GRkZub6nQNbpgvk9Pv744zxfW8uWLXHs2LFsQ8QfPHgQtWrVeuOpgomJidi2bRtGjhyZ63ZfH7b/4MGDaNmyZba+K1euwNHRUX00sCTQ2SJLY+SGb15Gg7Zt2wYPDw9cuHABkyZNynZEi4iIiKi08/Pzg0KhQLNmzfD777/j1q1buHbtGlasWJHjy/VLNWrUwL179xAYGIg7d+5gxYoV6qNUgOpUvXHjxuHo0aO4e/cuTpw4gbNnz6JOnToAgE8//RT79+9HREQEQkJCcOTIEfW83MTGxiI0NBRhYWEAVNfHh4aGIioqKs91OnTogMTERFy9elXdt27dOnTr1g2NGjVC/fr11Q9vb29YWVkhICAAgGrQDplMhqFDh+L8+fO4ffs21q9fj2XLluGzzz5Tb+/TTz9F69at0alTJ/j5+eHixYsIDw/Htm3b0KJFC9y6dSvXbC9PF8zvkd81WYMGDYKhoSFGjhyJq1evYuvWrVi+fDkmT56sXmbnzp25Xmu3detWZGZmYvDgwTnmffzxxwgPD8e0adNw/fp1rFq1Ctu2bcOkSZOyLffPP//gvffeyzOfJISOiY+PFwBEh6WLhPPnu8X+K48Lt4GkZ0Ls/1KILYOEmG0hxPc1iyfoa1JTU8XYsWMFAAFAtG3bVjx8+FAr+yYiIqLSJyUlRYSFhYmUlBSpoxTao0ePxNixY4Wzs7MwNDQUlStXFj169BBHjhxRLwNA7Ny5Uz09depUUaFCBVGuXDnh4+Mjli5dKiwtLYUQQqSlpYkBAwYIJycnYWhoKBwcHMS4cePU7824ceNEtWrVhJGRkbCxsRFDhgwRMTExeebbsGGD+jvZq4/Zs2fn+7q8vb3F9OnThRBCREVFCX19fbFt27Zclx0zZoxwc3NTT9+4cUP07t1bODg4CDMzM9GoUSOxdu1aoVQqs62XmpoqFi5cKBo0aCCMjY2FtbW1aN26tfD39xcZGRn55nsbFy9eFO+8844wMjISlStXFt9++222+S/fs9e1bNlSDBo0KM/tHjlyRDRu3FgYGhqKqlWrig0bNmSbn5KSIiwtLcWpU6fy3EZ+Pwsva4P4+Pg3vMLCkQnxFlcYlkIJCQmwtLREh6WLEB5VFz8PaYL36r35XFG10z8Bf03Lmq5YCxh3RvNBXxEREYH+/fvj/PnzAIAZM2Zg3rx50NfX2XFLiIiI6A1SU1MREREBV1fXXAdcIO27dOkS3n33Xdy5c0fjQ8TrqtWrV2Pnzp04cOBAnsvk97PwsjaIj4/PNlDK29LZb+nPkjLevNDrnlwHIo6p2vYNgXq9gBrFe2jy3r17cHNzQ3x8PKytrbFp06Y8b4xHRERERCVXw4YN8d133yEiIkI9XDy9HQMDA40PUqIJOltkvUhVFVmFuv/Apl7Ai8eqdmV3oM1n+S6uCU5OTujZsydu3bqFwMBAVKlSpdj3SURERETFY/jw4VJHKFNGjRoldYRc6WyR9ZKH85tvjqb2ssCq/T7QbHTxBAJw//59mJmZwdraGjKZDKtXr873Lt1ERERERFRy6PTogj0aOaC8WQFHB3x4Pqvd9QfArm6xZPrrr7/g5uaGYcOGqUcONDU1ZYFFRERERFRK6HSRVSjPXrn5sHkhBsoooMzMTHzxxRfo2rUrnj17hsePH+d5LwgiIiIiIiq5WGQVVtUOBb5reUE9evQInTp1wsKFCwEA48aNw4kTJ/K9HwEREREREZVMOn9NltSCg4MxaNAgPHnyBObm5vjll1/g7e0tdSwiIiIiIioiFln5eREN/G8CkPQUSH6m8c1nZGTgo48+wpMnT9CwYUMEBQWhZs2aGt8PERERERFpD4us/Nw+CNzcl73PsrLGNm9gYIDAwECsW7cOS5cuhYmJica2TURERERE0tDpa7JMDeX5L3BmrerZwR0YuBUY/LtqZMG3cOzYMQQEBKinmzZtijVr1rDAIiIiIioEmUyGP/74Q+oYhfLs2TPY2toiMjJS6ihlxvTp0zF+/HipY+Sg00XWx+2q5T3z6U3gcaiqXbEGUKszUN0TMChaMaRUKvHdd9+hY8eOGDlyJC5evFik7RARERGVdVFRURg/fjyqVq0KIyMjODk5oXv37ggODpY6GjIyMvD555+jQYMGMDMzg4ODA4YOHYpHjx69cd358+ejZ8+ecHFxyTHPy8sLcrkcZ8+ezTGvffv2+PTTT3P0+/v7w8rKKltfQkICZs6cidq1a8PY2Bj29vbw9PTEjh07IIQo6MsstKNHj8Ld3R1GRkaoXr06/P3937jO/v370aJFC5ibm8PGxgZ9+/bNUYD6+fmhTp06MDExQa1atfDrr79mmz9lyhRs3LgR4eHhGnw1b09niyyZTAaXimZ5LxB1Kavd8cu32tezZ8/QvXt3TJ8+HQqFAt7e3qhWLZ8Cj4iIiEhHRUZGokmTJjh8+DC+//57XL58Gfv27UOHDh0wduxYqeMhOTkZISEh+OqrrxASEoIdO3bgxo0b6NGjxxvXW7duHUaOHJlj3r1793Dy5EmMGzcO69evL3K2uLg4tGrVCr/++itmzJiBkJAQHDt2DD4+Ppg2bRri4+OLvO38REREoFu3bujQoQNCQ0Px6aefYtSoUdi/f3++6/Ts2RMdO3ZEaGgo9u/fj5iYGPTp00e9zOrVqzFjxgzMmTMHV69exdy5czF27Fj873//Uy9TsWJFeHl5YfXq1cXy2opM6Jj4+HgBQFT9am7+Cx5eIMRsCyH+GPtW+zt16pRwcnISAISxsbFYu3atUCqVb7VNIiIiojdJSUkRYWFhIiUlRQghhFKpFEnpSZI8CvPdp0uXLqJy5coiMTExx7znz5+r2wDEzp071dPTpk0TNWrUECYmJsLV1VV8+eWXIj09XT0/NDRUtG/fXpQrV06Ym5sLd3d3cfbsWSGEEJGRkeL9998XVlZWwtTUVNStW1fs2bOnwJnPnDkjAIi7d+/muUxQUJCwsbHJdd6cOXPEgAEDxLVr14SlpaVITk7ONr9du3Zi4sSJOdbbsGGDsLS0VE+PGTNGmJmZiYcPH+ZY9sWLFyIjI6NgL6iQpk2bJurVq5etz8fHR3h5eeW5TlBQkNDX1xcKhULd9+effwqZTKb+d2vZsqWYMmVKtvUmT54sWrduna1v48aNwtHRMc99vf6z8KqXtUF8fHzeL7AIOPAFAKQ8B15EZe9LeKh6NjIv8mZXrFiBzz77DJmZmahRowaCgoLQqFGjtwhKREREVDQpmSlo/ltzSfZ9etBpmBqYvnG52NhY7Nu3D/Pnz4eZWc4zjl4/Ne5V5ubm8Pf3h4ODAy5fvowPP/wQ5ubmmDZtGgDA19cXbm5uWL16NeRyOUJDQ2FgYAAAGDt2LNLT03Hs2DGYmZkhLCwM5cqVK/Dri4+Ph0wmyzffP//8gyZNmuToF0Jgw4YN8PPzQ+3atVG9enVs374dQ4YMKfD+AdWlKYGBgfD19YWDg0OO+fm9nn/++QddunTJd/s//fQTfH19c5136tQpeHp6Zuvz8vLK9RTHl5o0aQI9PT1s2LABw4cPR2JiIjZt2gRPT0/1v0taWhqMjY2zrWdiYoIzZ84gIyNDvVyzZs3w4MEDREZG5noqphRYZCU+BZY3BDKSNb7p+Ph4ZGZmwtvbG2vXroWFhYXG90FERERUVty+fRtCCNSuXbvQ6375ZdblHS4uLpgyZQoCAwPVRda9e/cwdepU9bZr1KihXv7evXvo27cvGjRoAACoWrVqgfebmpqKzz//HAMHDsz3u97du3dzLX4OHTqE5ORkeHl5AQAGDx6MdevWFbrIiomJwfPnz4v03nl4eCA0NDTfZezs7PKcFxUVlWO+nZ0dEhISkJKSkusAb66urjhw4AC8vb0xevRoKBQKtGzZEnv37lUv4+XlhV9++QW9evWCu7s7zp8/j19++QUZGRmIiYlBpUqVAED9vt69e5dFVokRd/e/AksGmFbIPs/QDKjdrVCbUygUkMtVoxbOnDkT9evXR69evSCTyTQUmIiIiKjwTPRNcHrQacn2XRDiLQZm2Lp1K1asWIE7d+4gMTERmZmZ2YqeyZMnY9SoUeqjJf3791dfIz9hwgSMGTMGBw4cgKenJ/r27YuGDRu+cZ8ZGRnw9vaGEOKN1wSlpKTkOCoDAOvXr4ePjw/09VVfywcOHIipU6fizp07hbqG/23eOxMTE1SvXr3I6xdFVFQUPvzwQwwbNgwDBw7EixcvMGvWLPTr1w8HDx6ETCbDV199haioKLRo0QJCCNjZ2WHYsGFYtGgR9PSyhpZ4WcQlJ2v+oElR6ezAF2q7/ruA0soJmHYn++PTS4DLOwXazMsfrlatWiElJQUAoKenh969e7PAIiIiIsnJZDKYGphK8ijod6EaNWpAJpPh+vXrhXptp06dgq+vL7p27Yrdu3fjwoULmDlzJtLT09XLvBw8oVu3bjh8+DDq1q2LnTt3AgBGjRqF8PBwDBkyBJcvX4aHhwdWrlyZ7z5fFlh3797FwYMH33jGUsWKFfH8+fNsfbGxsdi5cydWrVoFfX196Ovro3LlysjMzMw2AIaFhUWug1bExcXB0tISAGBjYwMrK6tCv3eA6nTBcuXK5ft49RZEr7O3t0d0dHS2vujoaFhYWOR5myI/Pz9YWlpi0aJFcHNzQ9u2bbF582YEBwfj9GnVHwNMTEywfv16JCcnIzIyEvfu3YOLi4t6NMKXYmNj1e9BScEi69kd1bOFY5E38eLFCwwaNAiffPIJzpw5gw0bNmgoHBEREZHusLa2hpeXF/z8/JCUlJRjflxcXK7rnTx5Es7Ozpg5cyY8PDxQo0YN3L17N8dyNWvWxKRJk3DgwAH06dMn23c2JycnfPzxx9ixYwc+++wzrF27Ns+cLwusW7du4dChQ6hQoUKey77k5uaGsLCwbH0BAQFwdHTExYsXERoaqn4sXrwY/v7+UCgUAIBatWohJCQkxzZDQkJQs2ZNAKo/7g8YMAABAQG5Dif/8uhebl6eLpjfI7/RE1u2bJljeP2DBw+iZcuWea6TnJyc7WgUAPXZYEqlMlu/gYEBHB0dIZfLERgYiPfffz/buleuXIGBgQHq1auX5/60TqPDaJQC2UYXTI5VjSA420KIuPtF2t6lS5dEzZo1BQChr68vFi9ezNEDiYiISHL5jahWkt25c0fY29uLunXriu3bt4ubN2+KsLAwsXz5clG7dm31cnhldMFdu3YJfX19sWXLFnH79m2xfPlyYW1trR55Lzk5WYwdO1YcOXJEREZGiuPHj4tq1aqJadOmCSGEmDhxoti3b58IDw8X58+fF82bNxfe3t655ktPTxc9evQQjo6OIjQ0VDx+/Fj9SEtLy/N1Xbp0Sejr64vY2Fh1X6NGjcTnn3+eY9m4uDhhaGgodu/erX5PjI2Nxfjx48XFixfF9evXxeLFi4W+vr7466+/1Os9e/ZM1K5dWzg6OoqNGzeKq1evips3b4p169aJ6tWrZxudUZPCw8OFqampmDp1qrh27Zrw8/MTcrlc7Nu3T73MypUrRceOHdXTwcHBQiaTiblz54qbN2+K8+fPCy8vL+Hs7KweXfHGjRti06ZN4ubNm+L06dPCx8dHWFtbi4iIiGz7nz17drZtv06K0QV1u8i6/HtWkZX6otDbWr9+vTA2NhYAhKOjozhx4kQxJCYiIiIqvNJaZAkhxKNHj8TYsWOFs7OzMDQ0FJUrVxY9evQQR44cUS+D14Zwnzp1qqhQoYIoV66c8PHxEUuXLlUXWWlpaWLAgAHCyclJGBoaCgcHBzFu3Dj1ezNu3DhRrVo1YWRkJGxsbMSQIUNETExMrtkiIiIEgFwfr+bLTbNmzcSaNWuEEEKcO3dOABBnzpzJddkuXbqI3r17q6fPnDkj3n33XWFjYyMsLS1F8+bNs73+l+Li4sT06dNFjRo1hKGhobCzsxOenp5i586dxXog4MiRI6Jx48bC0NBQVK1aVWzYsCHb/NmzZwtnZ+dsfVu2bBFubm7CzMxM2NjYiB49eohr166p54eFhYnGjRsLExMTYWFhIXr27CmuX7+eY9+1atUSW7ZsyTObFEWWTIhivPVzCZSQkABLS0tU/Wou7vSrA+wYpTpVcPLVQm3nu+++w/Tp0wEAnTt3xqZNm1CxYsXiiExERERUaKmpqYiIiICrq2uuAy6Q9u3ZswdTp07FlStXcpwqR0Xz119/4bPPPsOlS5fUg4e8Lr+fhZe1QXx8vEZHAue/LgBULPxoKoMGDYKtrS0WLFiAPXv2sMAiIiIionx169YNH330ER4+fCh1lDIjKSkJGzZsyLPAkkrJSqNtT68VavELFy7Azc0NgOriyFu3bvHeV0RERERUYPndoJcKr1+/flJHyJXOHskyQhrwz2LVhJ5BvsumpKRg9OjRcHd3x59//qnuZ4FFRERERESv09kjWeVliVkTrcbludytW7fQv39/XLx4ETKZDDdu3NBCOiIiIiIiKq10tsiaJt8CKAHIDYGq7XNdJigoCCNHjsSLFy9gY2ODgIAAvPvuu1rNSURERPQ2dGyMM6IcpPgZ0NnTBdUaDczRlZaWhgkTJsDb2xsvXrxAmzZtcOHCBRZYREREVGoYGKguh0hOTpY4CZG00tPTAWTd7FgbdPZIFgCg2UdA1+9zdAcHB2PlypUAgOnTp+Prr78ucSOWEBEREeVHLpfDysoKT548AQCYmppCJpNJnIpIu5RKJZ4+fQpTU1Otfp/X7crBtk6u3V27dsWMGTPQunVrdOvWTcuhiIiIiDTD3t4eANSFFpEu0tPTQ5UqVbT6RwYdL7LqAgAyMjKwYMECjB49Wv3LaMGCBVImIyIiInprMpkMlSpVgq2tLTIyMqSOQyQJQ0NDrd/8WbeLLJvaePDgAXx8fHDy5EkcO3YMhw4d4qF0IiIiKlPkcrlWr0ch0nUlYuALPz8/uLi4wNjYGM2bN8eZM2fyXT4oKAi1a9eGsbExGjRogL179xZ6nxmGltj3979wc3PDyZMnYWlpiXHjxrHAIiIiIiKityJ5kbV161ZMnjwZs2fPRkhICBo1agQvL688zx0+efIkBg4ciJEjR+LChQvo1asXevXqhStXrhRqv5uCU9G1a1fExMTA3d0d58+fR+/evTXxkoiIiIiISIfJhMQ3T2jevDmaNm2KH3/8EYBqBBAnJyeMHz8e06dPz7G8j48PkpKSsHv3bnVfixYt0LhxY6xZs+aN+0tISIClpaV6esyYMViyZAmMjY018GqIiIiIiKi0eFkbxMfHw8LCQmPblfSarPT0dJw/fx4zZsxQ9+np6cHT0xOnTp3KdZ1Tp05h8uTJ2fq8vLzwxx9/5Lp8Wloa0tLS1NPx8fEAAAMDGVavXov+/fsjPT1dPX4+ERERERHphoSEBACav2GxpEVWTEwMFAoF7OzssvXb2dnh+vXrua4TFRWV6/JRUVG5Lr9w4ULMnTs3R39GhsCoUaMwatSoIqYnIiIiIqKy4NmzZ9nOdntbZX50wRkzZmQ78hUXFwdnZ2fcu3dPo28k0esSEhLg5OSE+/fva/TwM9Hr+FkjbeFnjbSFnzXSlvj4eFSpUgXW1tYa3a6kRVbFihUhl8sRHR2drT86Olp9v6rX2dvbF2p5IyMjGBkZ5ei3tLTkDy1phYWFBT9rpBX8rJG28LNG2sLPGmmLpu+jJenogoaGhmjSpAmCg4PVfUqlEsHBwWjZsmWu67Rs2TLb8gBw8ODBPJcnIiIiIiLSJslPF5w8eTKGDRsGDw8PNGvWDMuWLUNSUhJGjBgBABg6dCgqV66MhQsXAgAmTpyIdu3aYfHixejWrRsCAwNx7tw5/Pzzz1K+DCIiIiIiIgAloMjy8fHB06dPMWvWLERFRaFx48bYt2+fenCLe/fuZTt816pVK/z222/48ssv8cUXX6BGjRr4448/UL9+/QLtz8jICLNnz871FEIiTeJnjbSFnzXSFn7WSFv4WSNtKa7PmuT3ySIiIiIiIipLJL0mi4iIiIiIqKxhkUVERERERKRBLLKIiIiIiIg0iEUWERERERGRBpXJIsvPzw8uLi4wNjZG8+bNcebMmXyXDwoKQu3atWFsbIwGDRpg7969WkpKpV1hPmtr165FmzZtUL58eZQvXx6enp5v/GwSvVTY32svBQYGQiaToVevXsUbkMqMwn7W4uLiMHbsWFSqVAlGRkaoWbMm/x+lAinsZ23ZsmWoVasWTExM4OTkhEmTJiE1NVVLaam0OnbsGLp37w4HBwfIZDL88ccfb1zn6NGjcHd3h5GREapXrw5/f/9C77fMFVlbt27F5MmTMXv2bISEhKBRo0bw8vLCkydPcl3+5MmTGDhwIEaOHIkLFy6gV69e6NWrF65cuaLl5FTaFPazdvToUQwcOBBHjhzBqVOn4OTkhPfeew8PHz7UcnIqbQr7WXspMjISU6ZMQZs2bbSUlEq7wn7W0tPT8e677yIyMhLbt2/HjRs3sHbtWlSuXFnLyam0Kexn7bfffsP06dMxe/ZsXLt2DevWrcPWrVvxxRdfaDk5lTZJSUlo1KgR/Pz8CrR8REQEunXrhg4dOiA0NBSffvopRo0ahf379xdux6KMadasmRg7dqx6WqFQCAcHB7Fw4cJcl/f29hbdunXL1te8eXMxevToYs1JpV9hP2uvy8zMFObm5mLjxo3FFZHKiKJ81jIzM0WrVq3EL7/8IoYNGyZ69uyphaRU2hX2s7Z69WpRtWpVkZ6erq2IVEYU9rM2duxY0bFjx2x9kydPFq1bty7WnFS2ABA7d+7Md5lp06aJevXqZevz8fERXl5ehdpXmTqSlZ6ejvPnz8PT01Pdp6enB09PT5w6dSrXdU6dOpVteQDw8vLKc3kioGiftdclJycjIyMD1tbWxRWTyoCiftbmzZsHW1tbjBw5UhsxqQwoymftzz//RMuWLTF27FjY2dmhfv36WLBgARQKhbZiUylUlM9aq1atcP78efUpheHh4di7dy+6du2qlcykOzRVG+hrMpTUYmJioFAoYGdnl63fzs4O169fz3WdqKioXJePiooqtpxU+hXls/a6zz//HA4ODjl+kIleVZTP2vHjx7Fu3TqEhoZqISGVFUX5rIWHh+Pw4cPw9fXF3r17cfv2bXzyySfIyMjA7NmztRGbSqGifNYGDRqEmJgYvPPOOxBCIDMzEx9//DFPFySNy6s2SEhIQEpKCkxMTAq0nTJ1JIuotPj2228RGBiInTt3wtjYWOo4VIa8ePECQ4YMwdq1a1GxYkWp41AZp1QqYWtri59//hlNmjSBj48PZs6ciTVr1kgdjcqYo0ePYsGCBVi1ahVCQkKwY8cO7NmzB19//bXU0YhyVaaOZFWsWBFyuRzR0dHZ+qOjo2Fvb5/rOvb29oVanggo2mftpR9++AHffvstDh06hIYNGxZnTCoDCvtZu3PnDiIjI9G9e3d1n1KpBADo6+vjxo0bqFatWvGGplKpKL/XKlWqBAMDA8jlcnVfnTp1EBUVhfT0dBgaGhZrZiqdivJZ++qrrzBkyBCMGjUKANCgQQMkJSXho48+wsyZM6Gnx+MGpBl51QYWFhYFPooFlLEjWYaGhmjSpAmCg4PVfUqlEsHBwWjZsmWu67Rs2TLb8gBw8ODBPJcnAor2WQOARYsW4euvv8a+ffvg4eGhjahUyhX2s1a7dm1cvnwZoaGh6kePHj3UoyQ5OTlpMz6VIkX5vda6dWvcvn1bXcgDwM2bN1GpUiUWWJSnonzWkpOTcxRSL4t71XgGRJqhsdqgcGNylHyBgYHCyMhI+Pv7i7CwMPHRRx8JKysrERUVJYQQYsiQIWL69Onq5U+cOCH09fXFDz/8IK5duyZmz54tDAwMxOXLl6V6CVRKFPaz9u233wpDQ0Oxfft28fjxY/XjxYsXUr0EKiUK+1l7HUcXpIIq7Gft3r17wtzcXIwbN07cuHFD7N69W9ja2opvvvlGqpdApURhP2uzZ88W5ubmYsuWLSI8PFwcOHBAVKtWTXh7e0v1EqiUePHihbhw4YK4cOGCACCWLFkiLly4IO7evSuEEGL69OliyJAh6uXDw8OFqampmDp1qrh27Zrw8/MTcrlc7Nu3r1D7LXNFlhBCrFy5UlSpUkUYGhqKZs2aiX///Vc9r127dmLYsGHZlt+2bZuoWbOmMDQ0FPXq1RN79uzRcmIqrQrzWXN2dhYAcjxmz56t/eBU6hT299qrWGRRYRT2s3by5EnRvHlzYWRkJKpWrSrmz58vMjMztZyaSqPCTRDZCAAACqdJREFUfNYyMjLEnDlzRLVq1YSxsbFwcnISn3zyiXj+/Ln2g1OpcuTIkVy/f738fA0bNky0a9cuxzqNGzcWhoaGomrVqmLDhg2F3q9MCB5jJSIiIiIi0pQydU0WERERERGR1FhkERERERERaRCLLCIiIiIiIg1ikUVERERERKRBLLKIiIiIiIg0iEUWERERERGRBrHIIiIiIiIi0iAWWURERERERBrEIouIiIrE398fVlZWUscoMplMhj/++CPfZYYPH45evXppJQ8REZUdLLKIiHTY8OHDIZPJcjxu374tdTT4+/ur8+jp6cHR0REjRozAkydPNLL9x48fo0uXLgCAyMhIyGQyhIaGZltm+fLl8Pf318j+8jJnzhz165TL5XBycsJHH32E2NjYQm2HBSERUcmhL3UAIiKSVufOnbFhw4ZsfTY2NhKlyc7CwgI3btyAUqnExYsXMWLECDx69Aj79+9/623b29u/cRlLS8u33k9B1KtXD4cOHYJCocC1a9fwwQcfID4+Hlu3btXK/omISLN4JIuISMcZGRnB3t4+20Mul2PJkiVo0KABzMzM4OTkhE8++QSJiYl5bufixYvo0KEDzM3NYWFhgSZNmuDcuXPq+cePH0ebNm1gYmICJycnTJgwAUlJSflmk8lksLe3h4ODA7p06YIJEybg0KFDSElJgVKpxLx58+Do6AgjIyM0btwY+/btU6+bnp6OcePGoVKlSjA2NoazszMWLlyYbdsvTxd0dXUFALi5uUEmk6F9+/YAsh8d+vnnn+Hg4AClUpktY8+ePfHBBx+op3ft2gV3d3cYGxujatWqmDt3LjIzM/N9nfr6+rC3t0flypXh6emJ/v374+DBg+r5CoUCI0eOhKurK0xMTFCrVi0sX75cPX/OnDnYuHEjdu3apT4qdvToUQDA/fv34e3tDSsrK1hbW6Nnz56IjIzMNw8REb0dFllERJQrPT09rFixAlevXsXGjRtx+PBhTJs2Lc/lfX194ejoiLNnz+L8+fOYPn06DAwMAAB37txB586d0bdvX1y6dAlbt27F8ePHMW7cuEJlMjExgVKpRGZmJpYvX47Fixfjhx9+wKVLl+Dl5YUePXrg1q1bAIAVK1bgzz//xLZt23Djxg0EBATAxcUl1+2eOXMGAHDo0CE8fvwYO3bsyLFM//798ezZMxw5ckTdFxsbi3379sHX1xcA8M8//2Do0KGYOHEiwsLC8NNPP8Hf3x/z588v8GuMjIzE/v37YWhoqO5TKpVwdHREUFAQwsLCMGvWLHzxxRfYtm0bAGDKlCnw9vZG586d8fjxYzx+/BitWrVCRkYGvLy8YG5ujn/++QcnTpxAuXLl0LlzZ6Snpxc4ExERFZIgIiKdNWzYMCGXy4WZmZn60a9fv1yXDQoKEhUqVFBPb9iwQVhaWqqnzc3Nhb+/f67rjhw5Unz00UfZ+v755x+hp6cnUlJScl3n9e3fvHlT1KxZU3h4eAghhHBwcBDz58/Ptk7Tpk3FJ598IoQQYvz48aJjx45CqVTmun0AYufOnUIIISIiIgQAceHChWzLDBs2TPTs2VM93bNnT/HBBx+op3/66Sfh4OAgFAqFEEKITp06iQULFmTbxqZNm0SlSpVyzSCEELNnzxZ6enrCzMxMGBsbCwACgFiyZEme6wghxNixY0Xfvn3zzPpy37Vq1cr2HqSlpQkTExOxf//+fLdPRERFx2uyiIh0XIcOHbB69Wr1tJmZGQDVUZ2FCxfi+vXrSEhIQGZmJlJTU5GcnAxTU9Mc25k8eTJGjRqFTZs2qU95q1atGgDVqYSXLl1CQECAenkhBJRKJSIiIlCnTp1cs8XHx6NcuXJQKpVITU3FO++8g19++QUJCQl49OgRWrdunW351q1b4+LFiwBUp/q9++67qFWrFjp37oz3338f77333lu9V76+vvjwww+xatUqGBkZISAgAAMGDICenp76dZ44cSLbkSuFQpHv+wYAtWrVwp9//onU1FRs3rwZoaGhGD9+fLZl/Pz8sH79ety7dw8pKSlIT09H48aN88178eJF3L59G+bm5tn6U1NTcefOnSK8A0REVBAssoiIdJyZmRmqV6+erS8yMhLvv/8+xowZg/nz58Pa2hrHjx/HyJEjkZ6enmuxMGfOHAwaNAh79uzBX3/9hdmzZyMwMBC9e/dGYmIiRo8ejQkTJuRYr0qVKnlmMzc3R0hICPT09FCpUiWYmJgAABISEt74utzd3REREYG//voLhw4dgre3Nzw9PbF9+/Y3rpuX7t27QwiBPXv2oGnTpvjnn3+wdOlS9fzExETMnTsXffr0ybGusbFxnts1NDRU/xt8++236NatG+bOnYuvv/4aABAYGIgpU6Zg8eLFaNmyJczNzfH999/j9OnT+eZNTExEkyZNshW3L5WUwU2IiMoiFllERJTD+fPnoVQqsXjxYvVRmpfX/+SnZs2aqFmzJiZNmoSBAwdiw4YN6N27N9zd3REWFpajmHsTPT29XNexsLCAg4MDTpw4gXbt2qn7T5w4gWbNmmVbzsfHBz4+PujXrx86d+6M2NhYWFtbZ9vey+ufFApFvnmMjY3Rp08fBAQE4Pbt26hVqxbc3d3V893d3XHjxo1Cv87Xffnll+jYsSPGjBmjfp2tWrXCJ598ol7m9SNRhoaGOfK7u7tj69atsLW1hYWFxVtlIiKiguPAF0RElEP16tWRkZGBlStXIjw8HJs2bcKaNWvyXD4lJQXjxo3D0aNHcffuXZw4cQJnz55Vnwb4+eef4+TJkxg3bhxCQ0Nx69Yt7Nq1q9ADX7xq6tSp+O6777B161bcuHED06dPR2hoKCZOnAgAWLJkCbZs2YLr16/j5s2bCAoKgr29fa43ULa1tYWJiQn27duH6OhoxMfH57lfX19f7NmzB+vXr1cPePHSrFmz8Ouvv2Lu3Lm4evUqrl27hsDAQHz55ZeFem0tW7ZEw4YNsWDBAgBAjRo1cO7cOezfvx83b97EV199hbNnz2Zbx8XFBZcuXcKNGzcQExODjIwM+Pr6omLFiujZsyf++ecfRERE4OjRo5gwYQIePHhQqExERFRwLLKIiCiHRo0aYcmSJfjuu+9Qv359BAQEZBv+/HVyuRzPnj3D0KFDUbNmTXh7e6NLly6YO3cuAKBhw4b4+++/cfPmTbRp0wZubm6YNWsWHBwcipxxwoQJmDx5Mj777DM0aNAA+/btw59//okaNWoAUJ1quGjRInh4eKBp06aIjIzE3r171UfmXqWvr48VK1bgp59+goODA3r27Jnnfjt27Ahra2vcuHEDgwYNyjbPy8sLu3fvxoEDB9C0aVO0aNECS5cuhbOzc6Ff36RJk/DLL7/g/v37GD16NPr06QMfHx80b94cz549y3ZUCwA+/PBD1KpVCx4eHrCxscGJEydgamqKY8eOoUqVKujTpw/q1KmDkSNHIjU1lUe2iIiKkUwIIaQOQUREREREVFbwSBYREREREZEGscgiIiIiIiLSIBZZREREREREGsQii4iIiIiISINYZBEREREREWkQiywiIiIiIiINYpFFRERERESkQSyyiIiIiIiINIhFFhERERERkQaxyCIiIiIiItIgFllEREREREQa9H/Qxy8wqSibuwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize predictor\n",
    "predictor = SentimentPredictor(language, config)\n",
    "\n",
    "# Make predictions\n",
    "predictions = predictor.predict(X_test_features)\n",
    "probabilities = predictor.predict_proba(X_test_features)\n",
    "\n",
    "# Modified evaluation code to handle multiclass\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "# Basic metrics\n",
    "results = {\n",
    "    'classification_report': classification_report(y_test, predictions),\n",
    "    'confusion_matrix': confusion_matrix(y_test, predictions)\n",
    "}\n",
    "\n",
    "# Display results\n",
    "print(\"Classification Report:\")\n",
    "print(results['classification_report'])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(results['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "n_classes = probabilities.shape[1]\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "for i in range(n_classes):\n",
    "    # Convert to one-vs-rest binary format\n",
    "    y_test_binary = (y_test == i).astype(int)\n",
    "    \n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, _ = roc_curve(y_test_binary, probabilities[:, i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # diagonal line\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves (One-vs-Rest)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Thử nghiệm Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-08 11:59:25,479 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-12-08 11:59:25,484 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "Word features shape: (1, 2000)\n",
      "Char features shape: (1, 500)\n",
      "Tfidf features shape: (1, 2000)\n",
      "Linguistic features shape: (1, 6)\n",
      "Emotion features shape: (1, 15)\n",
      "All features shape after hstack: (1, 4521)\n",
      "\n",
      "Text: Sản phẩm rất tốt, tôi rất thích\n",
      "Sentiment: 2\n",
      "Confidence: 0.8338\n",
      "Emotion: happy (vui vẻ) 😊\n",
      "2024-12-08 11:59:25,678 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-12-08 11:59:25,681 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "Word features shape: (1, 2000)\n",
      "Char features shape: (1, 500)\n",
      "Tfidf features shape: (1, 2000)\n",
      "Linguistic features shape: (1, 6)\n",
      "Emotion features shape: (1, 15)\n",
      "All features shape after hstack: (1, 4521)\n",
      "\n",
      "Text: Chất lượng kém, không đáng tiền\n",
      "Sentiment: 0\n",
      "Confidence: 0.4846\n",
      "Emotion: disappointed (thất vọng) 😞\n",
      "2024-12-08 11:59:25,850 - src.data.preprocessor - INFO - Preprocessing vi data...\n",
      "2024-12-08 11:59:25,853 - src.data.preprocessor - INFO - Preprocessed 1 valid samples\n",
      "Word features shape: (1, 2000)\n",
      "Char features shape: (1, 500)\n",
      "Tfidf features shape: (1, 2000)\n",
      "Linguistic features shape: (1, 6)\n",
      "Emotion features shape: (1, 15)\n",
      "All features shape after hstack: (1, 4521)\n",
      "\n",
      "Text: Tạm được, không tốt không xấu\n",
      "Sentiment: 2\n",
      "Confidence: 0.4224\n",
      "Emotion: happy (vui vẻ) 😊\n"
     ]
    }
   ],
   "source": [
    "# Test with sample texts\n",
    "test_texts = [\n",
    "    \"Sản phẩm rất tốt, tôi rất thích\",\n",
    "    \"Chất lượng kém, không đáng tiền\",\n",
    "    \"Tạm được, không tốt không xấu\"\n",
    "]\n",
    "\n",
    "# Process and predict\n",
    "for text in test_texts:\n",
    "    # Preprocess\n",
    "    df = pd.DataFrame({'text': [text]})\n",
    "    processed = preprocessor.preprocess(df)\n",
    "    \n",
    "    # Extract features\n",
    "    features = feature_extractor.extract_features(processed['cleaned_text'])\n",
    "    \n",
    "    # Get prediction with emotion\n",
    "    result = predictor.predict_emotion(features, text)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nText: {text}\")\n",
    "    print(f\"Sentiment: {result['sentiment']}\")\n",
    "    print(f\"Confidence: {result['sentiment_confidence']:.4f}\")\n",
    "    print(f\"Emotion: {result['emotion']} ({result['emotion_vi']}) {result['emotion_emoji']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Phân tích Hiệu năng chi tiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lấy metrics từ model_info\n",
    "model_path = os.path.join(config.DATA_DIR, \"models\", f\"{language}_sentiment_model.pkl\")\n",
    "model_info = joblib.load(model_path)\n",
    "metrics = model_info['metrics']\n",
    "\n",
    "# Hiển thị training history\n",
    "if 'training_history' in metrics:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for model_name, history in metrics['training_history'].items():\n",
    "        plt.plot(history['train_scores'], 'o-', label=f'{model_name}_train')\n",
    "        plt.plot(history['valid_scores'], 's--', label=f'{model_name}_val')\n",
    "    \n",
    "    plt.title('Training History')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Hiển thị feature importance nếu có\n",
    "if models and 'rf' in models and hasattr(models['rf'], 'feature_importances_'):\n",
    "    importances = models['rf'].feature_importances_\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(len(importances)), importances)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

================
File: README.md
================
# Vietnamese-English Sentiment Analysis System

A robust machine learning system for sentiment analysis supporting both Vietnamese and English text, built with advanced NLP techniques and ensemble learning.

## Key Features

- **Multilingual Support**: Vietnamese and English language processing
- **Advanced Text Processing**:
  - Intelligent text cleaning
  - Stop word removal
  - Language-specific tokenization
- **Feature Engineering**:
  - TF-IDF vectorization
  - SVD dimensionality reduction
  - Statistical feature extraction
- **Ensemble Learning**:
  - Random Forest
  - Linear SVC
  - Naive Bayes
- **Data Augmentation**:
  - Synonym replacement
  - Random swap
  - Random deletion
  - Random insertion

## Directory Structure
```
sentiment_analysis/
├── data/
│ ├── raw/ # Raw input data
│ ├── processed/ # Processed data
│ └── models/ # Trained model files
├── src/
│ ├── config.py # Configuration settings
│ ├── main.py # Main application entry point
│ ├── data/ # Data handling modules
│ ├── features/ # Feature engineering
│ ├── models/ # Model training and prediction
│ └── utils/ # Utility functions
├── scripts/
│ ├── generate_training_data.py
│ └── train_models.py
└── requirements.txt
```

## Installation

1. Clone the repository:

```bash
git clone https://github.com/yourusername/sentiment_analysis.git
cd sentiment_analysis
```

2. Create a virtual environment (optional but recommended):

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. Install dependencies:

```bash
pip install -r requirements.txt
```

## Usage

1. Data Generation
   Generate training data for both languages:

```bash
python scripts/generate_training_data.py --language vi --output data/processed/vi_processed_data.csv
python scripts/generate_training_data.py --language en --output data/processed/en_processed_data.csv
```

2. Model Training Train models for both languages:

```bash
python scripts/train_models.py --language vi --output models/vi_model.pkl
python scripts/train_models.py --language en --output models/en_model.pkl
```

3. Sentiment Analysis
   The main application supports three modes:

   - **Training Mode**: Train the model with new data.
   - **Prediction Mode**: Predict sentiment for new input text.
   - **Evaluation Mode**: Evaluate the model performance on test data.

4. Input Data Format
   The input CSV files should have the following format:

   ```csv
   text,label
   "This is a positive review",positive
   "This is a negative review",negative
   ```

## Model Performance

Current model performance metrics:

| Language   | Accuracy | F1-Score | Precision | Recall |
| ---------- | -------- | -------- | --------- | ------ |
| English    | 0.85     | 0.84     | 0.83      | 0.85   |
| Vietnamese | 0.82     | 0.81     | 0.80      | 0.82   |

## Requirements

- Python 3.8+
- scikit-learn
- pandas
- numpy
- underthesea (for Vietnamese)
- nltk
- textaugment
- seaborn
- matplotlib

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details

================
File: repomix.config.json
================
{
  "output": {
    "filePath": "repomix-output.txt",
    "style": "plain",
    "removeComments": false,
    "removeEmptyLines": false,
    "topFilesLength": 5,
    "showLineNumbers": false,
    "copyToClipboard": false
  },
  "include": [],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  },
  "security": {
    "enableSecurityCheck": true
  }
}

================
File: requirements.txt
================
asttokens==2.4.1
attrs==24.2.0
backcall==0.2.0
beautifulsoup4>=4.9.0
bleach==6.2.0
certifi==2024.8.30
chardet==3.0.4
charset-normalizer==3.4.0
click==8.1.7
colorama==0.4.6
comm==0.2.2
contourpy==1.3.0
cycler==0.12.1
debugpy==1.8.8
decorator==5.1.1
defusedxml==0.7.1
docopt==0.6.2
exceptiongroup==1.2.2
executing==2.1.0
fastjsonschema==2.20.0
fonttools==4.54.1
google-play-scraper>=1.2.0
googletrans==3.1.0a0
h11==0.9.0
h2==3.2.0
hpack==3.0.0
hstspreload==2024.11.1
httpcore==0.9.1
httpx==0.13.3
hyperframe==5.2.0
idna==2.10
iniconfig==2.0.0
ipykernel==6.29.5
ipython==8.12.3
ipywidgets==8.1.5
jedi==0.19.1
Jinja2==3.1.4
joblib>=1.0.0
jsonschema==4.23.0
jsonschema-specifications==2024.10.1
jupyter_client==8.6.3
jupyter_core==5.7.2
jupyterlab_pygments==0.3.0
jupyterlab_widgets==3.0.13
kiwisolver==1.4.7
markdown-it-py==3.0.0
MarkupSafe==3.0.2
matplotlib>=3.3.0
matplotlib-inline==0.1.7
mdurl==0.1.2
mistune==3.0.2
nbclient==0.10.0
nbconvert==7.16.4
nbformat==5.10.4
nest-asyncio==1.6.0
nltk>=3.6.0
numpy>=1.19.2
packaging==24.2
pandas>=1.2.0
pandocfilters==1.5.1
parso==0.8.4
pickleshare==0.7.5
pillow==11.0.0
pipreqs==0.5.0
platformdirs==4.3.6
pluggy==1.5.0
prompt_toolkit==3.0.48
psutil==6.1.0
pure_eval==0.2.3
Pygments==2.18.0
pyparsing==3.2.0
pytest==8.3.3
python-crfsuite==0.9.11
python-dateutil==2.9.0.post0
pytz==2024.2
pywin32==308
PyYAML==6.0.2
pyzmq==26.2.0
referencing==0.35.1
regex==2024.11.6
requests>=2.25.0
rfc3986==1.5.0
rich>=10.0.0
rpds-py==0.21.0
scikit-learn>=0.24.0
scipy==1.13.1
seaborn>=0.11.0
six==1.16.0
sklearn==0.0
smart-open==7.0.5
sniffio==1.3.1
soupsieve==2.6
stack-data==0.6.3
threadpoolctl==3.5.0
tinycss2==1.4.0
tomli==2.0.2
tornado==6.4.1
tqdm>=4.60.0
traitlets==5.14.3
typing_extensions==4.12.2
tzdata==2024.2
underthesea>=1.3.0
underthesea_core==1.0.4
urllib3==2.2.3
wcwidth==0.2.13
webencodings==0.5.1
widgetsnbextension==4.0.13
wrapt==1.16.0
yarg==0.1.9

================
File: road-map.md
================
# Chi Tiết Quy Trình Training Và Thuật Toán

## 1. Tổng Quan Quy Trình

### 1.1 Luồng Xử Lý
```
Input Text -> Preprocessing -> Feature Extraction -> Model Training -> Model Evaluation -> Export Model
```

### 1.2 Các Bước Chính
1. Thu thập dữ liệu từ nhiều nguồn
2. Tiền xử lý văn bản
3. Trích xuất đặc trưng 
4. Huấn luyện mô hình ensemble
5. Đánh giá và tối ưu hóa
6. Triển khai mô hình

## 2. Thu Thập & Tiền Xử Lý Dữ Liệu

### 2.1 Nguồn Dữ Liệu
- Comments trên mạng xã hội
- Reviews trên các trang thương mại điện tử
- Dữ liệu được gán nhãn thủ công
- Dữ liệu được sinh tự động (augmentation)

### 2.2 Tiền Xử Lý Văn Bản
- Làm sạch văn bản: loại bỏ HTML, kí tự đặc biệt
- Chuẩn hóa: lowercase, unicode
- Tokenization: tách từ theo ngôn ngữ
- Loại bỏ stopwords
- Cân bằng dữ liệu giữa các classes

## 3. Trích Xuất Đặc Trưng (Feature Engineering)

### 3.1 TF-IDF Vectorization
- Chuyển văn bản thành vector số theo tần suất từ
- Tham số chính:
  - max_features: 10000 (giới hạn số đặc trưng)
  - ngram_range: (1,3) (unigrams, bigrams, trigrams)
  - min_df: 5 (loại từ hiếm)
  - max_df: 0.95 (loại từ quá phổ biến)

### 3.2 Linguistic Features (6 đặc trưng)
- Số câu trong văn bản
- Độ dài trung bình mỗi câu
- Độ dài trung bình các từ
- Tỷ lệ dấu câu
- Tỷ lệ chữ hoa
- Tỷ lệ stopwords

### 3.3 Emotion Features (15 đặc trưng)
- Điểm số cho 12 loại cảm xúc cơ bản
- Tỷ lệ emojis
- Tỷ lệ dấu cảm xúc (!,?,...)
- Số từ cảm xúc trong từ điển

## 4. Huấn Luyện Mô Hình (Model Training)

### 4.1 Ensemble Model (Kết hợp 3 mô hình)

#### a) Random Forest
- Số cây (n_estimators): 1000
- Độ sâu tối đa (max_depth): 50
- Min samples split: 10
- Class weights: balanced
- Đặc điểm:
  + Chống overfitting tốt
  + Xử lý được dữ liệu không cân bằng
  + Cho biết feature importance

#### b) Linear SVM 
- C: 0.8 (regularization strength)
- Max iterations: 2000
- Class weights: balanced
- Dual: False
- Đặc điểm:
  + Hiệu quả với văn bản
  + Tìm siêu phẳng phân tách tối ưu
  + Xử lý được high dimensional data

#### c) Multinomial Naive Bayes
- Alpha: 1.2 (smoothing parameter)
- Fit prior: True
- Đặc điểm:
  + Nhanh và nhẹ
  + Hiệu quả với text classification
  + Xử lý được sparse data

### 4.2 Cross-validation
- Stratified K-Fold với k=10
- Đảm bảo cân bằng classes trong mỗi fold
- Metrics:
  + F1-score (weighted)
  + Precision & Recall
  + Accuracy

### 4.3 Early Stopping
- Patience: 5 epochs
- Min delta: 0.001
- Monitor: validation F1-score
- Giúp tránh overfitting

### 4.4 Class Balancing
- Compute sample weights
- Undersampling class đa số
- Oversampling class thiểu số
- Class weights tự động

## 5. Đánh Giá Và Tối Ưu Hóa

### 5.1 Grid Search CV
- Tìm hyperparameters tối ưu
- Parameters được search:
  + RF: n_estimators, max_depth
  + SVM: C, max_iter
  + NB: alpha, fit_prior
- Metrics: F1-score weighted

### 5.2 Feature Selection
- Mutual Information Classifier
- Chi-square test
- SelectKBest với k=800-1200

### 5.3 Regularization
- RF: ccp_alpha=0.002 (pruning)
- SVM: C=0.8 (regularization)
- NB: alpha=1.2 (smoothing)

## 6. Lưu Trữ & Triển Khai

### 6.1 Model Checkpointing
- Lưu model sau mỗi epoch
- Lưu optimizer state
- Lưu training history
- Giới hạn 5 checkpoints gần nhất

### 6.2 Model Export
- Lưu model cuối cùng
- Lưu feature extractors
- Lưu các metrics
- Lưu config

### 6.3 Model Serving
- REST API endpoints 
- WebSocket realtime
- Batch prediction
- Load balancing

## 7. Monitoring & Logging

### 7.1 Training Metrics
- Loss curves
- Accuracy curves
- F1-score theo epoch
- Learning rate changes

### 7.2 Production Metrics
- Inference latency
- Memory usage
- Error rates
- Request throughput

### 7.3 Alerts
- High error rate
- Long response time
- Resource usage cao
- Model degradation

## 8. Kết Quả & Hiệu Năng

### 8.1 Metrics
- Accuracy: 85-90%
- F1-score: 83-88%
- ROC-AUC: 0.90-0.95

### 8.2 Performance 
- Inference time: <100ms
- Memory usage: <500MB
- Error rate: <0.1%
- Uptime: 99.9%

================
File: run_api.py
================
import uvicorn
from src.config import Config

def main():
    config = Config()
    # Only use supported uvicorn.run() parameters
    uvicorn.run(
        "src.api.app:app",
        host=config.API_CONFIG['HOST'],
        port=config.API_CONFIG['PORT'],
        workers=config.API_CONFIG['WORKERS'],
        reload=config.API_CONFIG['RELOAD'],
        log_level="info",
        limit_concurrency=100
    )

if __name__ == "__main__":
    main()

================
File: scripts/data_collection_cli.py
================
from src.config import Config
from src.data.data_collection import DataCollector
import argparse
import pandas as pd

def main():
    parser = argparse.ArgumentParser(description='Thu thập dữ liệu đánh giá')
    parser.add_argument('--source', type=str, required=True,
                      choices=['google_play', 'shopee', 'facebook', 'manual'],
                      help='Nguồn dữ liệu cần thu thập')
    parser.add_argument('--app_id', type=str, help='ID ứng dụng Google Play')
    parser.add_argument('--product_ids', type=str, help='ID sản phẩm Shopee (phân cách bằng dấu phẩy)')
    parser.add_argument('--post_ids', type=str, help='ID bài đăng Facebook (phân cách bằng dấu phẩy)')
    parser.add_argument('--access_token', type=str, help='Facebook API access token')
    parser.add_argument('--input_file', type=str, help='Đường dẫn file Excel/CSV chứa đánh giá')
    parser.add_argument('--count', type=int, default=100, help='Số lượng đánh giá cần thu thập')
    
    args = parser.parse_args()
    config = Config()
    collector = DataCollector(config)
    
    if args.source == 'google_play':
        if not args.app_id:
            print("Vui lòng cung cấp app_id")
            return
        df = collector.collect_google_play_reviews(args.app_id, count=args.count)
        
    elif args.source == 'shopee':
        if not args.product_ids:
            print("Vui lòng cung cấp product_ids")
            return
        product_ids = args.product_ids.split(',')
        df = collector.collect_shopee_reviews(product_ids, max_reviews=args.count)
        
    elif args.source == 'facebook':
        if not args.post_ids or not args.access_token:
            print("Vui lòng cung cấp post_ids và access_token")
            return
        post_ids = args.post_ids.split(',')
        df = collector.collect_facebook_comments(post_ids, args.access_token)
        
    elif args.source == 'manual':
        if not args.input_file:
            print("Vui lòng cung cấp input_file")
            return
        df = collector.collect_manual_reviews(args.input_file)
    
    if not df.empty:
        collector.save_collected_data(df, args.source)

if __name__ == "__main__":
    main()

================
File: scripts/generate_training_data.py
================
import argparse
import random
import pandas as pd
from sklearn.utils import resample
import sys
import os

from src.utils.templates import CommentTemplates

# Add project root to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config import Config
from src.data.data_loader import DataLoader
from src.data.preprocessor import DataPreprocessor
from src.utils.logger import Logger
from src.utils.augmentation import TextAugmenter


class TrainingDataGenerator:
    def __init__(self, language: str, config: Config, num_samples: int = 1000):
        self.language = language
        self.config = config
        self.num_samples = num_samples
        self.logger = Logger(__name__).logger
        self.data_loader = DataLoader(config)
        self.preprocessor = DataPreprocessor(language, config)
        self.eda = TextAugmenter()

    def generate_natural_variation(self, text: str, label: int):
        """Tạo biến thể tự nhiên cho văn bản"""
        templates = CommentTemplates()
        
        # Thêm opening/closing ngẫu nhiên
        if random.random() < 0.7:  # 70% chance
            text = f"{random.choice(templates.natural_expressions['opening'])}, {text}"
        if random.random() < 0.5:  # 50% chance
            text = f"{text}. {random.choice(templates.natural_expressions['closing'])}"
            
        # Thêm emoji phù hợp
        sentiment = {0: 'negative', 1: 'neutral', 2: 'positive'}[label]
        if random.random() < 0.8:  # 80% chance
            emojis = templates.emojis[sentiment]
            emoji_count = random.randint(1, 3)
            text = f"{text} {''.join(random.sample(emojis, emoji_count))}"
            
        return text

    def generate_synthetic_data(self, text: str, label: int):
        synthetic_samples = []
        text_variations = set()
        
        templates = CommentTemplates()
        sentiment = {0: 'negative', 1: 'neutral', 2: 'positive'}[label]
        
        for _ in range(4):
            try:
                # Thêm xác suất để sinh bình luận tương tác
                if random.random() < 0.2:  # 20% chance for interaction comments
                    if label == 0:  # negative
                        interaction_type = random.choice(['argument', 'trolling'])
                        sub_type = 'aggressive' if interaction_type == 'argument' else None
                    elif label == 2:  # positive
                        interaction_type = 'support'
                        sub_type = random.choice(['agreement', 'praise'])
                    else:  # neutral
                        interaction_type = random.choice(['argument', 'support', 'trolling'])
                        sub_type = 'dismissive' if interaction_type == 'argument' else None
                    
                    augmented_text = templates.generate_interaction_comment(interaction_type, sub_type)
                else:
                    # Xác suất để chọn độ dài khác nhau
                    if random.random() < 0.3:
                        augmented_text = templates.generate_varied_length_comment(sentiment, 'general')
                    else:
                        augmented_text = self.eda.humanize_text(text, self.language, sentiment)
                
                augmented_text = self.generate_natural_variation(augmented_text, label)
                
                if augmented_text not in text_variations and len(augmented_text.split()) >= 3:
                    text_variations.add(augmented_text)
                    synthetic_samples.append({"text": augmented_text, "label": label})
            except Exception as e:
                self.logger.warning(f"Error in augmentation: {str(e)}")
                continue

        return synthetic_samples

    def balance_dataset(self, df: pd.DataFrame, target_col: str = "label"):
        """Balance dataset using upsampling"""
        self.logger.info("Balancing dataset...")

        # Get class distribution
        class_counts = df[target_col].value_counts()
        max_size = class_counts.max()

        # Balance each class
        balanced_dfs = []
        for label in class_counts.index:
            class_df = df[df[target_col] == label]
            if len(class_df) < max_size:
                upsampled = resample(
                    class_df, replace=True, n_samples=max_size, random_state=42
                )
                balanced_dfs.append(upsampled)
            else:
                balanced_dfs.append(class_df)

        return pd.concat(balanced_dfs)

    def generate_training_data(self, output_path: str):
        """Main method to generate and save training data with exactly two columns"""
        self.logger.info(f"Generating {self.num_samples} training samples for {self.language}...")
        
        # Create output directory if not exists
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # Generate synthetic data with topic-based generation
        synthetic_data = []
        
        # Define topics and sentiment ratios
        topics = {
            'product_review': 0.3,
            'food_review': 0.25,
            'service_review': 0.25,
            'movie_review': 0.2
        }
        
        sentiment_ratios = {
            'negative': 0.25,  # 25% negative
            'neutral': 0.25,   # 25% neutral
            'positive': 0.50   # 50% positive
        }
        
        # Calculate samples per topic and sentiment
        for topic, topic_weight in topics.items():
            topic_samples = int(self.num_samples * topic_weight)
            
            for sentiment, sent_ratio in sentiment_ratios.items():
                sent_samples = int(topic_samples * sent_ratio)
                sentiment_label = {'negative': 0, 'neutral': 1, 'positive': 2}[sentiment]
                
                comments = self.eda.generate_topic_comments(
                    topic, 
                    count=sent_samples,
                    language=self.language,
                    sentiment=sentiment_label
                )
                synthetic_data.extend(comments)
        
        # Convert to DataFrame with only required columns
        df = pd.DataFrame(synthetic_data)[['text', 'label']]
        
        # Validate and clean data
        df['text'] = df['text'].astype(str).str.strip()
        df['label'] = df['label'].astype(int)
        
        # Remove any rows with missing values
        df = df.dropna().reset_index(drop=True)
        
        # Thêm kiểm tra trùng lặp
        df.drop_duplicates(subset=['text'], keep='first', inplace=True)
        
        # Thêm random shuffling để tăng tính ngẫu nhiên
        df = df.sample(frac=1, random_state=42).reset_index(drop=True)
        
        # Save the data
        df.to_csv(output_path, index=False)
        self.logger.info(f"Generated and saved {len(df)} samples to {output_path}")
        
        # Log statistics
        self.logger.info("\n=== Generation Results ===")
        self.logger.info(f"Total samples: {len(df)}")
        self.logger.info("\nClass distribution:")
        self.logger.info(df['label'].value_counts())

def main():
    parser = argparse.ArgumentParser(
        description="Generate training data for sentiment analysis"
    )
    parser.add_argument(
        "--language",
        type=str,
        required=True,
        choices=["en", "vi"],
        help="Language to generate data for (en/vi)",
    )
    parser.add_argument(
        "--output",
        type=str,
        required=True,
        help="Output path for generated training data",
    )
    parser.add_argument(
        "--num_samples",
        type=int,
        default=1000,
        help="Number of synthetic samples to generate",
    )
    args = parser.parse_args()

    config = Config()
    generator = TrainingDataGenerator(args.language, config, args.num_samples)
    generator.generate_training_data(args.output)


if __name__ == "__main__":
    main()

================
File: scripts/train_models.py
================
import argparse
import joblib
import sys
import os

# Add project root to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.config import Config
from src.data.data_loader import DataLoader
from src.features.feature_engineering import FeatureExtractor
from src.models.model_trainer import EnhancedModelTrainer
from src.utils.logger import Logger

def train_model_for_language(language: str, config: Config):
    logger = Logger(__name__).logger
    logger.info(f"Training model for {language}...")
    
    # Initialize components
    data_loader = DataLoader(config)
    feature_extractor = FeatureExtractor(language, config)
    model_trainer = EnhancedModelTrainer(language, config)
    
    # Load processed data
    df = data_loader.load_processed_data(language)
    X, y = data_loader.get_features_and_labels(df)
    
    # Extract features
    X_features = feature_extractor.extract_features(X)
    
    # Train model
    model = model_trainer.train_with_grid_search(X_features, y)
    
    # Save model
    model_path = config.LANGUAGE_CONFIGS[language]['model_path']
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(model, model_path)
    logger.info(f"Model saved to {model_path}")

def main():
    parser = argparse.ArgumentParser(description='Train sentiment analysis models')
    parser.add_argument('--languages', nargs='+', choices=['en', 'vi'],
                      default=['en', 'vi'],
                      help='Languages to train models for')
    args = parser.parse_args()
    
    config = Config()
    for language in args.languages:
        train_model_for_language(language, config)

if __name__ == "__main__":
    main()

================
File: setup.py
================
from setuptools import setup, find_packages
import subprocess
import sys
import nltk
import os


def setup_environment():
    """Initialize required data and install dependencies"""

    print("Installing required packages...")
    try:
        subprocess.check_call(
            [sys.executable, "-m", "pip", "install", "-r", "requirements.txt"]
        )
    except subprocess.CalledProcessError as e:
        print(f"Error installing packages: {str(e)}")
        return False

    print("\nDownloading NLTK data...")
    try:
        # Download required NLTK data
        nltk.download("punkt")
        nltk.download("stopwords")
        nltk.download("wordnet")
        nltk.download("averaged_perceptron_tagger")
    except Exception as e:
        print(f"Error downloading NLTK data: {str(e)}")
        return False

    print("\nCreating required directories...")
    dirs = [
        "data",
        "data/raw_data",
        "data/processed_data",
        "data/models",
        "data/checkpoints",
        "data/metrics",
        "data/lexicons",
        "logs",
    ]

    for dir_path in dirs:
        os.makedirs(dir_path, exist_ok=True)
        print(f"Created directory: {dir_path}")

    print("\nSetup completed successfully!")
    return True


if __name__ == "__main__":
    setup_environment()

setup(
    name="sentiment_analysis",
    version="0.1.0",
    packages=find_packages(),
    install_requires=[
        "numpy",
        "pandas",
        "scikit-learn",
        "nltk",
        "underthesea",  # For Vietnamese text processing
        "matplotlib",
        "seaborn",
        "joblib",
        "pytest",
        "anyio",
    ],
    author="CatalizCS",
    description="Sentiment Analysis for Vietnamese and English Social Media Data",
    python_requires=">=3.7",
)

================
File: src/api/__init__.py
================
# Empty file to make the directory a Python package

================
File: src/api/app.py
================
import os
import subprocess
import sys
from functools import lru_cache
from fastapi import FastAPI, HTTPException, Request, WebSocket, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from fastapi.middleware.gzip import GZipMiddleware
from starlette.middleware.base import BaseHTTPMiddleware
from starlette.requests import Request
import asyncio
from datetime import datetime, timedelta
import time


from src.utils.server_utils import force_kill_port, is_port_in_use, ConnectionManager

# Add correct project root to path
project_root = os.path.dirname(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# Update imports to be relative to src
from fastapi import FastAPI, HTTPException, Request, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from pydantic import BaseModel
from typing import List, Dict, Optional, Any
import uvicorn
import pandas as pd
from datetime import datetime
import psutil
import json
import time
from collections import deque
import asyncio
import signal
import socket
from starlette.websockets import WebSocketState, WebSocketDisconnect
from contextlib import asynccontextmanager
import pathlib

from src.config import Config
from src.features.feature_engineering import FeatureExtractor
from src.models.model_predictor import SentimentPredictor
from src.data.preprocessor import DataPreprocessor
from src.utils.logger import Logger
from src.utils.metrics_store import MetricsStore
from sklearn.metrics import accuracy_score, precision_score, recall_score


# Add performance optimizations
class RateLimitMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, calls: int, period: int):
        super().__init__(app)
        self.calls = calls
        self.period = period
        self.requests = {}

    async def dispatch(self, request: Request, call_next):
        client_ip = request.client.host
        now = time.time()

        # Clean old requests
        self.requests = {
            ip: reqs
            for ip, reqs in self.requests.items()
            if reqs[-1] > now - self.period
        }

        if client_ip in self.requests:
            if len(self.requests[client_ip]) >= self.calls:
                raise HTTPException(status_code=429, detail="Rate limit exceeded")
            self.requests[client_ip].append(now)
        else:
            self.requests[client_ip] = [now]

        return await call_next(request)


# Add model caching
@lru_cache(maxsize=2)
def get_cached_model(language: str):
    """Cache model loading to improve performance"""
    return load_model(language)


# Add dependency for language validation
def validate_language(language: str = "vi"):
    if language not in ["vi", "en"]:
        raise HTTPException(status_code=400, detail="Invalid language")
    return language


# Optimize app initialization
app = FastAPI(
    title="Sentiment Analysis API",
    description="API for Vietnamese-English sentiment analysis",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
)

# Initialize config and logger
config = Config()
logger = Logger(__name__).logger

# Add performance middleware
app.add_middleware(GZipMiddleware, minimum_size=1000)
app.add_middleware(TrustedHostMiddleware, allowed_hosts=["*"])
app.add_middleware(
    RateLimitMiddleware,
    calls=config.API_CONFIG["RATE_LIMIT"]["requests"],
    period=config.API_CONFIG["RATE_LIMIT"]["window"],
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Update this in production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
)

# Initialize models dict
models = {"vi": None, "en": None}


# Pydantic models for request/response
class TextRequest(BaseModel):
    text: str
    language: str = "vi"


class BatchRequest(BaseModel):
    texts: List[str]
    language: str = "vi"


class SentimentResponse(BaseModel):
    text: str
    sentiment: int
    sentiment_label: str
    confidence: float
    emotion: Optional[Dict] = None
    processing_time: float


class ModelInfo(BaseModel):
    loaded: bool
    info: Dict[str, Any]


class HealthCheck(BaseModel):
    status: str
    timestamp: str
    models: Dict[str, ModelInfo]


def load_model(language: str):
    """Load model for specified language and track loading time"""
    try:
        start_time = time.time()
        if models[language] is None:
            feature_extractor = FeatureExtractor(language, config)
            predictor = SentimentPredictor(language, config)
            preprocessor = DataPreprocessor(language, config)
            models[language] = {
                "predictor": predictor,
                "extractor": feature_extractor,
                "preprocessor": preprocessor,
            }
        loading_time = time.time() - start_time
        metrics_store.update_model_loading_time(language, loading_time)
        return models[language]
    except Exception as e:
        logger.error(f"Error loading model for {language}: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"Failed to load model for {language}"
        )


def get_sentiment_label(sentiment: int) -> str:
    """Convert sentiment code to label"""
    return {
        0: "Negative / Tiêu cực",
        1: "Neutral / Trung tính",
        2: "Positive / Tích cực",
    }.get(sentiment, "Unknown")


@app.get("/")
async def root():
    """Root endpoint with API info"""
    return {
        "name": "Sentiment Analysis API",
        "version": "1.0.0",
        "languages": ["vi", "en"],
        "endpoints": [
            "/predict - Single text prediction",
            "/batch - Batch text prediction",
            "/health - API health check",
        ],
    }


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request, exc):
    return JSONResponse(
        status_code=400,
        content={
            "status": "error",
            "message": str(exc),
            "timestamp": datetime.now().isoformat(),
        },
    )


@app.middleware("http")
async def add_process_time_header(request: Request, call_next):
    start_time = datetime.now()
    try:
        response = await call_next(request)
        process_time = (datetime.now() - start_time).total_seconds()
        response.headers["X-Process-Time"] = str(process_time)
        return response
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": str(e),
                "timestamp": datetime.now().isoformat(),
            },
        )


# Optimize prediction endpoint
def evaluate_model(language: str, true_labels: List[int], predictions: List[int]):
    """Evaluate model performance and update metrics"""
    accuracy = accuracy_score(true_labels, predictions)
    precision = precision_score(true_labels, predictions, average="weighted")
    recall = recall_score(true_labels, predictions, average="weighted")
    metrics_store.update_ml_metrics(language, accuracy, precision, recall)


class PredictionRequest(BaseModel):
    text: str
    language: str


@app.post("/predict")
async def predict(request: Request):
    try:
        # Get input data
        data = await request.json()
        if not data or "text" not in data:
            return JSONResponse(status_code=400, content={"error": "No text provided"})

        text = data["text"]
        language = data.get("language", "vi")

        # Initialize components
        config = Config()
        predictor = SentimentPredictor(language, config)
        preprocessor = DataPreprocessor(language, config)
        feature_extractor = FeatureExtractor(language, config)

        # Preprocess
        df = pd.DataFrame({"text": [text]})
        processed = preprocessor.preprocess(df)

        # Extract features
        features = feature_extractor.extract_features(processed["cleaned_text"])

        # Get prediction with emotion
        result = predictor.predict_emotion(features, text)

        return JSONResponse(
            status_code=200,
            content={
                "text": text,
                "sentiment": int(result["sentiment"]),
                "sentiment_confidence": float(result["sentiment_confidence"]),
                "emotion": result["emotion"],
                "emotion_vi": result["emotion_vi"],
                "emotion_emoji": result["emotion_emoji"],
            },
        )

    except Exception as e:
        # Log the error for debugging
        print(f"Error in predict: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.post("/batch")
async def batch_predict(request: BatchRequest):
    """Predict sentiment for multiple texts"""
    start_time = datetime.now()

    try:
        # Validate language
        if request.language not in ["vi", "en"]:
            raise HTTPException(status_code=400, detail="Language must be 'vi' or 'en'")

        # Load model components
        model = load_model(request.language)

        # Process texts
        df = pd.DataFrame({"text": request.texts})
        processed_df = model["preprocessor"].preprocess(df)

        if processed_df.empty:
            raise HTTPException(status_code=400, detail="Text preprocessing failed")

        # Extract features
        features = model["extractor"].extract_features(processed_df["cleaned_text"])

        # Get predictions
        results = []
        for i, text in enumerate(request.texts):
            emotion_result = model["predictor"].predict_emotion(
                features[i : i + 1], text
            )

            results.append(
                {
                    "text": text,
                    "sentiment": emotion_result["sentiment"],
                    "sentiment_label": get_sentiment_label(emotion_result["sentiment"]),
                    "confidence": float(emotion_result["sentiment_confidence"]),
                    "emotion": {
                        "label": emotion_result["emotion_vi"],
                        "emoji": emotion_result["emotion_emoji"],
                        "confidence": float(emotion_result["emotion_confidence"]),
                        "scores": emotion_result.get("emotion_scores"),
                    },
                }
            )

        processing_time = (datetime.now() - start_time).total_seconds()

        return {
            "results": results,
            "count": len(results),
            "processing_time": processing_time,
        }

    except Exception as e:
        logger.error(f"Batch prediction error: {str(e)}")
        raise HTTPException(
            status_code=500, detail=f"Batch prediction failed: {str(e)}"
        )


# Add metrics optimization
async def update_metrics(processing_time: float):
    """Update metrics asynchronously"""
    try:
        metrics_store.increment_total_requests()  # Updated method call
        metrics_store.add_request(datetime.now())  # Updated method call
        metrics_store.add_response_time(processing_time)  # Updated method call

        # Cleanup old metrics
        now = datetime.now()
        cutoff = now - timedelta(days=config.METRICS_CONFIG["retention_days"])

        metrics_store.cleanup_old_metrics(cutoff)  # Updated method call

    except Exception as e:
        logger.error(f"Metrics update error: {str(e)}")


@app.get("/health", response_model=HealthCheck)
async def health_check():
    """Optimized health check"""
    try:
        return {
            "status": "healthy",
            "timestamp": datetime.now().isoformat(),
            "models": {
                lang: ModelInfo(
                    loaded=bool(models[lang]), info=config.MODEL_INFO.get(lang, {})
                )
                for lang in ["vi", "en"]
            },
            "metrics": {
                "requests": len(metrics_store["requests"]),
                "avg_response_time": (
                    sum(metrics_store["response_times"])
                    / len(metrics_store["response_times"])
                    if metrics_store["response_times"]
                    else 0
                ),
                "memory_usage": psutil.Process().memory_percent(),
            },
        }
    except Exception as e:
        logger.error(f"Health check error: {str(e)}")
        return {"status": "unhealthy", "error": str(e)}


@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on server shutdown"""
    try:
        # Clear model cache
        models["vi"] = None
        models["en"] = None
        # Additional cleanup if needed
    except Exception as e:
        logger.error(f"Error during shutdown: {e}")


@app.post("/shutdown")
async def shutdown():
    """Graceful shutdown endpoint"""
    try:
        # Get the process ID
        pid = os.getpid()

        # Schedule shutdown after response is sent
        async def shutdown_server():
            await asyncio.sleep(1)
            # Kill the current process
            if sys.platform == "win32":
                subprocess.run(["taskkill", "/F", "/PID", str(pid)])
            else:
                os.kill(pid, signal.SIGTERM)

        asyncio.create_task(shutdown_server())

        return {"message": "Server shutting down..."}
    except Exception as e:
        logger.error(f"Error during shutdown: {e}")
        raise HTTPException(status_code=500, detail="Shutdown failed")


# Server control functions
server_process = None


def start_new_terminal():
    """Start API server in a new terminal window"""
    try:
        # Get the project root directory and normalize path
        project_root = os.path.abspath(
            os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
        )
        api_script = os.path.join(project_root, "src", "api", "app.py")

        # Set environment variables
        env = os.environ.copy()
        env["PYTHONPATH"] = project_root
        env["PYTHONUNBUFFERED"] = "1"

        # Command to run API server
        api_command = [
            sys.executable,
            "-m",
            "uvicorn",
            "src.api.app:app",
            "--host=0.0.0.0",
            "--port=7270",
            "--reload",
            "--reload-dir=src",
        ]

        # Platform-specific commands
        if sys.platform == "win32":
            # Windows: use 'start' command
            full_command = [
                "cmd",
                "/c",
                "start",
                "cmd",
                "/k",
                "set PYTHONPATH=" + project_root + "&&" + " ".join(api_command),
            ]
            subprocess.Popen(full_command, shell=True, env=env, cwd=project_root)

        elif sys.platform == "darwin":
            # macOS: use AppleScript to open Terminal
            apple_script = [
                "osascript",
                "-e",
                f'tell app "Terminal" to do script "cd {project_root} && {" ".join(api_command)}"',
            ]
            subprocess.Popen(apple_script)

        else:
            # Linux: try common terminal emulators
            terminals = [
                ["gnome-terminal", "--"],
                ["xterm", "-e"],
                ["konsole", "-e"],
                ["xfce4-terminal", "--execute"],
            ]

            success = False
            for term_cmd in terminals:
                try:
                    subprocess.Popen(term_cmd + api_command, env=env, cwd=project_root)
                    success = True
                    break
                except FileNotFoundError:
                    continue

            if not success:
                raise RuntimeError("No suitable terminal emulator found")

        logger.info("API server started in new terminal window")
        return True

    except Exception as e:
        logger.error(f"Failed to start API server in new terminal: {e}")
        return False


def start_api_server(host="0.0.0.0", port=7270):
    """Enhanced API server starter"""
    global server_process
    try:
        # Kill any existing process using the port
        if is_port_in_use(port):
            force_kill_port(port)
            time.sleep(1)  # Wait for port to be freed

        # Set environment variables for better stability
        env = os.environ.copy()
        env["PYTHONUNBUFFERED"] = "1"
        env["PYTHONPATH"] = project_root

        # Start server with improved settings
        command = [
            sys.executable,
            "-m",
            "uvicorn",
            "src.api.app:app",
            f"--host={host}",
            f"--port={port}",
            "--reload",
            "--reload-dir",
            "src",
            "--workers",
            "1",  # Single worker for stability
            "--timeout-keep-alive",
            "30",
            "--limit-concurrency",
            "100",
            "--log-level",
            "info",
        ]

        server_process = subprocess.Popen(
            command, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )

        # Verify server started successfully
        time.sleep(2)
        if server_process.poll() is not None:
            stderr = server_process.stderr.read()
            raise RuntimeError(f"Server failed to start: {stderr}")

        logger.info(f"API server started on {host}:{port}")
        return True

    except Exception as e:
        logger.error(f"Failed to start API server: {str(e)}")
        return False


def stop_api_server():
    """Stop the API server subprocess"""
    global server_process
    try:
        if server_process and server_process.poll() is None:
            server_process.terminate()
            server_process.wait(timeout=5)
            logger.info(
                f"API server with PID {server_process.pid} terminated successfully."
            )
        else:
            logger.info("API server process is not running.")
        server_process = None

        # Clear model cache
        models["vi"] = None
        models["en"] = None

        time.sleep(1)  # Ensure the port is freed
        return True
    except Exception as e:
        logger.error(f"Error stopping API server: {e}")
        return False


def is_port_in_use(port: int) -> bool:
    """Check if port is in use"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind(("", port))
            return False
        except OSError:
            return True


def get_api_status():
    """Get API server status"""
    try:
        # Check if any Python processes are using our ports
        target_ports = [7270, 8000]
        connections = psutil.net_connections()
        server_running = False

        for conn in connections:
            try:
                if hasattr(conn, "laddr") and (conn.laddr.port in target_ports):
                    # Get process info
                    proc = psutil.Process(conn.pid)
                    if "python" in proc.name().lower():
                        server_running = True
                        break
            except (psutil.NoSuchProcess, psutil.AccessDenied, AttributeError):
                continue

        return {
            "running": server_running,
            "models_loaded": {
                "vi": models["vi"] is not None,
                "en": models["en"] is not None,
            },
            "port": config.API_CONFIG["PORT"],
            "uptime": (
                str(datetime.now() - metrics_store["start_time"])
                if (server_running)
                else "0:00:00"
            ),
            "total_requests": metrics_store["total_requests"],
            "total_errors": metrics_store["total_errors"],
        }
    except Exception as e:
        logger.error(f"Failed to get API status: {str(e)}")
        return {
            "running": False,
            "models_loaded": {"vi": False, "en": False},
            "error": str(e),
        }


# Initialize metrics storage
metrics_store = MetricsStore()

# Mount static files and templates
app.mount("/static", StaticFiles(directory="src/api/static"), name="static")
templates = Jinja2Templates(directory="src/api/templates")


@app.get("/dashboard")
async def dashboard(request: Request):
    """Render dashboard page"""
    return templates.TemplateResponse(
        "dashboard.html",
        {
            "request": request,
            "config": {
                "update_interval": config.DASHBOARD_CONFIG["update_interval"],
                "metrics_history": config.DASHBOARD_CONFIG["metrics_history"],
                "alert_thresholds": config.METRICS_CONFIG["alert_thresholds"],
            },
            "start_time": metrics_store["start_time"],
            "total_requests": metrics_store["total_requests"],
            "total_errors": metrics_store["total_errors"],
        },
    )


# Initialize connection manager
manager = ConnectionManager()


@app.websocket("/ws/metrics")
async def metrics_websocket(websocket: WebSocket):
    await manager.connect(websocket)

    try:
        while True:
            # Receive messages and send metrics concurrently
            receive_task = asyncio.create_task(websocket.receive_text())
            send_task = asyncio.create_task(send_metrics(websocket))

            done, pending = await asyncio.wait(
                [receive_task, send_task], return_when=asyncio.FIRST_COMPLETED
            )

            if receive_task in done:
                message = receive_task.result()
                data = json.loads(message)

                if data.get("type") == "heartbeat":
                    await websocket.send_text(json.dumps({"type": "heartbeat_ack"}))
                    # Cancel send_task to prevent duplication
                    send_task.cancel()
                    continue  # Continue to the next iteration

            if send_task in done:
                # Metrics have been sent
                pass

            # Cancel pending tasks
            for task in pending:
                task.cancel()

    except WebSocketDisconnect:
        logger.info("WebSocket client disconnected.")
        await manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        await manager.disconnect(websocket)


async def send_metrics(websocket: WebSocket):
    while True:
        try:
            # Send metrics to the client
            metrics = {
                "type": "metrics",
                "cpu_usage": psutil.cpu_percent(interval=0.5),
                "memory_usage": {
                    "percent": psutil.virtual_memory().percent,
                    "used": psutil.virtual_memory().used,
                    "total": psutil.virtual_memory().total,
                },
                "requests_per_sec": metrics_store.get_requests_per_sec(
                    config.DASHBOARD_CONFIG["update_interval"]
                ),
                "avg_response_time": (
                    metrics_store.get_avg_response_time()
                    if metrics_store.response_times
                    else 0
                ),
                "model_status": {
                    lang: {
                        "loaded": models[lang] is not None,
                        "info": config.MODEL_INFO.get(lang, {}),
                        "performance": metrics_store.get_model_performance().get(
                            lang, {}
                        ),
                    }
                    for lang in ["vi", "en"]
                },
                "total_requests": metrics_store.total_requests,
                "total_errors": metrics_store.total_errors,
            }
            await websocket.send_text(json.dumps(metrics))
            await asyncio.sleep(1)
        except WebSocketDisconnect:
            logger.info("WebSocket client disconnected.")
            break
        except Exception as e:
            logger.error(f"Error sending metrics: {e}")
            break


@app.get("/api/metrics/summary")
async def get_metrics_summary():
    """Get summary of API metrics"""
    return metrics_store.get_metrics()


# Update middleware to collect metrics
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time

    # Update metrics with process time and error status
    metrics_store.update_metrics(process_time, is_error=(response.status_code >= 400))

    return response


@app.get("/api/logs")
async def get_server_logs(
    lines: int = 100,
    level: str = "all",
    since: str = None,
    type: str = "all",
    path: str = None,
    status_code: int = None,
):
    """Enhanced log retrieval with more filtering options"""
    try:
        log_file = pathlib.Path(config.LOG_FILE)
        if not log_file.exists():
            return {"logs": [], "message": "No log file found"}

        # Read log file
        with open(log_file, "r", encoding="utf-8") as f:
            logs = f.readlines()

        filtered_logs = []
        for log in logs:
            try:
                # Apply filters
                if type != "all":
                    if (type == "init") and ("API Server" not in log):
                        continue
                    if (type == "request") and ("Request:" not in log):
                        continue

                if path and (path not in log):
                    continue

                if status_code and (f"Status: {status_code}" not in log):
                    continue

                if (level != "all") and (f"[{level.upper()}]" not in log):
                    continue

                if since:
                    try:
                        log_time = datetime.fromisoformat(log.split()[0])
                        since_time = datetime.fromisoformat(since)
                        if log_time < since_time:
                            continue
                    except:
                        pass

                filtered_logs.append(log)
            except:
                continue

        # Get last N lines
        filtered_logs = filtered_logs[-lines:]

        return {
            "logs": filtered_logs,
            "total": len(filtered_logs),
            "filters": {
                "type": type,
                "level": level,
                "path": path,
                "status_code": status_code,
                "since": since,
                "lines": lines,
            },
        }
    except Exception as e:
        logger.error(f"Error reading logs: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to read logs: {str(e)}")


# Add timeout handler
async def timeout_handler():
    """Handle request timeout"""
    await asyncio.sleep(config.API_CONFIG["TIMEOUT"])
    raise HTTPException(status_code=408, detail="Request timeout")


# Add request timeout middleware
@app.middleware("http")
async def timeout_middleware(request: Request, call_next):
    try:
        # Create timeout task
        timeout_task = asyncio.create_task(timeout_handler())
        # Create response task
        response_task = asyncio.create_task(call_next(request))

        done, pending = await asyncio.wait(
            [timeout_task, response_task], return_when=asyncio.FIRST_COMPLETED
        )

        # Cancel pending tasks
        for task in pending:
            task.cancel()

        if response_task in done:
            return await response_task
        else:
            raise HTTPException(status_code=408, detail="Request timeout")

    except Exception as e:
        logger.error(f"Request error: {str(e)}")
        # Cleanup resources
        models["vi"] = None
        models["en"] = None
        return JSONResponse(
            status_code=500, content={"detail": "Internal server error"}
        )


# Add periodic health check
async def periodic_health_check():
    """Run periodic health check"""
    while True:
        try:
            await asyncio.sleep(30)  # Check every 30 seconds
            status = await health_check()
            if status["status"] != "healthy":
                logger.warning("Unhealthy state detected, reloading models...")
                # Reload models
                models["vi"] = None
                models["en"] = None
        except Exception as e:
            logger.error(f"Health check error: {e}")


# Update startup event
@app.on_event("startup")
async def startup_event():
    """Enhanced startup logging and model preloading"""
    try:
        logger.info("=== API Server Starting ===")
        logger.info(f"Environment: {os.getenv('ENV', 'development')}")
        logger.info(f"Debug Mode: {app.debug}")
        logger.info(f"API Config: {json.dumps(config.API_CONFIG, indent=2)}")

        # Preload models on startup
        logger.info("Preloading models...")
        for language in ["vi", "en"]:
            try:
                logger.info(f"Loading {language.upper()} model...")
                _ = get_cached_model(language)
                logger.info(f"{language.upper()} model loaded successfully")
            except Exception as e:
                logger.error(f"Failed to load {language.upper()} model: {str(e)}")

        # Log available endpoints
        routes = []
        for route in app.routes:
            if hasattr(route, "methods"):
                routes.append(f"{route.methods} {route.path}")
        logger.info(f"Registered Routes:\n" + "\n".join(routes))

        # Start background tasks
        asyncio.create_task(periodic_health_check())
        logger.info("Health check task started")

        # Initialize metrics
        metrics_store.clear_all()
        logger.info("Metrics store initialized")

        logger.info("=== API Server Started Successfully ===")
    except Exception as e:
        logger.error(f"Startup failed: {str(e)}")
        raise


# Update shutdown event to be more thorough
@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    try:
        # Clear model cache
        models["vi"] = None
        models["en"] = None

        # Close all active connections
        for ws in manager.active_connections:
            await ws.close()
        manager.active_connections.clear()

        # Additional cleanup
        metrics_store["requests"].clear()
        metrics_store["response_times"].clear()
        metrics_store["errors"].clear()

    except Exception as e:
        logger.error(f"Error during shutdown: {e}")


# Add request logging middleware
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    method = request.method
    path = request.url.path
    query_params = str(request.query_params)

    # Log request
    logger.info(f"Request: {method} {path} {query_params}")

    try:
        # Get request body for POST/PUT requests
        if method in ["POST", "PUT"]:
            body = await request.json()
            logger.info(f"Request Body: {json.dumps(body, ensure_ascii=False)}")
    except:
        pass

    try:
        response = await call_next(request)

        process_time = time.time() - start_time
        status_code = response.status_code

        # Log response
        logger.info(
            f"Response: {method} {path} - Status: {status_code} - Time: {process_time:.3f}s"
        )

        return response
    except Exception as e:
        logger.error(f"Request failed: {method} {path} - Error: {str(e)}")
        raise


if __name__ == "__main__":
    # Run with uvicorn directly when script is executed
    import uvicorn

    port = 7270
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=port,
        reload=True,
        reload_dirs=["src"],
        log_level="info",
        # Remove invalid timeout parameter
        workers=1,
        limit_concurrency=100,
        # Add valid websocket configurations
        websocket_ping_interval=20,
        websocket_ping_timeout=30,
        limit_max_requests=None,
    )

# Export necessary functions
__all__ = [
    "app",
    "start_api_server",
    "stop_api_server",
    "is_port_in_use",
    "get_api_status",
    "get_cached_model",
    "validate_language",
    "update_metrics",
]

================
File: src/config.py
================
import os


class Config:
    # Paths
    ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    DATA_DIR = os.path.join(ROOT_DIR, "data")

    # Model parameters - Giảm độ phức tạp
    MAX_FEATURES = 10000  # tránh noise
    MIN_SAMPLES = 5  # đảm bảo tính ổn định
    MAX_LEN = 300  # giảm noise
    SVD_COMPONENTS = 100  # Add this line to define the number of SVD components
    # Language specific configs
    LANGUAGE_CONFIGS = {
        "vi": {
            "stop_words": ["và", "của", "các", "có", "được", "trong", "đã", "này"],
            "model_path": os.path.join(DATA_DIR, "models", "vi_sentiment_model.pkl"),
        },
        "en": {
            "stop_words": "english",  # Using NLTK's English stop words
            "model_path": os.path.join(DATA_DIR, "models", "en_sentiment_model.pkl"),
        },
    }

    # Expanded emotion labels
    EMOTION_LABELS = {
        "POSITIVE": {
            2: "positive",
            3: "excited",
            4: "happy",
            5: "satisfied",
            6: "impressed",
        },
        "NEGATIVE": {
            0: "negative",
            7: "angry",
            8: "disappointed",
            9: "frustrated",
            10: "worried",
        },
        "NEUTRAL": {1: "neutral", 11: "confused", 12: "uncertain", 13: "mixed"},
    }

    # Emotion mapping for conversion
    EMOTION_TO_SENTIMENT = {
        # Positive emotions -> 2
        "excited": 2,
        "happy": 2,
        "satisfied": 2,
        "impressed": 2,
        "positive": 2,
        # Negative emotions -> 0
        "angry": 0,
        "disappointed": 0,
        "frustrated": 0,
        "worried": 0,
        "negative": 0,
        # Neutral emotions -> 1
        "confused": 1,
        "uncertain": 1,
        "mixed": 1,
        "neutral": 1,
    }

    # Model saving configurations
    MODEL_SAVE_CONFIG = {
        "max_checkpoints": 5,
        "checkpoint_frequency": 1,  # Save checkpoint every N epochs
        "model_format": "pkl",
        "compression": True,
    }

    # Expanded emotion mapping
    EMOTION_MAPPING = {
        # Positive emotions (2)
        "happy": {"id": 2.1, "sentiment": 2, "vi": "vui vẻ", "emoji": "😊"},
        "excited": {"id": 2.2, "sentiment": 2, "vi": "phấn khích", "emoji": "🤗"},
        "satisfied": {"id": 2.3, "sentiment": 2, "vi": "hài lòng", "emoji": "😌"},
        "proud": {"id": 2.4, "sentiment": 2, "vi": "tự hào", "emoji": "😊"},
        # Neutral emotions (1)
        "neutral": {"id": 1.0, "sentiment": 1, "vi": "bình thường", "emoji": "😐"},
        "surprised": {"id": 1.1, "sentiment": 1, "vi": "ngạc nhiên", "emoji": "😮"},
        "confused": {"id": 1.2, "sentiment": 1, "vi": "bối rối", "emoji": "😕"},
        # Negative emotions (0)
        "sad": {"id": 0.1, "sentiment": 0, "vi": "buồn", "emoji": "😢"},
        "angry": {"id": 0.2, "sentiment": 0, "vi": "giận dữ", "emoji": "😠"},
        "disappointed": {"id": 0.3, "sentiment": 0, "vi": "thất vọng", "emoji": "😞"},
        "frustrated": {"id": 0.4, "sentiment": 0, "vi": "bực bội", "emoji": "😤"},
        "worried": {"id": 0.5, "sentiment": 0, "vi": "lo lắng", "emoji": "😟"},
    }

    # Emotion keywords for each category
    EMOTION_KEYWORDS = {
        "vi": {
            "happy": ["vui", "hạnh phúc", "thích", "tuyệt vời", "tốt", "thú vị"],
            "excited": ["phấn khích", "hào hứng", "tuyệt quá", "wow"],
            "satisfied": ["hài lòng", "thoải mái", "ổn", "được"],
            "proud": ["tự hào", "xuất sắc", "giỏi"],
            "neutral": ["bình thường", "tạm", "okay"],
            "surprised": ["ngạc nhiên", "bất ngờ", "không ngờ"],
            "confused": ["bối rối", "không hiểu", "lạ"],
            "sad": ["buồn", "khổ", "chán", "thương"],
            "angry": ["giận", "tức", "khó chịu", "ghét"],
            "disappointed": ["thất vọng", "không được", "kém"],
            "frustrated": ["bực", "khó chịu", "phiền"],
            "worried": ["lo", "sợ", "không an tâm"],
        },
        "en": {
            "happy": ["happy", "joyful", "pleased", "delighted", "good", "great"],
            "excited": ["excited", "thrilled", "eager", "enthusiastic", "wow"],
            "satisfied": ["satisfied", "content", "pleased", "okay", "fine"],
            "proud": ["proud", "accomplished", "successful", "confident"],
            "neutral": ["neutral", "indifferent", "unaffected", "okay"],
            "surprised": ["surprised", "shocked", "amazed", "astonished"],
            "confused": ["confused", "puzzled", "perplexed", "baffled"],
            "sad": ["sad", "unhappy", "down", "depressed", "miserable"],
            "angry": ["angry", "mad", "furious", "irritated", "annoyed"],
            "disappointed": ["disappointed", "dissatisfied", "unhappy", "let down"],
            "frustrated": ["frustrated", "annoyed", "irritated", "exasperated"],
            "worried": ["worried", "concerned", "anxious", "nervous", "apprehensive"],
        },
    }

    # API Configuration
    API_CONFIG = {
        "HOST": "0.0.0.0",
        "PORT": 7270,
        "WORKERS": 4,
        "TIMEOUT": 60,
        "RELOAD": True,
        "CORS_ORIGINS": ["*"],
        "MAX_REQUEST_SIZE": 1024 * 1024,  # 1MB
        "RATE_LIMIT": {"requests": 10000, "window": 60},  # seconds
    }

    # Dashboard Configuration
    DASHBOARD_CONFIG = {
        "update_interval": 5,  # seconds
        "metrics_history": 100,  # number of historical data points to keep
        "charts": {
            "request_rate": {"window": 60},  # 1 minute window
            "response_time": {"window": 300},  # 5 minute window
            "error_rate": {"window": 300},
        },
    }

    # Metrics Configuration
    METRICS_CONFIG = {
        "collect_detailed_metrics": True,
        "metrics_retention_days": 7,
        "metrics_file": "api_metrics.json",
        "alert_thresholds": {
            "error_rate": 0.1,  # 10% error rate
            "response_time": 1.0,  # 1 second
            "memory_usage": 0.8,  # 80% memory usage
        },
    }

    # Metrics configuration
    METRICS_CONFIG = {
        "retention_days": 7,
        "alert_thresholds": {"accuracy": 0.8, "precision": 0.8, "recall": 0.8},
    }

    # Enhanced model training configuration
    # MODEL_TRAINING_CONFIG = {
    #     "cv_folds": 10,  # Increased from 5
    #     "class_weight_method": "balanced",
    #     "feature_selection_method": "mutual_info_classif",
    #     "sampling_strategy": "smote",
    #     "preprocessing": {
    #         "min_df": 10,  # Increased from 5
    #         "max_df": 0.85,  # Reduced from 0.9
    #         "ngram_range": (1, 2),  # Reduced from (1,3) to prevent overfitting
    #         "analyzer": ["word", "char_wb"],
    #         "strip_accents": "unicode",
    #         "binary": True,
    #         "sublinear_tf": True,
    #     },
    # }
    MODEL_TRAINING_CONFIG = {
        "cv_folds": 10,
        "class_weight_method": "balanced",
        "preprocessing": {
            "min_df": 15,  # Increased to reduce noise
            "max_df": 0.8,  # Reduced to remove very common words
            "ngram_range": (1, 3),
            "max_features": 15000  # Increased vocabulary size
        },
        "ensemble": {
            "voting": "soft",
            "weights": [0.4, 0.3, 0.3]  # RF, SVM, NB weights
        }
    }

    # Optimized parameter grid with better regularization
    PARAM_GRID = {
        # Random Forest - Improved parameters
        "rf__n_estimators": [500, 800, 1000],  # Increased values
        "rf__max_depth": [30, 50, 70],  # Adjusted range
        "rf__min_samples_split": [10, 15],  # Increased to reduce overfitting
        "rf__min_samples_leaf": [4, 8],  # Increased for better generalization
        "rf__max_features": ["sqrt", "log2"],  # Added log2 option
        "rf__bootstrap": [True],
        "rf__criterion": ["gini", "entropy"],  # Added entropy
        "rf__oob_score": [True],

        # SVM - Enhanced regularization
        "svm__C": [0.01, 0.1, 0.5],  # Adjusted for stronger regularization
        "svm__tol": [1e-4, 1e-3],
        "svm__max_iter": [2000],  # Increased iterations
        "svm__class_weight": ["balanced"],
        "svm__dual": [False],

        # Naive Bayes - Adjusted smoothing
        "nb__alpha": [0.8, 1.2, 1.5],  # Adjusted range
        "nb__fit_prior": [True, False],  # Test both options

        # Feature Selection - Optimized
        "feature_selection__k": [800, 1200],  # Adjusted feature count
        "feature_selection__score_func": ["mutual_info_classif"],
    }

    VALIDATION_CONFIG = {
        "early_stopping": {
            "patience": 5,  # Increased from 3
            "min_delta": 0.0005,  # Reduced from 0.001 for finer control
            "monitor": "val_score"
        },
        "validation_split": 0.15,  # Reduced from 0.2
        "shuffle": True,
        "random_state": 42,
    }

    # Enhanced regularization configuration
    # REGULARIZATION_CONFIG = {
    #     "rf_reg": {
    #         "ccp_alpha": 0.005,  # Reduced from 0.01 for finer pruning
    #         "max_samples": 0.7,  # Reduced from 0.8
    #     },
    #     "svm_reg": {
    #         "kernel": "linear",
    #         "shrinking": True
    #     },
    # }
    REGULARIZATION_CONFIG = {
        "rf_reg": {
            "ccp_alpha": 0.002,  # Pruning strength 
            "max_samples": 0.8,
            "max_features": "sqrt",
            "min_samples_leaf": 4
        },
        "svm_reg": {
            "C": 0.8,  # Stronger regularization
            "class_weight": "balanced",
            "dual": False
        },
        "nb_reg": {
            "alpha": 1.2,
            "fit_prior": True
        }
    }

    # Add scoring configuration
    SCORING_CONFIG = {
        "precision_zero_division": 1,  # Handle zero division in precision
        "score_weights": {"precision": 0.4, "recall": 0.4, "f1": 0.2},
    }

    # Error messages
    ERROR_MESSAGES = {
        "MODEL_NOT_FOUND": "Model not found for language {}",
        "PREPROCESSING_FAILED": "Text preprocessing failed",
        "FEATURE_EXTRACTION_FAILED": "Feature extraction failed",
        "PREDICTION_FAILED": "Prediction failed",
        "INVALID_LANGUAGE": 'Invalid language. Must be "vi" or "en"',
        "EMPTY_TEXT": "Empty text provided",
        "SERVER_ERROR": "Internal server error",
    }

    # Model information
    MODEL_INFO = {
        "vi": {
            "name": "Vietnamese Sentiment Model",
            "version": "1.0.0",
            "description": "A model for analyzing Vietnamese sentiment.",
        },
        "en": {
            "name": "English Sentiment Model",
            "version": "1.0.0",
            "description": "A model for analyzing English sentiment.",
        },
    }

================
File: src/docs/algorithm_overview.py
================
class TongQuanThuatToan:
    """
    Tổng quan về các thuật toán sử dụng trong hệ thống phân tích cảm xúc.
    """

    @staticmethod
    def feature_extraction_algorithms():
        """
        Các thuật toán trích xuất đặc trưng (Feature Extraction)
        """
        return {
            "TF-IDF": {
                "name": "Term Frequency-Inverse Document Frequency",
                "purpose": "Chuyển đổi văn bản thành vector số dựa trên tần suất từ",
                "implementation": "sklearn.feature_extraction.text.TfidfVectorizer",
                "parameters": {
                    "max_features": "2000 - Giới hạn số lượng đặc trưng",
                    "ngram_range": "(1,3) - Sử dụng unigrams, bigrams và trigrams",
                    "min_df": "2 - Loại bỏ các từ hiếm",
                    "max_df": "0.95 - Loại bỏ các từ phổ biến"
                }
            },
            "SVD": {
                "name": "Singular Value Decomposition",
                "purpose": "Giảm chiều dữ liệu và trích xuất các đặc trưng quan trọng",
                "implementation": "sklearn.decomposition.TruncatedSVD",
                "parameters": {
                    "n_components": "95 hoặc min(features-1, samples-1)",
                    "algorithm": "randomized"
                }
            },
            "Character N-grams": {
                "name": "Character Level Features",
                "purpose": "Phân tích mẫu ký tự, hữu ích cho lỗi chính tả và biến thể từ",
                "implementation": "Custom TfidfVectorizer với analyzer='char'",
                "parameters": {
                    "ngram_range": "(2,4)",
                    "max_features": "500"
                }
            }
        }

    @staticmethod
    def classification_algorithms():
        """
        Các thuật toán phân loại (Classification)
        """
        return {
            "RandomForest": {
                "name": "Random Forest Classifier",
                "purpose": "Phân loại tổng hợp dựa trên nhiều cây quyết định",
                "strengths": [
                    "Hiệu quả với dữ liệu có nhiều chiều",
                    "Chống overfitting tốt",
                    "Có thể xử lý dữ liệu không cân bằng"
                ],
                "parameters": {
                    "n_estimators": "200-300 cây",
                    "max_depth": "20-30 độ sâu tối đa",
                    "class_weight": "balanced"
                }
            },
            "LinearSVC": {
                "name": "Linear Support Vector Classification",
                "purpose": "Phân loại tuyến tính dựa trên Support Vector Machines",
                "strengths": [
                    "Hiệu quả với văn bản có chiều cao",
                    "Tốt cho dữ liệu phân tách tuyến tính",
                    "Nhanh và hiệu quả bộ nhớ"
                ],
                "parameters": {
                    "C": [0.1, 1.0, 10.0],
                    "max_iter": 2000,
                    "class_weight": "balanced"
                }
            },
            "MultinomialNB": {
                "name": "Multinomial Naive Bayes",
                "purpose": "Phân loại xác suất dựa trên định lý Bayes",
                "strengths": [
                    "Hiệu quả với dữ liệu văn bản",
                    "Nhanh trong huấn luyện và dự đoán",
                    "Hoạt động tốt với ít dữ liệu"
                ],
                "parameters": {
                    "alpha": [0.1, 0.5, 1.0],
                    "fit_prior": [True, False]
                }
            }
        }

    @staticmethod
    def text_augmentation_techniques():
        """
        Các kỹ thuật tăng cường dữ liệu văn bản
        """
        return {
            "Synonym Replacement": {
                "description": "Thay thế từ bằng từ đồng nghĩa",
                "implementation": "Sử dụng từ điển đồng nghĩa hoặc thay thế ký tự",
                "purpose": "Tăng đa dạng từ vựng"
            },
            "Random Swap": {
                "description": "Hoán đổi vị trí ngẫu nhiên các từ",
                "implementation": "Thuật toán hoán đổi ngẫu nhiên",
                "purpose": "Tạo biến thể cấu trúc câu"
            },
            "Random Deletion": {
                "description": "Xóa ngẫu nhiên một số từ",
                "implementation": "Xóa với xác suất cho trước",
                "purpose": "Mô phỏng câu thiếu từ"
            },
            "Text Humanization": {
                "description": "Thêm biến thể người dùng thực",
                "implementation": "Thêm typo, emojis, từ lóng",
                "purpose": "Tăng tính thực tế của dữ liệu"
            }
        }

    @staticmethod
    def evaluation_metrics():
        """
        Các độ đo đánh giá
        """
        return {
            "Classification Report": {
                "metrics": ["Precision", "Recall", "F1-score"],
                "purpose": "Đánh giá chi tiết từng lớp"
            },
            "Confusion Matrix": {
                "purpose": "Phân tích chi tiết dự đoán đúng/sai",
                "visualization": "Heatmap with seaborn"
            },
            "ROC Curve": {
                "purpose": "Đánh giá hiệu suất phân loại ở các ngưỡng khác nhau",
                "metrics": ["AUC-ROC"]
            }
        }

    @staticmethod
    def get_pipeline_overview():
        """
        Tổng quan về pipeline xử lý
        """
        return {
            "1. Data Preprocessing": {
                "steps": [
                    "Làm sạch văn bản",
                    "Chuẩn hóa ký tự",
                    "Tokenization",
                    "Loại bỏ stopwords"
                ]
            },
            "2. Feature Engineering": {
                "steps": [
                    "TF-IDF Vectorization",
                    "Character N-grams",
                    "Dimensionality Reduction (SVD)",
                    "Feature Scaling"
                ]
            },
            "3. Model Training": {
                "steps": [
                    "Ensemble Learning",
                    "Cross Validation",
                    "Hyperparameter Optimization",
                    "Model Selection"
                ]
            },
            "4. Evaluation": {
                "steps": [
                    "Performance Metrics",
                    "Error Analysis",
                    "Visualization",
                    "Model Comparison"
                ]
            }
        }

    @staticmethod
    def get_optimization_techniques():
        """
        Các kỹ thuật tối ưu hóa
        """
        return {
            "Hyperparameter Tuning": {
                "method": "Grid Search với Cross Validation",
                "parameters": {
                    "RandomForest": ["n_estimators", "max_depth", "min_samples_split"],
                    "LinearSVC": ["C", "max_iter", "tol"],
                    "MultinomialNB": ["alpha", "fit_prior"]
                }
            },
            "Feature Selection": {
                "method": "SelectKBest với chi2",
                "purpose": "Chọn đặc trưng quan trọng nhất"
            },
            "Ensemble Methods": {
                "technique": "Voting Classifier",
                "purpose": "Kết hợp dự đoán từ nhiều mô hình"
            },
            "Class Balancing": {
                "method": "Class Weights",
                "purpose": "Xử lý dữ liệu không cân bằng"
            }
        }

    @staticmethod
    def get_model_selection_criteria():
        """
        Tiêu chí lựa chọn mô hình
        """
        return {
            "Performance": {
                "metrics": ["F1-score", "Accuracy", "ROC-AUC"],
                "importance": "High"
            },
            "Training Time": {
                "consideration": "Thời gian huấn luyện hợp lý",
                "importance": "Medium"
            },
            "Memory Usage": {
                "consideration": "Sử dụng bộ nhớ hiệu quả",
                "importance": "Medium"
            },
            "Interpretability": {
                "consideration": "Khả năng giải thích kết quả",
                "importance": "Medium-High"
            }
        }

================
File: src/features/feature_engineering.py
================
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from src.config import Config
from src.utils.logger import Logger
import numpy as np
import os
import joblib
import re


class FeatureExtractor:
    def __init__(self, language: str, config: Config):
        try:
            self.language = language
            self.config = config
            self.is_fitted = False
            self.logger = Logger(__name__).logger

            # Initialize all required attributes
            self.tfidf = TfidfVectorizer(max_features=config.MAX_FEATURES)
            self.svd = TruncatedSVD(n_components=config.SVD_COMPONENTS) 
            self.scaler = StandardScaler()
            self.feature_dims = None
            self.vocabulary = None
            self.n_features = None
            self.min_components = 2
            self.word_vectorizer = None
            self.char_vectorizer = None

            # Load lexicons and initialize vectorizers
            self.sentiment_lexicon = self._load_sentiment_lexicon()
            self.positive_words = self._load_word_list("positive")
            self.negative_words = self._load_word_list("negative")

            # Try loading existing extractors first
            if not self._initialize_extractors():
                self._initialize_base_extractors()

        except Exception as e:
            print(f"Error initializing FeatureExtractor: {str(e)}")
            raise

    def preprocess_text(self, text: str):
        # Implement text preprocessing logic
        return text

    def _initialize_base_extractors(self):
        """Initialize feature extractors with documented parameters"""

        # TF-IDF vectorizer
        self.tfidf = TfidfVectorizer(
            max_features=2000,
            ngram_range=(1, 3),
            min_df=2,
            max_df=0.95,
            strip_accents="unicode",
            token_pattern=r"(?u)\b\w+\b",
            lowercase=True,
        )

        # SVD for dimensionality reduction
        self.svd = TruncatedSVD(n_components=None)

        # Word and character level vectorizers
        self.word_vectorizer = TfidfVectorizer(
            max_features=2000,
            ngram_range=(1, 3),
            min_df=2,
            max_df=0.95,
            strip_accents="unicode",
            token_pattern=r"(?u)\b\w+\b",
            lowercase=True,
        )

        self.char_vectorizer = TfidfVectorizer(
            analyzer="char", ngram_range=(2, 4), max_features=500
        )

        self.scaler = MinMaxScaler()

    def _initialize_extractors(self):
        """Load pretrained extractors if available"""
        model_path = os.path.join(
            self.config.DATA_DIR, "models", f"{self.language}_sentiment_model.pkl"
        )

        if os.path.exists(model_path):
            try:
                model_info = joblib.load(model_path)
                if "feature_extractor" in model_info:
                    # Load all vectorizers and transformers
                    self.tfidf = model_info["feature_extractor"]["vectorizer"]
                    self.svd = model_info["feature_extractor"]["svd"]
                    self.scaler = model_info["feature_extractor"]["scaler"]
                    self.word_vectorizer = model_info["feature_extractor"].get(
                        "word_vectorizer"
                    )
                    self.char_vectorizer = model_info["feature_extractor"].get(
                        "char_vectorizer"
                    )
                    self.feature_dims = model_info["feature_extractor"].get(
                        "feature_dims"
                    )
                    self.vocabulary = self.tfidf.vocabulary_

                    # Initialize vectorizers if they don't exist in saved model
                    if self.word_vectorizer is None:
                        self._initialize_text_vectorizers()

                    self.is_fitted = True
                    print(
                        f"Loaded feature extractor with {self.feature_dims} dimensions"
                    )
                    return True
            except Exception as e:
                print(f"Error loading pretrained extractors: {str(e)}")
                self._initialize_text_vectorizers()
        return False

    def _initialize_text_vectorizers(self):
        """Initialize word and character vectorizers"""
        self.word_vectorizer = TfidfVectorizer(
            max_features=1000,
            ngram_range=(1, 2),
            min_df=1,
            max_df=1.0,
            strip_accents="unicode",
            token_pattern=r"(?u)\b\w+\b",
            lowercase=True,
        )

        self.char_vectorizer = TfidfVectorizer(
            analyzer="char", ngram_range=(2, 4), max_features=500, min_df=1, max_df=1.0
        )

    def _load_sentiment_lexicon(self):
        """Load sentiment lexicon based on language"""
        try:
            lexicon_path = os.path.join(
                self.config.DATA_DIR,
                "lexicons",
                f"{self.language}_sentiment_lexicon.txt",
            )
            if os.path.exists(lexicon_path):
                with open(lexicon_path, "r", encoding="utf-8") as f:
                    return set(line.strip() for line in f)
            return set()
        except Exception:
            return set()

    def _load_word_list(self, category):
        """Load positive/negative word lists"""
        try:
            path = os.path.join(
                self.config.DATA_DIR,
                "lexicons",
                f"{self.language}_{category}_words.txt",
            )
            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    return set(line.strip() for line in f)
            return set()
        except Exception:
            return set()

    def extract_features(self, texts):
        """Enhanced feature extraction with proper array handling"""
        try:
            # Validate input
            if texts is None or len(texts) == 0:
                raise ValueError("Empty input texts provided")

            # Convert input
            if isinstance(texts, str):
                texts = [texts]
            elif isinstance(texts, pd.Series):
                texts = texts.tolist()

            # Clean and validate texts
            valid_texts = [str(t).strip() for t in texts if str(t).strip()]
            if not valid_texts:
                raise ValueError("No valid text content after cleaning")

            # Extract features based on fit status
            if not self.is_fitted:
                # Training phase - fit and transform
                word_features = self.word_vectorizer.fit_transform(
                    valid_texts
                ).toarray()
                char_features = self.char_vectorizer.fit_transform(
                    valid_texts
                ).toarray()
                tfidf_features = self.tfidf.fit_transform(valid_texts).toarray()
            else:
                # Prediction phase - transform only
                word_features = self.word_vectorizer.transform(valid_texts).toarray()
                char_features = self.char_vectorizer.transform(valid_texts).toarray()
                tfidf_features = self.tfidf.transform(valid_texts).toarray()

            # Add new linguistic features
            linguistic_features = self._extract_linguistic_features(valid_texts)

            # Add emotion lexicon features
            emotion_features = self._extract_emotion_features(valid_texts)

            # Add semantic features if available
            semantic_features = self._extract_semantic_features(valid_texts)

            # Debugging: Print shapes of individual feature arrays
            print(f"Word features shape: {word_features.shape}")
            print(f"Char features shape: {char_features.shape}")
            print(f"Tfidf features shape: {tfidf_features.shape}")
            print(f"Linguistic features shape: {linguistic_features.shape}")
            print(f"Emotion features shape: {emotion_features.shape}")
            if semantic_features is not None:
                print(f"Semantic features shape: {semantic_features.shape}")

            # Ensure all feature arrays are 2D and have consistent sample size
            features_list = [
                word_features,
                char_features,
                tfidf_features,
                linguistic_features,
                emotion_features,
            ]

            if semantic_features is not None:
                features_list.append(semantic_features)

            num_samples = len(valid_texts)
            for i, feat in enumerate(features_list):
                # Check if feature array is None
                if feat is None:
                    raise ValueError(f"Feature array at index {i} is None")

                # Ensure feature arrays are 2D
                if feat.ndim == 1:
                    feat = feat.reshape(-1, 1)
                    features_list[i] = feat

                # Check if the number of samples matches
                if feat.shape[0] != num_samples:
                    raise ValueError(
                        f"Feature array at index {i} has inconsistent number of samples. Expected {num_samples}, got {feat.shape[0]}"
                    )

            # Combine all features
            all_features = np.hstack(features_list)
            print(f"All features shape after hstack: {all_features.shape}")

            # Scale features
            if not self.is_fitted:
                self.scaler.fit(all_features)
                self.is_fitted = True

            scaled_features = self.scaler.transform(all_features)

            return scaled_features

        except Exception as e:
            print(f"Feature extraction failed: {str(e)}")
            print(f"Debug info - Input size: {len(texts)}")
            print(
                f"Debug info - Features shape: {[f.shape for f in features_list if f is not None]}"
            )
            print(f"Debug info - Is fitted: {self.is_fitted}")
            print(
                f"Debug info - Vectorizers: word={self.word_vectorizer is not None}, char={self.char_vectorizer is not None}"
            )
            raise

    def _extract_and_scale_features(self, tfidf_features, texts):
        """Extract and scale features using SVD"""
        n_components = min(
            tfidf_features.shape[1] - 1, len(texts) - 1, self.config.MAX_FEATURES
        )
        self.svd.n_components = n_components

        svd_features = self.svd.fit_transform(tfidf_features)
        scaled_features = self.scaler.fit_transform(svd_features)

        return scaled_features

    def _extract_statistical_features(self, texts):
        """Enhanced statistical features for better sentiment detection"""
        features = []
        for text in texts:
            text = str(text)
            words = text.split()

            # Basic features
            length = len(text)
            word_count = len(text.split())
            avg_word_length = length / max(word_count, 1)

            # Additional features
            unique_chars = len(set(text))
            digit_count = sum(c.isdigit() for c in text)
            upper_count = sum(c.isupper() for c in text)
            space_count = sum(c.isspace() for c in text)
            special_chars = sum(not c.isalnum() for c in text)

            # New advanced features
            sentiment_words = len([w for w in words if w in self.sentiment_lexicon])
            exclamation_count = text.count("!")
            question_count = text.count("?")
            emoji_count = len(re.findall(r"[\U0001F300-\U0001F9FF]", text))

            # Word patterns
            caps_word_count = len([w for w in words if w.isupper()])
            word_length_variance = np.var([len(w) for w in words]) if words else 0

            # Sentiment patterns
            positive_words = len([w for w in words if w in self.positive_words])
            negative_words = len([w for w in words if w in self.negative_words])

            # Additional sentiment-specific features
            exclamation_sequences = len(re.findall(r"!+", text))
            question_sequences = len(re.findall(r"\?+", text))
            uppercase_words = sum(1 for word in words if word.isupper())
            word_count = len(words)

            # Emotional pattern features
            positive_emoticons = len(re.findall(r"[:;]-?[\)pP]", text))
            negative_emoticons = len(re.findall(r"[:;]-?[\(]", text))
            emoji_pattern = len(re.findall(r"[\U0001F600-\U0001F64F]", text))

            # Sentiment word ratios
            positive_ratio = sum(
                1 for word in words if word in self.positive_words
            ) / max(word_count, 1)
            negative_ratio = sum(
                1 for word in words if word in self.negative_words
            ) / max(word_count, 1)

            features.append(
                [
                    length,
                    word_count,
                    avg_word_length,
                    unique_chars,
                    digit_count,
                    upper_count,
                    space_count,
                    special_chars,
                    sentiment_words / max(len(words), 1),
                    exclamation_count,
                    question_count,
                    emoji_count,
                    caps_word_count / max(len(words), 1),
                    word_length_variance,
                    positive_words / max(len(words), 1),
                    negative_words / max(len(words), 1),
                    exclamation_sequences,
                    question_sequences,
                    uppercase_words / max(word_count, 1),
                    positive_emoticons,
                    negative_emoticons,
                    emoji_pattern,
                    positive_ratio,
                    negative_ratio,
                ]
            )

        return np.array(features, dtype=np.float32)

    def _extract_linguistic_features(self, texts):
        """Extract linguistic features from texts"""
        features = []
        for text in texts:
            text = str(text)
            words = text.split()

            # Syntactic features
            sentence_count = len([s for s in text.split(".") if len(s.strip()) > 0])
            avg_words_per_sentence = len(words) / max(sentence_count, 1)
            avg_word_length = sum(len(w) for w in words) / max(len(words), 1)

            # Basic features
            punctuation_ratio = sum(c in ".,!?;:" for c in text) / max(len(text), 1)
            capital_ratio = sum(c.isupper() for c in text) / max(len(text), 1)

            # Stop words ratio
            stop_words = self.config.LANGUAGE_CONFIGS[self.language]["stop_words"]
            if isinstance(stop_words, str) and stop_words == "english":
                from nltk.corpus import stopwords

                stop_words = set(stopwords.words("english"))
            else:
                stop_words = set(stop_words)
            stop_word_ratio = sum(w.lower() in stop_words for w in words) / max(
                len(words), 1
            )

            # Combine basic features
            feature_vector = [
                sentence_count,
                avg_words_per_sentence,
                avg_word_length,
                punctuation_ratio,
                capital_ratio,
                stop_word_ratio,
            ]

            features.append(feature_vector)

        return np.array(features, dtype=np.float32)

    def _extract_emotion_features(self, texts):
        """Extract emotion-based features from texts"""
        features = []
        for text in texts:
            text = str(text).lower()
            words = text.split()

            # Get emotion keywords for current language
            emotion_keywords = self.config.EMOTION_KEYWORDS.get(self.language, {})

            # Calculate emotion scores
            emotion_scores = []
            for emotion, keywords in sorted(
                emotion_keywords.items()
            ):  # Sort for consistent order
                score = sum(1 for word in words if word in keywords)
                emotion_scores.append(score / max(len(words), 1))

            # Additional emotion indicators
            exclamation_ratio = text.count("!") / max(len(text), 1)
            question_ratio = text.count("?") / max(len(text), 1)
            emoji_ratio = len(re.findall(r"[\U0001F300-\U0001F9FF]", text)) / max(
                len(text), 1
            )

            # Combine all emotion features
            feature_vector = [
                *emotion_scores,
                exclamation_ratio,
                question_ratio,
                emoji_ratio,
            ]
            features.append(feature_vector)

        return np.array(features, dtype=np.float32)

    def _extract_semantic_features(self, texts):
        """Extract semantic features from texts if available"""
        if not hasattr(self, "word_vectors"):
            return None

        vector_size = getattr(self.word_vectors, "vector_size", 100)
        features = []

        for text in texts:
            words = str(text).lower().split()
            word_vectors = []

            for word in words:
                try:
                    if word in self.word_vectors:
                        word_vectors.append(self.word_vectors[word])
                except:
                    continue

            if word_vectors:
                avg_vector = np.mean(word_vectors, axis=0)
            else:
                avg_vector = np.zeros(vector_size)

            features.append(avg_vector)

        return np.array(features, dtype=np.float32)

================
File: src/features/text_cleaner.py
================
import re
import unicodedata
from underthesea import word_tokenize  # For Vietnamese
from nltk.tokenize import word_tokenize as en_tokenize
from nltk.corpus import stopwords


class TextCleaner:
    """Text cleaning and preprocessing class"""

    def __init__(self, language: str, config):
        self.language = language
        self.config = config
        self.stop_words = self._get_stop_words()

    def _get_stop_words(self):
        return self.config.LANGUAGE_CONFIGS[self.language]["stop_words"]

    def clean_text(self, text: str) -> str:
        """Clean and normalize input text"""
        # Remove HTML
        text = re.sub(r"<[^>]+>", "", text)

        # Normalize text to NFC form to standardize characters
        text = unicodedata.normalize("NFC", text)

        # Remove characters that are not letters or whitespace
        text = re.sub(r"[^\w\s]", " ", text, flags=re.UNICODE)

        # Remove digits and underscores
        text = re.sub(r"[\d_]+", " ", text)

        text = text.lower()

        # Tokenize based on languages
        if self.language == "vi":
            tokens = word_tokenize(text)
        else:
            tokens = en_tokenize(text)

        # Remove stop words
        tokens = [t for t in tokens if t not in self.stop_words]

        return " ".join(tokens)

================
File: src/main.py
================
import argparse
import json
from logging import config
import subprocess
from anyio import open_process
from matplotlib import pyplot as plt
import pandas as pd
import os
import sys
import joblib
from datetime import datetime
import psutil
from rich.prompt import Prompt
import requests
import socket
import time
import logging
from logging.handlers import RotatingFileHandler

# Add project root to path
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)

from src.data.data_collection import DataCollector
from src.utils.server_utils import force_kill_port, is_port_in_use
from src.api.app import app, start_api_server, stop_api_server, get_api_status
from src.config import Config
from src.data.data_loader import DataLoader
from src.data.preprocessor import DataPreprocessor
from src.features.feature_engineering import FeatureExtractor
from src.models.model_trainer import EnhancedModelTrainer
from src.models.model_predictor import SentimentPredictor
from src.utils.evaluation import ModelEvaluator
from src.utils.logger import Logger
from src.utils.menu import TerminalMenu
from scripts.generate_training_data import TrainingDataGenerator
from src.visualization import ModelVisualizer

# Add logger initialization at the top level
logger = Logger(__name__).logger


def parse_args():
    parser = argparse.ArgumentParser(description="Sentiment Analysis CLI")
    parser.add_argument(
        "--mode",
        type=str,
        required=True,
        choices=["train", "predict", "evaluate"],
        help="Mode of operation: train, predict, or evaluate",
    )
    parser.add_argument(
        "--language",
        type=str,
        required=True,
        choices=["en", "vi"],
        help="Language for sentiment analysis (en/vi)",
    )
    parser.add_argument(
        "--input", type=str, help="Input file path for prediction or evaluation"
    )
    parser.add_argument(
        "--output", type=str, help="Output file path for saving results"
    )
    return parser.parse_args()


def train(language: str, config: Config):
    logger = Logger(__name__).logger
    logger.info(f"Starting training for {language} language")

    try:
        # Initialize components with proper error handling
        data_loader = DataLoader(config)
        preprocessor = DataPreprocessor(language, config)
        feature_extractor = None

        try:
            feature_extractor = FeatureExtractor(language, config)
            if feature_extractor is None:
                raise ValueError("Failed to initialize feature extractor")
        except Exception as fe:
            logger.error(f"Feature extractor initialization failed: {str(fe)}")
            raise

        # initialize model trainer
        model_trainer = EnhancedModelTrainer(language, config)
        if feature_extractor:
            model_trainer.feature_extractor = feature_extractor

        # Load and validate data with error checks
        file_path = os.path.join(config.DATA_DIR, 'raw', f'{language}_social_media.csv')
        df = data_loader.load_data(file_path)
        if df is None or df.empty:
            raise ValueError("No data loaded")

        processed_df = preprocessor.preprocess(df)
        if processed_df is None or processed_df.empty:
            raise ValueError("No valid samples after preprocessing")

        # Split and extract features with validation
        train_df, test_df = data_loader.split_data(processed_df)
        if train_df.empty or test_df.empty:
            raise ValueError("Error in train-test split")

        X_train, y_train = data_loader.get_features_and_labels(train_df)
        if len(X_train) == 0 or len(y_train) == 0:
            raise ValueError("No training samples available")

        # Record start time
        start_time = datetime.now()

        # Train model with error handling
        models = model_trainer.train_with_grid_search(X_train, y_train)
        if not models:
            raise ValueError("Model training failed - no valid models returned")

        # Calculate training time
        training_time = (datetime.now() - start_time).total_seconds()

        # Get metrics for best performing model
        best_model_name = max(
            models.items(), key=lambda x: getattr(x[1], "best_score_", 0)
        )[0]
        best_model = models[best_model_name]

        # Evaluate on test set
        X_test, y_test = data_loader.get_features_and_labels(test_df)
        X_test_features = feature_extractor.extract_features(X_test)

        # Calculate metrics using the best model
        test_score = best_model.score(X_test_features, y_test)

        final_metrics = {
            "test_score": test_score,
            "best_model": best_model_name,
            "training_time": training_time,
        }

        if hasattr(best_model, "feature_importances_"):
            final_metrics["feature_importance"] = (
                best_model.feature_importances_.tolist()
            )

        # Save final model with metrics
        model_trainer.save_final_model(models, final_metrics)

        logger.info("Training completed successfully")
        logger.info(f"Total training time: {training_time:.2f} seconds")
        logger.info(f"Best model: {best_model_name} with test score: {test_score:.4f}")

        return models

    except Exception as e:
        logger.error(f"Training failed: {str(e)}")
        # Load last checkpoint if available
        checkpoint_dir = os.path.join(config.DATA_DIR, "checkpoints")
        if os.path.exists(checkpoint_dir):
            checkpoints = sorted(
                [
                    f
                    for f in os.listdir(checkpoint_dir)
                    if f.startswith(f"{language}_checkpoint")
                ]
            )
            if checkpoints:
                latest_checkpoint = joblib.load(
                    os.path.join(checkpoint_dir, checkpoints[-1])
                )
                logger.info(f"Loaded latest checkpoint from {checkpoints[-1]}")
                return latest_checkpoint["model_state"]
        raise e


def predict(language: str, input_file: str, output_file: str, config: Config):
    logger = Logger(__name__).logger
    logger.info(f"Starting prediction for {language} language")

    # Initialize components
    predictor = SentimentPredictor(language, config)
    preprocessor = DataPreprocessor(language, config)
    feature_extractor = FeatureExtractor(language, config)

    # Load and process input data
    df = pd.read_csv(input_file)
    processed_df = preprocessor.preprocess(df)
    features = feature_extractor.extract_features(processed_df["cleaned_text"])

    # Make predictions
    predictions = predictor.predict(features)
    df["sentiment"] = predictions
    df.to_csv(output_file, index=False)

    logger.info(f"Predictions saved to {output_file}")

    # Output prediction results
    for text, sentiment in zip(df["text"], df["sentiment"]):
        print(f"Text: {text}")
        print(f"Prediction: {sentiment}")


def evaluate(language: str, input_file: str, config: Config):
    logger = Logger(__name__).logger
    logger.info(f"Starting evaluation for {language} language")

    # Initialize components
    predictor = SentimentPredictor(language, config)
    preprocessor = DataPreprocessor(language, config)
    feature_extractor = FeatureExtractor(language, config)
    evaluator = ModelEvaluator(language)

    # Load and process test data
    df = pd.read_csv(input_file)
    processed_df = preprocessor.preprocess(df)
    features = feature_extractor.extract_features(processed_df["cleaned_text"])

    # Make predictions and evaluate
    predictions = predictor.predict(features)
    probabilities = predictor.predict_proba(features)
    results = evaluator.evaluate(processed_df["label"], predictions, probabilities)

    logger.info("Evaluation results:")
    logger.info(results["classification_report"])


def validate_paths(input_file: str = None, output_file: str = None):
    """Validate input and output paths"""
    if input_file:
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"Input file not found: {input_file}")

    if output_file:
        output_dir = os.path.dirname(output_file)
        if output_dir:
            os.makedirs(output_dir, exist_ok=True)


def test_model(language: str, config: Config):
    """Interactive model testing"""
    logger = Logger(__name__).logger
    menu = TerminalMenu(config)  # Pass config here

    try:
        # Initialize components
        predictor = SentimentPredictor(language, config)
        preprocessor = DataPreprocessor(language, config)
        feature_extractor = FeatureExtractor(language, config)

        while True:
            try:
                # Get test text
                test_text = menu.get_test_text()
                if test_text.lower() == "q":
                    break

                # Create DataFrame with single text
                df = pd.DataFrame({"text": [test_text]})

                # Process text
                processed_df = preprocessor.preprocess(df)
                if processed_df.empty:
                    menu.display_result(False, "Text preprocessing failed")
                    continue

                # Extract features
                features = feature_extractor.extract_features(
                    processed_df["cleaned_text"]
                )
                if features is None or features.size == 0:
                    menu.display_result(False, "Feature extraction failed")
                    continue

                # Get predictions with emotion analysis
                emotion_result = predictor.predict_emotion(features, test_text)

                # Display results
                menu.display_emotion_result(test_text, emotion_result)

            except Exception as e:
                logger.error(f"Error processing text: {str(e)}")
                menu.display_result(False, f"Error: {str(e)}")

    except Exception as e:
        logger.error(f"Test model error: {str(e)}")
        menu.display_result(False, f"Error: {str(e)}")

    return


def restore_model(language: str, config: Config):
    """Restore model from checkpoint"""
    logger = Logger(__name__).logger
    trainer = EnhancedModelTrainer(language, config)

    try:
        # List available checkpoints
        checkpoints = trainer.list_checkpoints()
        if not checkpoints:
            logger.warning("No checkpoints available")
            return None

        # Display available checkpoints
        print("\nAvailable checkpoints:")
        for i, cp in enumerate(checkpoints):
            print(f"{i+1}. {cp['filename']}")
            print(f"   Timestamp: {cp['timestamp']}")
            print(f"   Epoch: {cp['epoch']}")
            print(f"   Score: {cp['metrics']:.4f if cp['metrics'] else 'N/A'}")

        # Get user choice
        choice = input(
            "\nEnter checkpoint number to restore (or press Enter for latest): "
        )
        if choice.strip():
            idx = int(choice) - 1
            if 0 <= idx < len(checkpoints):
                checkpoint_name = checkpoints[idx]["filename"]
            else:
                raise ValueError("Invalid checkpoint number")
        else:
            checkpoint_name = None

        # Restore model
        model, metrics = trainer.restore_from_checkpoint(checkpoint_name)
        if model is not None:
            logger.info("Model restored successfully")
            logger.info(f"Model metrics: {metrics}")
            return model

    except Exception as e:
        logger.error(f"Error restoring model: {str(e)}")
        return None


def display_metrics(language: str, config: Config):
    """Display current model metrics and performance visualization"""
    logger = Logger(__name__).logger
    model_path = os.path.join(
        config.DATA_DIR, "models", f"{language}_sentiment_model.pkl"
    )
    metrics_img_path = os.path.join(
        config.DATA_DIR, "metrics", f"{language}_model_metrics.png"
    )
    os.makedirs(os.path.dirname(metrics_img_path), exist_ok=True)

    try:
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"No model found for {language}")

        # Load model info
        model_info = joblib.load(model_path)

        # Print basic info
        print("\n=== Model Performance Metrics ===")
        print(f"Language: {language.upper()}")

        # Extract metrics
        if "metrics" not in model_info:
            raise ValueError("No metrics found in model")

        metrics = model_info["metrics"]

        # Extract scores
        scores = []
        model_names = []

        if isinstance(metrics, dict):
            model_data = metrics.get("models", {})
            if not model_data:
                model_data = {"base_model": metrics}

            for model_name, model_metrics in model_data.items():
                if isinstance(model_metrics, dict):
                    # Try to get score from various possible keys
                    score = None
                    for score_key in [
                        "best_score",
                        "test_score",
                        "f1_score",
                        "accuracy",
                    ]:
                        if score_key in model_metrics:
                            score = float(model_metrics[score_key])
                            break

                    if score is not None:
                        scores.append(score)
                        model_names.append(model_name)
                        print(f"\n{model_name.upper()} Score: {score:.4f}")

        if not scores:
            raise ValueError("No valid scores found in metrics")

        # Create simple bar plot of scores
        plt.figure(figsize=(15, 5))

        # Plot 1: Model Scores
        plt.subplot(1, 2, 1)
        bars = plt.bar(range(len(scores)), scores, color=["blue", "green", "red"])
        plt.xticks(range(len(model_names)), model_names, rotation=45)
        plt.title(f"Model Performance Comparison\n{language.upper()}")
        plt.xlabel("Models")
        plt.ylabel("Score")
        plt.ylim(0, 1)

        # Add score labels
        for bar, score in zip(bars, scores):
            plt.text(
                bar.get_x() + bar.get_width() / 2,
                score + 0.01,
                f"{score:.3f}",
                ha="center",
            )

        # Plot 2: Overtraining Analysis
        plt.subplot(1, 2, 2)
        has_data = False

        # Kiểm tra dữ liệu training history
        if isinstance(metrics, dict):
            # Thử lấy từ các vị trí có thể
            history_sources = [
                metrics.get('training_history', {}),
                metrics.get('models', {}),
            ]

            for history in history_sources:
                if history:  # Nếu không rỗng
                    for model_name, model_data in history.items():
                        if isinstance(model_data, dict):
                            train_scores = model_data.get('train_scores', [])
                            valid_scores = model_data.get('valid_scores', [])

                            if train_scores and valid_scores:  # Nếu có dữ liệu
                                has_data = True
                                epochs = range(1, len(train_scores) + 1)
                                
                                # Plot with different colors for each model
                                train_line, = plt.plot(epochs, train_scores, 'o-', 
                                    label=f'{model_name}_train', alpha=0.7)
                                val_line, = plt.plot(epochs, valid_scores, 's--', 
                                    label=f'{model_name}_val', alpha=0.7)

                                # Print scores for debugging
                                print(f"\n{model_name} Training History:")
                                print(f"Training scores: {[f'{score:.4f}' for score in train_scores]}")
                                print(f"Validation scores: {[f'{score:.4f}' for score in valid_scores]}")
                    
                    if has_data:
                        break  # Nếu đã tìm thấy dữ liệu, không cần kiểm tra nguồn khác

        # Cấu hình plot
        if has_data:
            plt.title('Training vs Validation Performance')
            plt.xlabel('Epochs')
            plt.ylabel('Score')
            plt.legend(loc='lower right')
            plt.grid(True, alpha=0.3)
            plt.ylim(0, 1)
        else:
            plt.text(0.5, 0.5, 'No training history available',
                    ha='center', va='center', fontsize=12, color='red')
            print("Warning: No training history found in metrics")

        plt.tight_layout()
        plt.savefig(metrics_img_path, dpi=300, bbox_inches="tight")
        plt.show()

        print(f"\nMetrics visualization saved to: {metrics_img_path}")

    except Exception as e:
        logger.error(f"Error displaying metrics: {str(e)}")
        print(f"Error: Could not display metrics: {str(e)}")


def handle_data_collection(menu, language, config):
    """Handle data collection menu options"""
    while True:
        choice = menu.display_data_collection_menu()
        if choice == "b":
            break

        try:
            # Get custom sample counts
            sample_counts = menu.get_custom_sample_count()
            collector = DataCollector(config)

            if choice == "1":
                app_id = menu.console.input("Enter Google Play app ID: ")
                df = collector.collect_google_play_reviews(
                    app_id, language, sample_counts=sample_counts
                )

            elif choice == "2":
                product_ids = menu.console.input(
                    "Enter Shopee product IDs (comma-separated): "
                )
                df = collector.collect_shopee_reviews(
                    product_ids.split(","), sample_counts=sample_counts
                )

            elif choice == "3":
                token = menu.console.input("Enter Facebook access token: ")
                post_ids = menu.console.input("Enter post IDs (comma-separated): ")
                df = collector.collect_facebook_comments(
                    post_ids.split(","), token, sample_counts=sample_counts
                )

            elif choice == "4":
                file_path = menu.get_file_path("input")
                df = collector.collect_manual_reviews(
                    file_path, sample_counts=sample_counts
                )

            elif choice == "5":
                url = menu.console.input("Enter website URL: ")
                df = collector.collect_from_website(url, sample_counts=sample_counts)

            if not df.empty:
                # Print collection statistics
                stats = df["sentiment"].value_counts()
                menu.console.print("\n[cyan]Collection Statistics:[/cyan]")
                menu.console.print(f"Positive samples: {stats.get(2, 0)}")
                menu.console.print(f"Neutral samples: {stats.get(1, 0)}")
                menu.console.print(f"Negative samples: {stats.get(0, 0)}")

                output_path = menu.get_file_path("output")
                collector.save_collected_data(df, output_path)
                menu.display_result(True, f"Collected {len(df)} samples total")

        except Exception as e:
            menu.display_result(False, f"Error: {str(e)}")
        menu.wait_for_user()


def run_detailed_test(menu, endpoint: str, language: str):
    """Run detailed API testing"""
    try:
        # Test single text
        response = requests.post(
            f"{endpoint}/predict",
            json={"text": "Tôi rất thích sản phẩm này", "language": language},
        )

        # Calculate basic metrics
        metrics = {
            "Response Time": response.elapsed.total_seconds(),
            "Status Code": response.status_code,
            "Response Size": len(response.content),
        }

        # Test accuracy if response is successful
        if response.status_code == 200:
            result = response.json()
            metrics["Confidence"] = result.get("confidence", 0)
            metrics["Sentiment Score"] = result.get("sentiment", -1)

        menu.display_performance_metrics(metrics)
        return metrics

    except Exception as e:
        menu.display_result(False, f"Test failed: {str(e)}")
        return None


def test_api(menu, language):
    """Test API endpoints with detailed options"""
    while True:
        choice = menu.display_api_test_menu()
        if choice == "b":
            break

        try:
            endpoint = menu.get_api_endpoint()

            if choice == "1":  # Test single text prediction
                text = menu.get_test_text()
                if text.lower() == "q":
                    continue

                response = requests.post(
                    f"{endpoint}/predict", json={"text": text, "language": language}
                )
                if response.status_code == 200:
                    menu.display_api_response(response.json())
                else:
                    menu.display_result(False, f"API Error: {response.text}")

            elif choice == "2":  # Test batch prediction
                texts = []
                menu.console.print("\nEnter texts (empty line to finish):")
                while True:
                    text = input("> ").strip()
                    if not text:
                        break
                    texts.append(text)

                if texts:
                    response = requests.post(
                        f"{endpoint}/batch", json={"texts": texts, "language": language}
                    )
                    if response.status_code == 200:
                        menu.display_api_response(response.json()["results"])
                    else:
                        menu.display_result(False, f"API Error: {response.text}")

            elif choice == "3":  # Test health check
                response = requests.get(f"{endpoint}/health")
                if response.status_code == 200:
                    menu.display_api_response(response.json())
                else:
                    menu.display_result(False, f"API Error: {response.text}")

            elif choice == "4":  # Detailed testing
                while True:
                    test_choice = menu.display_detailed_test_menu()
                    if test_choice == "b":
                        break

                    if test_choice == "1":
                        # Test với văn bản đơn lẻ
                        text = menu.get_test_text()
                        if text.lower() == "q":
                            continue

                        response = requests.post(
                            f"{endpoint}/predict",
                            json={"text": text, "language": language},
                        )
                        metrics = run_detailed_test(menu, endpoint, language)
                        if response.status_code == 200:
                            menu.display_api_response(response.json())

                    elif test_choice == "2":
                        # Test với tập dữ liệu mẫu
                        batch_size = menu.get_test_batch_size()
                        test_texts = [
                            "Sản phẩm tốt",
                            "Dịch vụ kém",
                            "Bình thường",
                            # Thêm các mẫu test khác...
                        ][:batch_size]

                        response = requests.post(
                            f"{endpoint}/batch",
                            json={"texts": test_texts, "language": language},
                        )
                        if response.status_code == 200:
                            menu.display_api_response(response.json()["results"])

                    elif test_choice == "3":
                        # Test hiệu năng
                        menu.display_progress("Testing performance")
                        metrics = run_detailed_test(menu, endpoint, language)

                    elif test_choice == "4":
                        # Test độ chính xác
                        menu.display_progress("Testing accuracy")
                        # Implement accuracy testing with known samples
                        test_samples = [
                            ("Sản phẩm rất tốt, tôi rất thích", 2),  # Positive
                            ("Sản phẩm này thật tệ", 0),  # Negative
                            ("Sản phẩm tạm được", 1),  # Neutral
                        ]

                        correct = 0
                        for text, expected in test_samples:
                            response = requests.post(
                                f"{endpoint}/predict",
                                json={"text": text, "language": language},
                            )
                            if response.status_code == 200:
                                result = response.json()
                                if result["sentiment"] == expected:
                                    correct += 1

                        accuracy = correct / len(test_samples)
                        menu.display_performance_metrics({"Accuracy": accuracy})

                    elif test_choice == "5":
                        # Test khả năng chịu tải
                        menu.display_progress("Testing load capacity")
                        batch_sizes = [10, 50, 100]
                        load_metrics = {}

                        for size in batch_sizes:
                            test_texts = ["Test text"] * size
                            start_time = datetime.now()
                            response = requests.post(
                                f"{endpoint}/batch",
                                json={"texts": test_texts, "language": language},
                            )
                            processing_time = (
                                datetime.now() - start_time
                            ).total_seconds()

                            load_metrics[f"Batch {size}"] = {
                                "Processing Time": processing_time,
                                "Time per Text": processing_time / size,
                            }

                        menu.display_performance_metrics(
                            {"Load Test Results": load_metrics}
                        )

        except requests.exceptions.ConnectionError:
            menu.display_result(False, "Could not connect to API server")
        except Exception as e:
            menu.display_result(False, f"Error: {str(e)}")

        menu.wait_for_user()


def find_free_port(start_port=7270, end_port=7280):
    """Find first available port in range"""
    import socket

    for port in range(start_port, end_port + 1):
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            try:
                sock.bind(("", port))
                return port
            except OSError:
                continue
    return None


def force_kill_port(port):
    """Force kill any process using the specified port"""
    try:
        # Get all network connections
        connections = psutil.net_connections()
        for conn in connections:
            try:
                # Check if connection is using our port
                if conn.laddr.port == port:
                    # Find and kill the process
                    try:
                        proc = psutil.Process(conn.pid)
                        proc.kill()
                        return True
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        continue
            except (AttributeError, TypeError):
                continue
        return False
    except Exception as e:
        print(f"Error killing process on port {port}: {e}")
        return False


def end_task_by_name(name: str) -> bool:
    """End task by process name"""
    try:
        killed = False
        for proc in psutil.process_iter(["pid", "name", "cmdline"]):
            try:
                # Check process name first
                if name.lower() in proc.info["name"].lower():
                    proc.kill()
                    killed = True
                    logger.info(
                        f"Killed process: {proc.info['name']} (PID: {proc.info['pid']})"
                    )
                    continue

                # Then check cmdline if available
                cmdline = proc.info.get("cmdline")
                if cmdline:
                    if any(name.lower() in cmd.lower() for cmd in cmdline):
                        proc.kill()
                        killed = True
                        logger.info(
                            f"Killed process: {proc.info['name']} (PID: {proc.info['pid']})"
                        )

            except (
                psutil.NoSuchProcess,
                psutil.AccessDenied,
                psutil.ZombieProcess,
            ) as e:
                logger.debug(f"Skip process: {e}")
                continue
        return killed
    except Exception as e:
        logger.error(f"Error ending task {name}: {e}")
        return False


def cleanup_api_servers():
    """Stop all running API server processes"""
    try:
        killed = False
        target_ports = [7270, 8000]  # Define target ports

        # Get all connections using target ports
        connections = psutil.net_connections()
        target_pids = set()

        for conn in connections:
            try:
                if hasattr(conn, "laddr") and conn.laddr.port in target_ports:
                    target_pids.add(conn.pid)
            except (AttributeError, TypeError):
                continue

        # Only kill Python processes that are using our target ports
        for pid in target_pids:
            try:
                proc = psutil.Process(pid)
                # Verify it's a Python process before killing
                if "python" in proc.name().lower():
                    proc.kill()
                    killed = True
                    logger.info(f"Killed Python process using port {port}: PID {pid}")
            except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                logger.debug(f"Skip process {pid}: {e}")
                continue

        # Verify ports are freed
        for port in target_ports:
            if is_port_in_use(port):
                logger.warning(f"Port {port} is still in use")

        # Small delay to ensure processes are terminated
        if killed:
            time.sleep(1)

        return True
    except Exception as e:
        logger.error(f"Error cleaning up servers: {e}")
        return False


def start_api_server(host="0.0.0.0", port=7270):
    """Start API server with improved management"""
    global server_process
    try:
        # Kill any existing process using the port
        if is_port_in_use(port):
            force_kill_port(port)
            time.sleep(1)  # Wait for port to be freed

        # Set environment variables for better stability
        env = os.environ.copy()
        env["PYTHONUNBUFFERED"] = "1"
        env["PYTHONPATH"] = project_root

        # Start server with improved settings
        command = [
            sys.executable,
            "-m",
            "uvicorn",
            "src.api.app:app",
            f"--host={host}",
            f"--port={port}",
            "--reload",
            "--reload-dir",
            "src",
            "--workers",
            "1",  # Single worker for stability
            "--timeout-keep-alive",
            "30",
            "--limit-concurrency",
            "100",
            "--log-level",
            "info",
        ]

        server_process = subprocess.Popen(
            command, env=env, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
        )

        # Verify server started successfully
        time.sleep(2)
        if server_process.poll() is not None:
            stderr = server_process.stderr.read()
            raise RuntimeError(f"Server failed to start: {stderr}")

        logger.info(f"API server started on {host}:{port}")
        return True

    except Exception as e:
        logger.error(f"Failed to start API server: {str(e)}")
        return False


# Improved server stop function
def stop_api_server():
    """Stop API server with improved cleanup"""
    global server_process
    try:
        # Try graceful shutdown first
        if server_process and server_process.poll() is None:
            requests.post(f"http://localhost:{config.API_CONFIG['PORT']}/shutdown")
            time.sleep(2)

        # Force kill if still running
        if server_process and server_process.poll() is None:
            server_process.terminate()
            server_process.wait(timeout=5)

        # Additional cleanup
        cleanup_api_servers()
        time.sleep(1)

        server_process = None
        return True

    except Exception as e:
        logger.error(f"Error stopping API server: {e}")
        # Force cleanup
        cleanup_api_servers()
        return False


def handle_api_server(menu, language, config):
    """Handle API server operations"""
    while True:
        choice = menu.display_api_menu()
        if choice == "b":
            break

        try:
            if choice == "1":  # Start Server
                menu.display_progress("Starting API server")
                # Get user choice for new terminal

                success = start_api_server(
                    config.API_CONFIG["HOST"], config.API_CONFIG["PORT"]
                )

                if success:
                    menu.display_result(
                        "API server started on http://localhost:{config.API_CONFIG['PORT']}"
                    )
                else:
                    menu.display_result(False, "Failed to start server")

            elif choice == "2":  # Stop Server
                menu.display_progress("Stopping API server")
                try:
                    # Try graceful shutdown first
                    response = requests.post(
                        f"http://localhost:{config.API_CONFIG['PORT']}/shutdown"
                    )
                    if response.status_code == 200:
                        menu.display_result(True, "Server stopped gracefully")
                    else:
                        # Only kill process on used port
                        if force_kill_port(config.API_CONFIG["PORT"]):
                            menu.display_result(
                                True, "Server force stopped successfully"
                            )
                        else:
                            menu.display_result(False, "Failed to stop server")
                except:
                    # If server is not responding, kill specific port
                    if force_kill_port(config.API_CONFIG["PORT"]):
                        menu.display_result(True, "Server force stopped successfully")
                    else:
                        menu.display_result(False, "Failed to stop server")

            elif choice == "3":  # View Status
                try:
                    status = get_api_status()
                    menu.console.print("\n[cyan]API Server Status:[/cyan]")
                    menu.console.print(
                        f"Running: {'Yes' if status['running'] else 'No'}"
                    )
                    menu.console.print("\nLoaded Models:")
                    for lang, loaded in status["models_loaded"].items():
                        menu.console.print(
                            f"{lang.upper()}: {'Loaded' if loaded else 'Not loaded'}"
                        )
                except Exception as e:
                    menu.display_result(False, f"Error getting status: {e}")

            elif choice == "4":  # Configure Settings
                menu.console.print("\n[cyan]API Configuration:[/cyan]")
                menu.console.print(f"Host: {config.API_CONFIG['HOST']}")
                menu.console.print(f"Port: {config.API_CONFIG['PORT']}")
                menu.console.print(f"Workers: {config.API_CONFIG['WORKERS']}")
                menu.console.print(f"Request Timeout: {config.API_CONFIG['TIMEOUT']}s")
                menu.console.print(
                    f"Max Request Size: {config.API_CONFIG['MAX_REQUEST_SIZE']/1024/1024}MB"
                )
                menu.console.print("\nConfiguration can be modified in config.py")

            elif choice == "5":  # Test API
                test_api(menu, language)

            elif choice == "6":  # View Logs
                subchoice = menu.display_logs_menu()
                if subchoice != "b":
                    params = {}

                    if subchoice in ["1", "2", "3"]:  # View logs
                        params["lines"] = menu.get_log_lines()
                        if subchoice == "2":
                            params["type"] = "init"
                        elif subchoice == "3":
                            params["type"] = "request"

                    elif subchoice == "4":  # Filter by path
                        params["path"] = menu.console.input("Enter path: ")

                    elif subchoice == "5":  # Filter by status
                        params["status_code"] = menu.console.input(
                            "Enter status code: "
                        )

                    elif subchoice == "6":  # Filter by time
                        params["since"] = menu.get_log_time()

                    elif subchoice == "7":  # Filter by level
                        params["level"] = menu.get_log_level()

                    elif subchoice == "8":  # Search logs
                        params.update(menu.get_log_search_params())

                    elif subchoice == "9":  # Export logs
                        params["export"] = True
                        params["output"] = menu.get_file_path("logs")

                    # Get and display logs
                    display_server_logs(menu, config, params)

            elif choice == "7":  # Monitor Metrics
                subchoice = menu.display_metrics_menu()
                if subchoice != "b":
                    filters = menu.get_metrics_filter()
                    metrics = ModelEvaluator(language).get_filtered_metrics(filters)
                    menu.display_metrics_summary(metrics)

            elif choice == "8":  # Open Dashboard
                import webbrowser

                port = config.API_CONFIG["PORT"]
                webbrowser.open(f"http://localhost:{port}/dashboard")

            elif choice == "9":  # Export Data
                export_path = menu.get_file_path("export")
                data = {
                    "metrics": ModelEvaluator(language).get_filtered_metrics(
                        {"time_range": "7d"}
                    ),
                    "logs": get_server_logs(config.API_CONFIG["PORT"], lines=1000),
                }
                with open(export_path, "w") as f:
                    json.dump(data, f, indent=2)
                menu.display_result(True, f"Data exported to {export_path}")

        except Exception as e:
            menu.display_result(False, f"Error: {str(e)}")

        menu.wait_for_user()


def handle_preprocessing_menu(menu, language, config):
    """Handle preprocessing options"""
    while True:
        subchoice = menu.display_preprocessing_menu()
        if subchoice == "b":
            break

        try:
            if subchoice == "1":  # Clean text
                input_file = menu.get_file_path("input")
                output_file = menu.get_file_path("output")
                preprocessor = DataPreprocessor(language, config)

                df = pd.read_csv(input_file)
                processed_df = preprocessor.preprocess(df)
                processed_df.to_csv(output_file, index=False)
                menu.display_result(True, f"Cleaned data saved to {output_file}")

            elif subchoice == "2":  # Remove duplicates
                input_file = menu.get_file_path("input")
                output_file = menu.get_file_path("output")

                df = pd.read_csv(input_file)
                df.drop_duplicates(subset=["text"], inplace=True)
                df.to_csv(output_file, index=False)
                menu.display_result(
                    True, f"Duplicates removed and saved to {output_file}"
                )

            elif subchoice == "3":  # Balance dataset
                input_file = menu.get_file_path("input")
                output_file = menu.get_file_path("output")

                df = pd.read_csv(input_file)
                min_samples = df["label"].value_counts().min()
                balanced_df = pd.concat(
                    [
                        df[df["label"] == label].sample(n=min_samples, random_state=42)
                        for label in df["label"].unique()
                    ]
                )
                balanced_df.to_csv(output_file, index=False)
                menu.display_result(True, f"Balanced dataset saved to {output_file}")

            elif subchoice == "4":  # Filter by criteria
                input_file = menu.get_file_path("input")
                output_file = menu.get_file_path("output")
                min_length = menu.console.input("Enter minimum text length: ")

                df = pd.read_csv(input_file)
                filtered_df = df[df["text"].str.len() >= int(min_length)]
                filtered_df.to_csv(output_file, index=False)
                menu.display_result(True, f"Filtered data saved to {output_file}")

            elif subchoice == "5":  # Augment data
                input_file = menu.get_file_path("input")
                output_file = menu.get_file_path("output")

                from data.data_augmentation import DataAugmentor

                augmentor = DataAugmentor(language)
                df = pd.read_csv(input_file)
                augmented_df = augmentor.augment_data(df)
                augmented_df.to_csv(output_file, index=False)
                menu.display_result(True, f"Augmented data saved to {output_file}")

        except Exception as e:
            menu.display_result(False, f"Error: {str(e)}")
        menu.wait_for_user()


def handle_optimization_menu(menu, language, config):
    """Handle model optimization options"""
    while True:
        subchoice = menu.display_optimization_menu()
        if subchoice == "b":
            break

        try:
            if subchoice == "1":  # Hyperparameter tuning
                menu.display_progress("Running hyperparameter optimization...")
                trainer = EnhancedModelTrainer(language, config)
                best_params = trainer.optimize_hyperparameters()
                menu.display_result(True, f"Best parameters found: {best_params}")

            elif subchoice == "2":  # Feature selection
                menu.display_progress("Performing feature selection...")
                feature_selector = feature_selector(language, config)
                selected_features = feature_selector.select_best_features()
                menu.display_result(
                    True, f"Selected {len(selected_features)} best features"
                )

            elif subchoice == "3":  # Cross validation
                menu.display_progress("Running cross validation...")
                evaluator = ModelEvaluator(language)
                cv_scores = evaluator.cross_validate()
                menu.display_result(True, f"Cross validation scores: {cv_scores}")

            elif subchoice == "4":  # Model ensemble
                menu.display_progress("Creating model ensemble...")
                trainer = EnhancedModelTrainer(language, config)
                ensemble = trainer.create_ensemble()
                menu.display_result(True, "Model ensemble created successfully")

            elif subchoice == "5":  # Performance analysis
                menu.display_progress("Analyzing model performance...")
                evaluator = ModelEvaluator(language)
                metrics = evaluator.analyze_performance()
                menu.display_result(True, "Performance analysis complete")
                menu.display_performance_metrics(metrics)

        except Exception as e:
            menu.display_result(False, f"Error: {str(e)}")
        menu.wait_for_user()


def handle_export_menu(menu, language, config):
    """Handle export options"""
    while True:
        subchoice = menu.display_export_menu()
        if subchoice == "b":
            break

        try:
            if subchoice == "1":  # Export predictions
                input_file = menu.get_file_path("input")
                output_file = menu.get_file_path("output")
                predict(language, input_file, output_file, config)
                menu.display_result(True, f"Predictions exported to {output_file}")

            elif subchoice == "2":  # Export metrics
                output_file = menu.get_file_path("metrics")
                evaluator = ModelEvaluator(language)
                metrics = evaluator.get_all_metrics()
                evaluator.export_metrics(metrics, output_file)
                menu.display_result(True, f"Metrics exported to {output_file}")

            elif subchoice == "3":  # Generate report
                output_file = menu.get_file_path("report")
                from src.utils.report import ReportGenerator

                generator = ReportGenerator(language)
                generator.generate_report(output_file)
                menu.display_result(True, f"Report generated at {output_file}")

            elif subchoice == "4":  # Export visualizations
                output_dir = menu.get_file_path("visualizations")
                visualizer = ModelVisualizer(language)
                try:
                    visualizer.generate_plots(output_dir)
                    menu.display_result(True, f"Visualizations saved to {output_dir}")
                except Exception as e:
                    menu.display_result(
                        False, f"Error generating visualizations: {str(e)}"
                    )

            elif subchoice == "5":  # Export model
                output_file = menu.get_file_path("model")
                trainer = EnhancedModelTrainer(language, config)
                trainer.export_model(output_file)
                menu.display_result(True, f"Model exported to {output_file}")

        except Exception as e:
            menu.display_result(False, f"Error: {str(e)}")
        menu.wait_for_user()


def display_server_logs(menu, config, params=None):
    """Display and filter server logs"""
    while True:
        if not params:
            subchoice = menu.display_logs_menu()
            if subchoice == "b":
                break

            params = {}
            if subchoice == "1":  # View latest logs
                params["lines"] = menu.get_log_lines()

            elif subchoice == "2":  # View init logs
                params["type"] = "init"
                params["lines"] = menu.get_log_lines()

            elif subchoice == "3":  # View request logs
                params["type"] = "request"
                params["lines"] = menu.get_log_lines()

            elif subchoice == "4":  # Filter by path
                params["path"] = menu.console.input("Enter path: ")
                params["lines"] = menu.get_log_lines()

            elif subchoice == "5":  # Filter by status
                params["status_code"] = int(menu.console.input("Enter status code: "))
                params["lines"] = menu.get_log_lines()

            elif subchoice == "6":  # Export logs
                output_file = menu.get_file_path("logs")
                params = {"lines": 1000, "output": output_file}

        try:
            # Make API request
            response = requests.get(
                f"http://localhost:{config.API_CONFIG['PORT']}/api/logs",
                params={k: v for k, v in params.items() if k != "output"},
            )

            if response.status_code == 200:
                logs = response.json()

                if "output" in params:  # Export to file
                    with open(params["output"], "w", encoding="utf-8") as f:
                        f.writelines(logs["logs"])
                    menu.display_result(True, f"Logs exported to {params['output']}")
                else:  # Display in console
                    menu.display_filtered_logs(logs["logs"], logs["filters"])
                    menu.display_result(True, f"Found {logs['total']} log entries")
                break
            else:
                menu.display_result(False, f"Failed to get logs: {response.text}")
                break

        except Exception as e:
            menu.display_result(False, f"Error: {str(e)}")
            break

        menu.wait_for_user()


def get_server_logs(port, lines=1000):
    """Fetch server logs from the API"""
    try:
        response = requests.get(
            f"http://localhost:{port}/api/logs", params={"lines": lines}
        )
        if response.status_code == 200:
            return response.json()["logs"]
        else:
            raise RuntimeError(f"Failed to get logs: {response.text}")
    except Exception as e:
        logger.error(f"Error fetching server logs: {e}")
        return []


def setup_logging():
    log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    log_file = 'sentiment_analysis.log'

    file_handler = RotatingFileHandler(log_file, maxBytes=10*1024*1024, backupCount=5)
    file_handler.setFormatter(log_formatter)
    file_handler.setLevel(logging.INFO)

    console_handler = logging.StreamHandler()
    console_handler.setFormatter(log_formatter)
    console_handler.setLevel(logging.INFO)

    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)


def continue_training(language: str, config: Config):
    """Continue training from checkpoint"""
    logger = Logger(__name__).logger
    menu = TerminalMenu(config)
    
    try:
        # Initialize trainer
        trainer = EnhancedModelTrainer(language, config)
        
        # List available checkpoints
        checkpoints = trainer.list_checkpoints()
        if not checkpoints:
            menu.display_result(False, "No checkpoints available")
            return
            
        # Display checkpoints
        print("\nAvailable checkpoints:")
        for i, cp in enumerate(checkpoints):
            print(f"{i+1}. {cp['filename']}")
            print(f"   Timestamp: {cp['timestamp']}")
            print(f"   Epoch: {cp['epoch']}")
            print(f"   Score: {cp['metrics']:.4f if cp['metrics'] else 'N/A'}")
            
        # Get user choice
        choice = menu.console.input("\nEnter checkpoint number (or press Enter for latest): ")
        checkpoint_name = None
        if choice.strip():
            idx = int(choice) - 1
            if 0 <= idx < len(checkpoints):
                checkpoint_name = checkpoints[idx]["filename"]
            else:
                menu.display_result(False, "Invalid checkpoint number")
                return
                
        # Get training parameters
        num_epochs = int(menu.console.input("Enter number of epochs to train: "))
        
        # Load training data
        data_loader = DataLoader(config)
        input_file = menu.get_file_path("training data")
        df = pd.read_csv(input_file)
        
        # Preprocess data
        preprocessor = DataPreprocessor(language, config)
        processed_df = preprocessor.preprocess(df)
        if processed_df.empty:
            raise ValueError("No valid samples after preprocessing")
            
        # Get features and labels
        X_train = processed_df["cleaned_text"]
        y_train = processed_df["label"]
        
        # Continue training
        menu.display_progress("Continuing model training...")
        model, metrics = trainer.continue_training(X_train, y_train, checkpoint_name, num_epochs)
        
        if model:
            menu.display_result(True, "Training continued successfully")
            # Display updated metrics
            display_metrics(language, config)
        else:
            menu.display_result(False, "Training failed")
            
    except Exception as e:
        logger.error(f"Continue training error: {str(e)}")
        menu.display_result(False, f"Error: {str(e)}")

def main():
    # Initialize config first
    config = Config()

    # Pass config to TerminalMenu
    menu = TerminalMenu(config)

    # Only cleanup when starting the program
    cleanup_api_servers()

    while True:
        menu.display_header()
        choice = menu.display_menu()

        if choice == "q":
            break

        language = menu.get_language_choice()

        try:
            if choice == "1":
                menu.display_progress("Training new model")
                train(language, config)
                menu.display_result(True, "Model training completed successfully")
            elif choice == "2":
                input_file = menu.get_file_path("input")
                output_file = menu.get_file_path("output")
                validate_paths(input_file, output_file)
                menu.display_progress("Analyzing text")
                predict(language, input_file, output_file, config)
                menu.display_result(True, f"Results saved to {output_file}")

            elif choice == "3":
                input_file = menu.get_file_path("test data")
                validate_paths(input_file)
                menu.display_progress("Evaluating model")
                evaluate(language, input_file, config)

            elif choice == "4":
                output_file = menu.get_file_path("output")
                validate_paths(output_file=output_file)
                num_samples = menu.get_sample_count()
                menu.display_progress(f"Generating {num_samples} training samples")

                generator = TrainingDataGenerator(language, config, num_samples)
                generator.generate_training_data(output_file)

                menu.display_result(
                    True, f"Generated {num_samples} samples successfully"
                )

            elif choice == "5":
                menu.display_progress("Loading model metrics")
                display_metrics(language, config)

            elif choice == "6":  # Add new test option
                menu.display_progress("Loading model for testing")
                test_model(language, config)

            elif choice == "7":  # Add new restore option
                menu.display_progress("Restoring model from checkpoint")
                model = restore_model(language, config)
                if model:
                    menu.display_result(True, "Model restored successfully")
                else:
                    menu.display_result(False, "Failed to restore model")

            elif choice == "8":
                handle_data_collection(menu, language, config)

            elif choice == "9":
                handle_preprocessing_menu(menu, language, config)

            elif choice == "10":
                handle_optimization_menu(menu, language, config)

            elif choice == "11":
                handle_export_menu(menu, language, config)

            elif choice == "12":  # API Server
                handle_api_server(menu, language, config)
            elif choice == "13":  # Add new menu option
                continue_training(language, config)

        except Exception as e:
            menu.display_result(False, f"Error: {str(e)}")

        menu.wait_for_user()


if __name__ == "__main__":
    setup_logging()
    main()

================
File: src/models/model_predictor.py
================
import os
import joblib
import numpy as np
from scipy import stats
from src.features.feature_engineering import FeatureExtractor
from src.config import Config
from src.utils.logger import Logger


class SentimentPredictor:
    def __init__(self, language: str, config: Config):
        self.language = language
        self.config = config
        self.logger = Logger(__name__).logger
        self.model_path = os.path.join(
            config.DATA_DIR, "models", f"{language}_sentiment_model.pkl"
        )
        self.feature_extractor = FeatureExtractor(language, config)
        self.models = self._load_model()
        self.feature_dims = (
            self.feature_extractor.feature_dims
        )  # Ensure feature_dims is set

    def _load_model(self):
        """Load trained model from file"""
        model_path = os.path.join(
            self.config.DATA_DIR, "models", f"{self.language}_sentiment_model.pkl"
        )

        if not os.path.exists(model_path):
            raise FileNotFoundError(
                f"No model found for {self.language} at {model_path}"
            )

        model_info = joblib.load(model_path)

        if "model" in model_info:
            model = model_info["model"]
            if isinstance(model, dict):
                return {k: v for k, v in model.items() if hasattr(v, "predict")}
            elif hasattr(model, "predict"):
                return {"base": model}

        raise ValueError("No valid models found in model file")

    def predict(self, features):
        """Ensemble prediction using voting with dimension validation"""
        if not self.models:
            raise ValueError("No models available")

        if not isinstance(features, np.ndarray):
            features = np.array(features)

        # Validate feature dimensions
        if self.feature_dims:
            if features.shape[1] != self.feature_dims:
                raise ValueError(
                    f"Feature dimension mismatch. Expected {self.feature_dims}, got {features.shape[1]}"
                )

        predictions = []
        for name, model in self.models.items():
            try:
                if hasattr(model, "predict"):
                    pred = model.predict(features)
                    predictions.append(pred)
            except Exception as e:
                self.logger.error(f"Error in {name} prediction: {str(e)}")
                continue

        if not predictions:
            raise RuntimeError("All models failed to predict")

        # Use majority voting
        stacked_preds = np.vstack(predictions)
        modes, _ = stats.mode(stacked_preds, axis=0)
        return modes.flatten()

    def predict_proba(self, features):
        """Get probability estimates from available models"""
        if not self.models:
            raise ValueError("No models loaded")

        probas = []
        for name, model in self.models.items():
            try:
                # Handle models that don't have predict_proba
                if hasattr(model, "predict_proba"):
                    proba = model.predict_proba(features)
                elif hasattr(model, "decision_function"):
                    # Convert decision function to probabilities
                    dec = model.decision_function(features)
                    proba = 1 / (1 + np.exp(-dec))
                    # Normalize to get probabilities
                    proba = proba / proba.sum(axis=1, keepdims=True)
                else:
                    continue
                probas.append(proba)
            except Exception as e:
                self.logger.error(f"Error in {name} probability estimation: {str(e)}")
                continue

        if probas:
            # Average probabilities from all models
            return np.mean(probas, axis=0)

        raise RuntimeError("No models could provide probability estimates")

    def predict_detailed_emotion(self, features):
        """Predict detailed emotions based on sentiment probabilities"""
        sentiments = self.predict(features)
        probabilities = self.predict_proba(features)

        predictions = []
        for sent, probs in zip(sentiments, probabilities):
            # Map sentiment to emotion category
            if sent == 2:
                emotions = self.config.EMOTION_LABELS["POSITIVE"]
            elif sent == 0:
                emotions = self.config.EMOTION_LABELS["NEGATIVE"]
            else:
                emotions = self.config.EMOTION_LABELS["NEUTRAL"]

            # Select random emotion from category with confidence
            emotion = np.random.choice(list(emotions.values()))
            confidence = np.max(probs)

            predictions.append(
                {
                    "sentiment": sent,
                    "sentiment_confidence": confidence,
                    "detailed_emotion": emotion,
                    "emotion_confidence": confidence
                    * 0.8,  # Slightly lower confidence for detailed emotion
                }
            )

        return predictions

    def predict_emotion(self, features, text: str = None):
        """Predict detailed emotion with confidence scores"""
        try:
            # Get base sentiment prediction
            sentiment = self.predict(features)[0]
            probabilities = self.predict_proba(features)[0]
            base_confidence = max(probabilities)

            # Initialize emotion detector if text is provided
            emotion_scores = {}

            if text:
                text = text.lower()
                # Get emotion keywords for the current language
                keywords = self.config.EMOTION_KEYWORDS.get(self.language, {})

                # Calculate emotion scores based on keyword presence
                for emotion, words in keywords.items():
                    score = sum(1 for word in words if word in text)
                    multiplier = 1.0

                    # Adjust score based on punctuation and capitalization
                    if "!" in text:
                        multiplier *= 1.2
                    if text.isupper():
                        multiplier *= 1.3

                    emotion_scores[emotion] = score * multiplier

                # Normalize scores
                total = sum(emotion_scores.values()) or 1
                emotion_scores = {k: v / total for k, v in emotion_scores.items()}

            # Get emotion mapping for the predicted sentiment
            valid_emotions = {
                emotion: details
                for emotion, details in self.config.EMOTION_MAPPING.items()
                if details["sentiment"] == sentiment
            }

            # Select most likely emotion
            if emotion_scores:
                # Filter emotions by base sentiment
                valid_scores = {
                    emotion: score
                    for emotion, score in emotion_scores.items()
                    if emotion in valid_emotions
                }

                if valid_scores:
                    predicted_emotion = max(valid_scores.items(), key=lambda x: x[1])[0]
                else:
                    # Fallback to default emotion for sentiment
                    predicted_emotion = next(iter(valid_emotions))
            else:
                # Fallback if no text analysis
                predicted_emotion = next(iter(valid_emotions))

            # Get emotion details
            emotion_info = self.config.EMOTION_MAPPING[predicted_emotion]

            return {
                "sentiment": sentiment,
                "sentiment_confidence": base_confidence,
                "emotion": predicted_emotion,
                "emotion_vi": emotion_info["vi"],
                "emotion_emoji": emotion_info["emoji"],
                "emotion_confidence": base_confidence
                * 0.8,  # Slightly lower confidence for detailed emotion
                "emotion_scores": emotion_scores if emotion_scores else None,
            }

        except Exception as e:
            self.logger.error(f"Error in emotion prediction: {str(e)}")
            return None

    async def predict_async(self, text: str):
        try:
            self.logger.info(f"Received text for prediction: {text}")
            processed_text = self.feature_extractor.preprocess_text(text)
            self.logger.info(f"Processed text: {processed_text}")
            features = self.feature_extractor.extract_features([processed_text])
            self.logger.info(f"Extracted features: {features.shape}")
            prediction = self.predict(features)
            self.logger.info(f"Prediction result: {prediction}")
            return prediction[0]
        except Exception as e:
            self.logger.error(f"Prediction error: {e}")
            return None

================
File: src/models/model_trainer.py
================
import os
import joblib
from datetime import datetime
import warnings
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.feature_selection import (
    SelectFromModel,
    SelectKBest,
    chi2,
    mutual_info_classif,
)
from sklearn.utils.class_weight import compute_sample_weight, compute_class_weight
import matplotlib.pyplot as plt
import seaborn as sns
from src.utils.logger import Logger
from sklearn.metrics import (
    f1_score,
    precision_score,
    recall_score,
    make_scorer,
    balanced_accuracy_score,
    roc_auc_score,
)
import numpy as np
import collections


class SVMWithProba(LinearSVC):
    """SVM with probability estimates"""

    def predict_proba(self, X):
        decision = self.decision_function(X)
        if len(decision.shape) == 1:
            decision = np.column_stack([-decision, decision])
        probs = 1 / (1 + np.exp(-decision))
        probs /= probs.sum(axis=1, keepdims=True)
        return probs


class EnhancedModelTrainer:
    """Enhanced model trainer with ensemble learning and performance monitoring."""

    def __init__(self, language: str, config):
        self.language = language
        self.config = config
        self.logger = Logger(__name__).logger
        self.checkpoint_dir = os.path.join(config.DATA_DIR, "checkpoints")
        self.models_dir = os.path.join(config.DATA_DIR, "models")
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        os.makedirs(self.models_dir, exist_ok=True)
        self.training_time = 0
        self.feature_extractor = None  # Initialize feature extractor as None
        self.param_grid = config.PARAM_GRID
        self.model_config = config.MODEL_TRAINING_CONFIG
        self.regularization_config = config.REGULARIZATION_CONFIG
        self.validation_config = config.VALIDATION_CONFIG
        self.scoring_config = config.SCORING_CONFIG

    def _convert_deque_to_list(self, obj):
        """Recursively convert deque objects to lists in the given object."""
        if isinstance(obj, collections.deque):
            return list(obj)
        elif isinstance(obj, dict):
            return {k: self._convert_deque_to_list(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_deque_to_list(v) for v in obj]
        else:
            return obj

    def create_ensemble_model(self):
        """Create model ensemble with documented algorithms"""

        rf = RandomForestClassifier(
            n_estimators=1000,  # Increased from 300
            max_depth=50,  # Increased from 30
            min_samples_split=self.model_config["preprocessing"]["min_df"],
            class_weight=self.model_config["class_weight_method"],
            ccp_alpha=self.regularization_config["rf_reg"]["ccp_alpha"],
            max_samples=0.7,  # Reduced from 0.8 for more randomization
            random_state=42,
            bootstrap=True,
            oob_score=True,  # Enable out-of-bag score estimation
            n_jobs=-1  # Use all CPU cores
        )

        svm = SVMWithProba(
            C=0.5,  # Reduced from 1.0 for better regularization
            max_iter=2000,  # Increased from 1000
            class_weight="balanced",
            dual=False,
            tol=1e-4
        )

        nb = MultinomialNB(
            alpha=0.8,  # Adjusted from default
            fit_prior=True
        )

        models = [
            ("rf", Pipeline([("scaler", MinMaxScaler()), ("rf", rf)])),
            ("svm", Pipeline([("scaler", MinMaxScaler()), ("svm", svm)])),
            ("nb", Pipeline([("scaler", MinMaxScaler()), ("nb", nb)])),
        ]
        return models

    def save_checkpoint(self, model, metrics, epoch=None):
        """Save training checkpoint"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        checkpoint_path = os.path.join(
            self.checkpoint_dir, f"{self.language}_checkpoint_{timestamp}.pkl"
        )

        checkpoint = {
            "model_state": model,
            "metrics": self._convert_deque_to_list(metrics),
            "epoch": epoch,
            "timestamp": timestamp,
            "language": self.language,
        }

        joblib.dump(checkpoint, checkpoint_path)
        self.logger.info(f"Saved checkpoint to {checkpoint_path}")

        # Keep only last 5 checkpoints
        checkpoints = sorted(
            [
                f
                for f in os.listdir(self.checkpoint_dir)
                if f.startswith(f"{self.language}_checkpoint")
            ]
        )
        if len(checkpoints) > 5:
            for old_checkpoint in checkpoints[:-5]:
                os.remove(os.path.join(self.checkpoint_dir, old_checkpoint))

    def save_final_model(self, model, metrics):
        """Save the final trained model with all feature extractors"""
        model_path = os.path.join(
            self.models_dir, f"{self.language}_sentiment_model.pkl"
        )

        # Ensure metrics are properly formatted
        model_metrics = {
            "models": {},
            "total_time": metrics.get("total_time", self.training_time),
        }

        # Format metrics for each model type
        if isinstance(model, dict):
            for model_name, model_obj in model.items():
                model_metrics["models"][model_name] = {
                    "best_score": metrics.get(
                        "test_score", 0.0
                    ),  # Default to test_score if available
                    "training_time": self.training_time,
                    "parameters": getattr(model_obj, "get_params", lambda: {})(),
                }

                # Add additional metrics if available
                if model_name in metrics.get("models", {}):
                    model_metrics["models"][model_name].update(
                        metrics["models"][model_name]
                    )

                # Add feature importance for RF model
                if model_name == "rf" and hasattr(model_obj, "feature_importances_"):
                    model_metrics["models"][model_name][
                        "feature_importance"
                    ] = model_obj.feature_importances_.tolist()

        model_info = {
            "model": model,
            "metrics": self._convert_deque_to_list(metrics),
            "feature_extractor": {
                "vectorizer": self.feature_extractor.tfidf,
                "svd": self.feature_extractor.svd,
                "scaler": self.feature_extractor.scaler,
                "word_vectorizer": self.feature_extractor.word_vectorizer,
                "char_vectorizer": self.feature_extractor.char_vectorizer,
                "feature_dims": self.feature_extractor.feature_dims,
            },
            "config": {
                "language": self.language,
                "max_features": self.config.MAX_FEATURES,
                "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S"),
            },
        }

        joblib.dump(model_info, model_path)
        self.logger.info(f"Saved final model to {model_path}")

    def plot_training_progress(self, grid_search, X_test=None, y_test=None):
        """Visualizes training progress and performance metrics"""
        try:
            # Create figure with 3 subplots
            fig = plt.figure(figsize=(20, 6))

            # 1. Model Performance Comparison
            ax1 = plt.subplot(131)
            scores = []
            names = []

            for name, model in grid_search.items():
                # Get all available scores
                train_f1 = np.mean(model.cv_results_["mean_train_f1"])
                val_f1 = np.mean(model.cv_results_["mean_test_f1"])
                test_score = None
                if X_test is not None and y_test is not None:
                    test_score = f1_score(
                        y_test, model.predict(X_test), average="weighted"
                    )

                scores.append(
                    {"train": train_f1, "validation": val_f1, "test": test_score}
                )
                names.append(name)

            # Plot grouped bar chart
            x = np.arange(len(names))
            width = 0.25

            ax1.bar(
                x - width,
                [s["train"] for s in scores],
                width,
                label="Train",
                color="skyblue",
            )
            ax1.bar(
                x,
                [s["validation"] for s in scores],
                width,
                label="Validation",
                color="lightgreen",
            )
            if all(s["test"] is not None for s in scores):
                ax1.bar(
                    x + width,
                    [s["test"] for s in scores],
                    width,
                    label="Test",
                    color="salmon",
                )

            ax1.set_ylabel("F1 Score")
            ax1.set_title("Model Performance Comparison")
            ax1.set_xticks(x)
            ax1.set_xticklabels(names)
            ax1.legend()
            ax1.grid(True, alpha=0.3)

            # 2. Learning Curves
            ax2 = plt.subplot(132)
            for name, model in grid_search.items():
                train_scores = model.cv_results_["mean_train_f1"]
                val_scores = model.cv_results_["mean_test_f1"]
                epochs = range(1, len(train_scores) + 1)

                ax2.plot(epochs, train_scores, "o-", label=f"{name}_train", alpha=0.7)
                ax2.plot(epochs, val_scores, "s--", label=f"{name}_val", alpha=0.7)

            ax2.set_xlabel("Epochs")
            ax2.set_ylabel("F1 Score")
            ax2.set_title("Learning Curves")
            ax2.legend(bbox_to_anchor=(1.05, 1), loc="upper left")
            ax2.grid(True, alpha=0.3)

            # 3. Model Performance Details
            ax3 = plt.subplot(133)
            details = []
            metrics = ["precision", "recall", "f1"]

            for name, model in grid_search.items():
                row = [name]
                for metric in metrics:
                    train_score = np.mean(model.cv_results_[f"mean_train_{metric}"])
                    val_score = np.mean(model.cv_results_[f"mean_test_{metric}"])
                    row.extend([train_score, val_score])
                details.append(row)

            # Create table
            cell_text = [
                [f"{x:.3f}" if isinstance(x, float) else x for x in row]
                for row in details
            ]
            columns = ["Model"] + sum([[f"{m}_train", f"{m}_val"] for m in metrics], [])
            table = ax3.table(cellText=cell_text, colLabels=columns, loc="center")
            table.auto_set_font_size(False)
            table.set_fontsize(9)
            table.scale(1.2, 1.5)
            ax3.axis("off")
            ax3.set_title("Detailed Metrics")

            plt.tight_layout()
            return fig

        except Exception as e:
            self.logger.error(f"Error plotting training progress: {str(e)}")
            import traceback

            print(traceback.format_exc())
            return None

    def _plot_learning_curves(self, grid_search):
        """Plot learning curves showing training vs validation performance"""
        if isinstance(grid_search, dict):
            for name, model in grid_search.items():
                if hasattr(model, "cv_results_"):
                    train_scores = model.cv_results_["mean_train_f1"]
                    valid_scores = model.cv_results_["mean_test_f1"]
                    iterations = range(1, len(train_scores) + 1)

                    plt.plot(
                        iterations, train_scores, "o-", label=f"{name}_train", alpha=0.8
                    )
                    plt.plot(
                        iterations, valid_scores, "s-", label=f"{name}_val", alpha=0.8
                    )

            plt.title("Learning Curves")
            plt.xlabel("Parameter Combination")
            plt.ylabel("F1 Score")
            plt.legend(loc="center right")
            plt.grid(True)

    def train_with_grid_search(self, X_train, y_train):
        """Train with documented evaluation metrics"""
        start_time = datetime.now()
        self.logger.info("Starting model training...")

        try:
            # Basic feature extraction
            if self.feature_extractor is None:
                from src.features.feature_engineering import FeatureExtractor

                self.feature_extractor = FeatureExtractor(self.language, self.config)

            # Extract and validate features
            X_train_features = self.feature_extractor.extract_features(X_train)
            if X_train_features is None or X_train_features.shape[0] == 0:
                raise ValueError("Feature extraction failed")

            # Simple parameter grid with corrected keys
            self.param_grid = {
                "rf__n_estimators": [300],
                "rf__max_depth": [30],
                "svm__C": [1.0],
                "nb__alpha": [0.1],
            }

            # Update scorers to handle different model types safely
            scorers = {
                "f1": make_scorer(f1_score, average="weighted"),
                "precision": make_scorer(
                    precision_score, average="weighted", zero_division=1
                ),
                "recall": make_scorer(
                    recall_score, average="weighted", zero_division=1
                ),
            }

            # K-fold CV as documenteds
            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

            if isinstance(y_train, pd.Series):
                y_train = y_train.to_numpy()
            if isinstance(X_train, pd.Series):
                X_train = X_train.to_numpy()

            X_train_features = self.feature_extractor.extract_features(X_train)

            # Initialize dictionaries to store training history
            training_history = {}

            # Train models
            models = self.create_ensemble_model()
            best_models = {}
            best_metrics = {}

            # Update grid search to use decision function for SVM
            for name, pipeline in models:
                try:
                    self.logger.info(f"\nTraining {name} model...")

                    # Get training scores for each fold
                    num_epochs = 10  # Increased from 5
                    train_scores = []
                    valid_scores = []

                    # Create cross-validation splits with stratification
                    cv = StratifiedKFold(
                        n_splits=num_epochs, 
                        shuffle=True, 
                        random_state=42
                    )

                    # Add early stopping
                    patience = self.config.VALIDATION_CONFIG["early_stopping"]["patience"]
                    min_delta = self.config.VALIDATION_CONFIG["early_stopping"]["min_delta"]
                    best_score = float('-inf')
                    patience_count = 0

                    # Manual cross-validation loop with early stopping
                    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_features, y_train)):
                        # Split data - using numpy indexing
                        X_train_fold = X_train_features[train_idx]
                        X_val_fold = X_train_features[val_idx]
                        y_train_fold = y_train[train_idx]
                        y_val_fold = y_train[val_idx]

                        # Train model
                        pipeline.fit(X_train_fold, y_train_fold)

                        # Get scores using weighted F1
                        train_score = f1_score(
                            y_train_fold,
                            pipeline.predict(X_train_fold),
                            average="weighted",
                        )
                        val_score = f1_score(
                            y_val_fold, pipeline.predict(X_val_fold), average="weighted"
                        )

                        train_scores.append(train_score)
                        valid_scores.append(val_score)

                        self.logger.info(
                            f"Fold {fold+1}/{num_epochs} - "
                            f"Train: {train_score:.4f}, Val: {val_score:.4f}"
                        )

                        # Add early stopping check
                        if val_score > best_score + min_delta:
                            best_score = val_score
                            patience_count = 0
                        else:
                            patience_count += 1

                        if patience_count >= patience:
                            self.logger.info(f"Early stopping triggered at fold {fold+1}")
                            break

                    # Store training history
                    training_history[name] = {
                        "train_scores": train_scores,
                        "valid_scores": valid_scores,
                        "epochs": range(1, num_epochs + 1),
                    }

                    # Final training on full dataset
                    pipeline.fit(X_train_features, y_train)
                    best_models[name] = pipeline
                    best_metrics[name] = {
                        "best_score": np.max(valid_scores),
                        "training_time": (datetime.now() - start_time).total_seconds(),
                        "train_scores": train_scores,
                        "valid_scores": valid_scores,
                        "epochs": range(1, num_epochs + 1),
                    }

                    self.logger.info(
                        f"{name} Final Scores:\n"
                        f"Best validation score: {np.max(valid_scores):.4f}\n"
                        f"Final training score: {train_scores[-1]:.4f}"
                    )

                except Exception as e:
                    self.logger.error(f"Error training {name}: {str(e)}")
                    continue

            if not best_models:
                raise ValueError("No models were successfully trained")

            # Save final model
            final_metrics = {
                "models": best_metrics,
                "total_time": (datetime.now() - start_time).total_seconds(),
                "training_history": training_history,  # Include full training history
                "feature_importance": getattr(
                    best_models["rf"], "feature_importances_", None
                ),
                "validation_scores": {
                    "precision": self.scoring_config["precision_zero_division"]
                },
            }
            self.save_final_model(best_models, final_metrics)

            return best_models

        except Exception as e:
            self.logger.error(f"Training failed: {str(e)}")
            return None

    def list_checkpoints(self):
        """List all available checkpoints with better metrics handling"""
        checkpoints = []
        try:
            for file in os.listdir(self.checkpoint_dir):
                if file.startswith(f"{self.language}_checkpoint"):
                    checkpoint_path = os.path.join(self.checkpoint_dir, file)
                    info = joblib.load(checkpoint_path)
                    metrics_value = None

                    # Safely extract metrics
                    if "metrics" in info:
                        if isinstance(info["metrics"], dict):
                            metrics_value = info["metrics"].get("best_score")
                        else:
                            metrics_value = str(info["metrics"])

                    checkpoints.append(
                        {
                            "filename": file,
                            "timestamp": info.get("timestamp", "Unknown"),
                            "epoch": info.get("epoch", "Unknown"),
                            "metrics": metrics_value,
                        }
                    )
            return sorted(checkpoints, key=lambda x: x["timestamp"], reverse=True)
        except Exception as e:
            self.logger.error(f"Error listing checkpoints: {str(e)}")
            return []

    def restore_from_checkpoint(self, checkpoint_name=None):
        """Restore model from checkpoint"""
        try:
            if checkpoint_name is None:
                # Get latest checkpoint
                checkpoints = sorted(
                    [
                        f
                        for f in os.listdir(self.checkpoint_dir)
                        if f.startswith(f"{self.language}_checkpoint")
                    ]
                )
                if not checkpoints:
                    raise ValueError("No checkpoints found")
                checkpoint_name = checkpoints[-1]

            checkpoint_path = os.path.join(self.checkpoint_dir, checkpoint_name)
            if not os.path.exists(checkpoint_path):
                raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")

            checkpoint = joblib.load(checkpoint_path)
            self.logger.info(f"Restored model from checkpoint: {checkpoint_name}")
            return checkpoint["model_state"], checkpoint["metrics"]

        except Exception as e:
            self.logger.error(f"Error restoring checkpoint: {str(e)}")
            return None, None

    def optimize_hyperparameters(self, X_train=None, y_train=None):
        """Optimize hyperparameters using cross-validation"""
        self.logger.info("Starting hyperparameter optimization...")

        try:
            # Use stored data if not provided
            if X_train is None or y_train is None:
                # Load last checkpoint to get data
                checkpoints = self.list_checkpoints()
                if not checkpoints:
                    raise ValueError("No checkpoints found and no data provided")
                checkpoint = joblib.load(
                    os.path.join(self.checkpoint_dir, checkpoints[0]["filename"])
                )
                X_train = checkpoint.get("X_train")
                y_train = checkpoint.get("y_train")

            if X_train is None or y_train is None:
                raise ValueError("No training data available")

            # Extract features
            if self.feature_extractor is None:
                from src.features.feature_engineering import FeatureExtractor

                self.feature_extractor = FeatureExtractor(self.language, self.config)

            X_train_features = self.feature_extractor.extract_features(X_train)

            # Define expanded parameter grid for optimization
            expanded_param_grid = {
                "rf__n_estimators": [300, 500, 1000],
                "rf__max_depth": [30, 50, 100],
                "rf__min_samples_split": [2, 5, 10],
                "rf__min_samples_leaf": [1, 2, 4],
                "rf__max_features": ["sqrt", "log2", None],
                "svm__C": [0.1, 1.0, 10.0],
                "svm__tol": [1e-4, 1e-5],
                "svm__max_iter": [3000, 5000],
                "nb__alpha": [0.01, 0.1, 0.5, 1.0],
                "nb__fit_prior": [True, False],
                "feature_selection__k": [300, 500, 1000],
            }

            # Configure cross-validation
            cv = StratifiedKFold(
                n_splits=self.config.MODEL_TRAINING_CONFIG["cv_folds"],
                shuffle=True,
                random_state=42,
            )

            # Initialize models
            models = self.create_ensemble_model()
            best_params = {}

            # Optimize each model separately
            for name, pipeline in models:
                self.logger.info(f"\nOptimizing {name} model...")

                # Get relevant parameters for this model
                model_params = {
                    k: v for k, v in expanded_param_grid.items() if k.startswith(name)
                }

                # Configure scoring
                scorers = {
                    "f1": make_scorer(f1_score, average="weighted", zero_division=1),
                    "precision": make_scorer(
                        precision_score, average="weighted", zero_division=1
                    ),
                    "recall": make_scorer(
                        recall_score, average="weighted", zero_division=1
                    ),
                    "balanced_accuracy": make_scorer(balanced_accuracy_score),
                }

                # Perform grid search
                grid_search = GridSearchCV(
                    pipeline,
                    param_grid=model_params,
                    cv=cv,
                    scoring=scorers,
                    refit="balanced_accuracy",
                    n_jobs=-1,
                    verbose=1,
                )

                # Fit with sample weights if applicable
                sample_weights = compute_sample_weight("balanced", y_train)
                fit_params = {}
                if name in ["rf", "svm"]:
                    fit_params = {f"{name}__sample_weight": sample_weights}

                grid_search.fit(X_train_features, y_train, **fit_params)

                # Store best parameters
                best_params[name] = {
                    "params": grid_search.best_params_,
                    "score": grid_search.best_score_,
                }

                self.logger.info(f"Best {name} parameters: {grid_search.best_params_}")
                self.logger.info(f"Best {name} score: {grid_search.best_score_:.4f}")

            # Save optimized parameters
            optimization_path = os.path.join(
                self.config.DATA_DIR,
                "optimization",
                f"{self.language}_optimized_params.json",
            )
            os.makedirs(os.path.dirname(optimization_path), exist_ok=True)

            with open(optimization_path, "w") as f:
                import json

                json.dump(best_params, f, indent=4)

            self.logger.info(f"Saved optimized parameters to {optimization_path}")
            return best_params

        except Exception as e:
            self.logger.error(f"Hyperparameter optimization failed: {str(e)}")
            return None

    def continue_training(self, X_train, y_train, checkpoint_name=None, num_epochs=5):
        """Continue training from a checkpoint"""
        self.logger.info("Continuing training from checkpoint...")
        try:
            # Restore model state from checkpoint
            model, metrics = self.restore_from_checkpoint(checkpoint_name)
            if model is None:
                raise ValueError("Could not restore model from checkpoint")

            # Get last epoch
            start_epoch = metrics.get("epoch", 0) if metrics else 0
            
            # Extract features if not already done
            if self.feature_extractor is None:
                from src.features.feature_engineering import FeatureExtractor
                self.feature_extractor = FeatureExtractor(self.language, self.config)
            
            X_train_features = self.feature_extractor.extract_features(X_train)

            # Continue training for each model in ensemble
            for name, pipeline in model.items():
                self.logger.info(f"\nContinuing training for {name}...")
                
                # Setup validation
                cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
                train_scores = metrics.get("models", {}).get(name, {}).get("train_scores", [])
                valid_scores = metrics.get("models", {}).get(name, {}).get("valid_scores", [])
                
                # Training loop
                for epoch in range(start_epoch + 1, start_epoch + num_epochs + 1):
                    epoch_train_scores = []
                    epoch_valid_scores = []
                    
                    for fold, (train_idx, val_idx) in enumerate(cv.split(X_train_features, y_train)):
                        # Split data
                        X_train_fold = X_train_features[train_idx]
                        X_val_fold = X_train_features[val_idx]
                        y_train_fold = y_train[train_idx]
                        y_val_fold = y_train[val_idx]

                        # Calculate class weights
                        sample_weights = compute_sample_weight("balanced", y_train_fold)
                        
                        # Partial fit for the model
                        if name in ["rf", "svm"]:
                            pipeline.fit(X_train_fold, y_train_fold, 
                                      **{f"{name}__sample_weight": sample_weights})
                        else:
                            pipeline.fit(X_train_fold, y_train_fold)

                        # Get scores
                        train_score = f1_score(y_train_fold, 
                                             pipeline.predict(X_train_fold), 
                                             average="weighted")
                        val_score = f1_score(y_val_fold, 
                                           pipeline.predict(X_val_fold), 
                                           average="weighted")
                        
                        epoch_train_scores.append(train_score)
                        epoch_valid_scores.append(val_score)

                    # Average scores for epoch
                    avg_train = np.mean(epoch_train_scores)
                    avg_valid = np.mean(epoch_valid_scores)
                    train_scores.append(avg_train)
                    valid_scores.append(avg_valid)

                    self.logger.info(
                        f"Epoch {epoch} - Train: {avg_train:.4f}, Val: {avg_valid:.4f}"
                    )

                    # Update model metrics
                    metrics["models"][name].update({
                        "train_scores": train_scores,
                        "valid_scores": valid_scores,
                        "last_epoch": epoch
                    })

                    # Save checkpoint
                    if epoch % self.config.MODEL_SAVE_CONFIG["checkpoint_frequency"] == 0:
                        self.save_checkpoint(model, metrics, epoch)

            # Final save
            self.save_checkpoint(model, metrics, start_epoch + num_epochs)
            self.save_final_model(model, metrics)
            
            return model, metrics

        except Exception as e:
            self.logger.error(f"Continue training failed: {str(e)}")
            return None, None

================
File: src/utils/augmentation.py
================
import random
import re
from typing import List, Dict


class TextAugmenter:
    def __init__(self):
        self.common_typos = {
            "a": "aq",
            "b": "vb",
            "c": "xc",
            "d": "sd",
            "e": "er",
            "h": "gh",
            "i": "ui",
            "k": "jk",
            "m": "nm",
            "n": "bn",
            "o": "io",
            "p": "op",
            "r": "er",
            "s": "as",
            "t": "rt",
            "u": "yu",
            "v": "cv",
            "w": "qw",
            "y": "ty",
        }

        self.vi_variations = {
            "vâng": ["vang", "vânggg", "vâg", "uk"],
            "không": ["khong", "hông", "ko", "k", "khg"],
            "rất": ["rat", "rất là", "rất chi là"],
            "tốt": ["tot", "tốt", "tuyệt"],
            "được": ["dc", "đc", "được"],
            "biết": ["bít", "bik", "biết"],
            "thích": ["thik", "thích", "thíchhh"],
            "quá": ["qá", "quá trời", "quớ"],
        }

        self.en_variations = {
            "yes": ["yep", "yeah", "yup", "yas"],
            "no": ["nope", "nah", "noway"],
            "very": ["rlly", "rly", "super", "v"],
            "good": ["gud", "noice", "gr8"],
            "thanks": ["thx", "tks", "ty"],
            "please": ["pls", "plz", "plss"],
            "love": ["luv", "luvv", "lovee"],
            "cool": ["kewl", "noice", "lit"],
        }

        self.emojis = {
            "positive": ["😊", "😄", "👍", "❤️", "🥰", "💯", "✨"],
            "negative": ["😢", "😞", "👎", "😠", "😕", "💔", "😫"],
            "neutral": ["🤔", "😐", "💭", "👀", "🆗", "💁"],
        }

        from src.utils.templates import CommentTemplates

        self.templates = CommentTemplates()

    def _apply_typos(self, word: str) -> str:
        if len(word) < 4 or random.random() > 0.3:  # 30% chance for typo
            return word

        pos = random.randint(1, len(word) - 1)
        chars = list(word)
        if chars[pos] in self.common_typos:
            chars[pos] = random.choice(list(self.common_typos[chars[pos]]))
        return "".join(chars)

    def _get_variation(self, word: str, language: str) -> str:
        variations = self.vi_variations if language == "vi" else self.en_variations
        return variations.get(word.lower(), [word])[0]

    def _add_emojis(self, text: str, sentiment: str = "neutral") -> str:
        if random.random() > 0.3:  # 30% chance to add emoji
            return text
        emoji = random.choice(self.emojis[sentiment])
        position = random.choice(["prefix", "suffix"])
        return f"{emoji} {text}" if position == "prefix" else f"{text} {emoji}"

    def humanize_text(
        self, text: str, language: str = "vi", sentiment: str = "neutral"
    ) -> str:
        """Create more natural text variations"""
        words = text.split()
        result = []

        for word in words:
            # Apply variations
            if random.random() < 0.3:  # 30% chance for informal variations
                word = self._get_variation(word, language)
            elif random.random() < 0.2:  # 20% chance for typos
                word = self._apply_typos(word)

            # Random repeated letters (excitement/emphasis)
            if random.random() < 0.1:  # 10% chance
                if word[-1] in "aeiouydg":
                    word = word + word[-1] * random.randint(1, 3)

            result.append(word)

        text = " ".join(result)

        # Add emojis based on sentiment
        text = self._add_emojis(text, sentiment)

        # Random punctuation variations
        if random.random() < 0.2:  # 20% chance
            text = text + random.choice(["!!!", "..", "?!", "!"])

        return text

    def _tokenize(self, text: str) -> List[str]:
        """Simple tokenization that works for both English and Vietnamese"""
        return text.split()

    def synonym_replacement(self, text: str) -> str:
        """Simple word variation by character substitution"""
        words = self._tokenize(text)
        if len(words) < 2:
            return text

        n = max(1, int(len(words) * 0.1))  # Replace 10% of words
        indexes = random.sample(range(len(words)), min(n, len(words)))

        for i in indexes:
            word = words[i]
            if len(word) > 3:
                # Simple character substitution instead of using WordNet
                pos = random.randint(1, len(word) - 2)
                chars = list(word)
                chars[pos] = random.choice(
                    [c for c in "abcdefghijklmnopqrstuvwxyz" if c != chars[pos]]
                )
                words[i] = "".join(chars)

        return " ".join(words)

    def random_swap(self, text: str) -> str:
        words = text.split()
        if len(words) < 2:
            return text

        n = max(1, int(len(words) * 0.1))  # Swap 10% of words
        for _ in range(n):
            idx1, idx2 = random.sample(range(len(words)), 2)
            words[idx1], words[idx2] = words[idx2], words[idx1]

        return " ".join(words)

    def random_deletion(self, text: str) -> str:
        words = text.split()
        if len(words) < 2:
            return text

        keep_prob = 0.9  # Keep 90% of words
        words = [word for word in words if random.random() < keep_prob]

        return " ".join(words) if words else text

    def random_insertion(self, text: str) -> str:
        words = text.split()
        n = max(1, int(len(words) * 0.1))  # Insert 10% new words

        for _ in range(n):
            if not words:
                break
            # Insert a random word from the text at a random position
            word_to_insert = random.choice(words)
            insert_pos = random.randint(0, len(words))
            words.insert(insert_pos, word_to_insert)

        return " ".join(words)

    def _add_expression(
        self, comment: str, sentiment: str, language: str = "vi"
    ) -> str:
        """Thêm biểu thức cảm xúc vào bình luận"""
        if random.random() > 0.3:  # 30% chance
            return comment

        expressions = (
            self.templates.vi_expressions
            if language == "vi"
            else self.templates.en_expressions
        )
        expr = random.choice(expressions[sentiment])

        position = random.choice(["prefix", "suffix"])
        if position == "prefix":
            return f"{expr}, {comment.lower()}"
        return f"{comment}, {expr}"

    def _apply_internet_slang(self, text: str, language: str) -> str:
        """Apply internet slang to text"""
        if random.random() > 0.4:  # 40% chance to use internet slang
            return text

        words = text.split()
        result = []

        for word in words:
            if random.random() < 0.3:  # 30% chance per word
                slang_word = self.templates.get_internet_term(word, language)
                result.append(slang_word)
            else:
                result.append(word)

        return " ".join(result)

    def _randomly_combine_expressions(self, text: str, sentiment: str, language: str) -> str:
        """Randomly combine multiple expressions and slang terms"""
        if random.random() > 0.3:
            return text
            
        num_expressions = random.randint(1, 3)  # Add 1-3 expressions
        expressions = []
        
        for _ in range(num_expressions):
            expr_type = random.choice(['slang', 'expression', 'internet_term'])
            if expr_type == 'slang':
                category = random.choice(list(self.templates.vi_slangs[sentiment].keys()))
                expr = self.templates.get_random_slang(sentiment, category, language)
            elif expr_type == 'expression':
                expr = random.choice(self.templates.vi_expressions[sentiment])
            else:
                word = random.choice(list(self.templates.vi_slangs['internet_terms'].keys()))
                expr = self.templates.get_internet_term(word, language)
                
            if expr:
                expressions.append(expr)
                
        if expressions:
            position = random.choice(['prefix', 'both', 'suffix'])
            if position == 'prefix':
                return f"{' '.join(expressions)} {text}"
            elif position == 'suffix':
                return f"{text} {' '.join(expressions)}"
            else:
                return f"{expressions[0]} {text} {' '.join(expressions[1:])}"
        return text

    def _add_random_punctuation(self, text: str, sentiment: str) -> str:
        """Add random punctuation based on sentiment"""
        if random.random() > 0.4:
            return text
            
        punct_patterns = {
            'positive': ['!!!', '!?!', '...!!!', '!!! <3'],
            'negative': ['...', '!?', '(?)', '>.<'],
            'neutral': ['...', '.', '...?', '(?!)']
        }
        
        num_puncts = random.randint(1, 3)
        puncts = [random.choice(punct_patterns[sentiment]) for _ in range(num_puncts)]
        return f"{text}{''.join(puncts)}"

    def generate_realistic_comment(
        self, topic: str, sentiment: str, language: str = "vi"
    ) -> str:
        """Generate a realistic comment for a given topic and sentiment"""
        templates = (
            self.templates.vi_templates
            if language == "vi"
            else self.templates.en_templates
        )
        fillers = (
            self.templates.vi_fillers if language == "vi" else self.templates.en_fillers
        )

        if topic not in templates:
            topic = list(templates.keys())[0]  # default to first topic

        topic_templates = templates[topic][sentiment]
        template = random.choice(topic_templates)

        # Generate fillers for the template
        filled_comment = template
        for placeholder in re.findall(r"\{(\w+)\}", template):
            if placeholder in fillers:
                filler = random.choice(fillers[placeholder])
                filled_comment = filled_comment.replace(f"{{{placeholder}}}", filler)
            else:
                # Generic fillers for undefined placeholders
                filled_comment = filled_comment.replace(f"{{{placeholder}}}", "")

        # Add variations and humanization
        filled_comment = self.humanize_text(filled_comment, language, sentiment)

        # Add slang and internet speech variations
        if random.random() < 0.4:  # 40% chance to use slang
            filled_comment = self._apply_internet_slang(filled_comment, language)

            # Add random slang intensifier
            if random.random() < 0.3:
                intensifier = self.templates.get_random_intensifier(language)
                filled_comment = f"{intensifier} {filled_comment}"

        # Add expressions and emojis
        filled_comment = self._add_expression(filled_comment, sentiment, language)
        filled_comment = self._add_emojis(filled_comment, sentiment)

        # Random variations in punctuation and emphasis
        if random.random() < 0.3:
            filled_comment = filled_comment + random.choice(["!!!", "..", "?!", "!!"])

        # Randomize comment structure
        if random.random() < 0.3:
            # Add random topic-specific context
            contexts = {
                'product_review': ['Mới mua', 'Dùng được 1 tuần', 'Đặt trên shopee'],
                'food_review': ['Ghé quán hôm qua', 'Đi ăn với bạn', 'Oder mang về'],
                'movie_review': ['Xem buổi chiều', 'Ra rạp coi', 'Xem trên Netflix'],
                'service_review': ['Làm dịch vụ hôm qua', 'Mới trải nghiệm', 'Book lịch']
            }
            if topic in contexts:
                context = random.choice(contexts[topic])
                filled_comment = f"{context}, {filled_comment}"

        # Add random expressions and slang combinations
        filled_comment = self._randomly_combine_expressions(filled_comment, sentiment, language)
        
        # Add varied punctuation
        filled_comment = self._add_random_punctuation(filled_comment, sentiment)

        return filled_comment

    def generate_topic_comment(self, topic: str, sentiment: str, language: str = 'vi') -> str:
        """Generate a comment for a specific topic and sentiment"""
        if not topic.endswith('_review'):
            topic = f"{topic}_review"
            
        return self.generate_realistic_comment(topic, sentiment, language)

    def generate_topic_comments(self, topic: str, count: int = 10, language: str = 'vi', sentiment: int = None) -> list:
        """Generate comments for a specific topic with optional sentiment"""
        comments = []
        sentiment_map = {0: 'negative', 1: 'neutral', 2: 'positive'}
        
        for _ in range(count):
            # If sentiment is provided, use it, otherwise randomly choose
            if sentiment is not None:
                sent = sentiment_map[sentiment]
            else:
                sent = random.choice(['negative', 'neutral', 'positive'])
                
            text = self.generate_topic_comment(topic, sent, language)
            label = {'negative': 0, 'neutral': 1, 'positive': 2}[sent]
            
            comments.append({
                'text': text,
                'label': label
            })
            
        return comments

================
File: src/utils/evaluation.py
================
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns


class ModelEvaluator:
    """
    Model evaluation utility with visualization capabilities.
    
    Attributes:
        language (str): Language code for the model being evaluated
    """
    def __init__(self, language: str):
        self.language = language

    def evaluate(self, y_true, y_pred, y_prob=None):
        """
        Evaluates model performance with multiple metrics.
        
        Args:
            y_true: True labels
            y_pred: Predicted labels
            y_prob: Prediction probabilities (optional)
            
        Returns:
            dict: Dictionary containing evaluation metrics and plots
        """
        results = {}
        
        # Detailed metrics
        report = classification_report(y_true, y_pred, output_dict=True)
        results["classification_report"] = classification_report(y_true, y_pred)
        results["metrics"] = {
            "accuracy": report['accuracy'],
            "macro_f1": report['macro avg']['f1-score'],
            "weighted_f1": report['weighted avg']['f1-score']
        }
        
        # Plot metrics
        self._plot_metrics_summary(results["metrics"])

        # Basic classification metrics
        results["classification_report"] = classification_report(y_true, y_pred)

        # Confusion matrix
        cm = confusion_matrix(y_true, y_pred)
        self.plot_confusion_matrix(cm)

        if y_prob is not None:
            # ROC curve
            self.plot_roc_curve(y_true, y_prob)

        return results

    def _plot_metrics_summary(self, metrics):
        """Plots a summary of key performance metrics"""
        plt.figure(figsize=(10, 4))
        colors = ['skyblue', 'lightgreen', 'lightcoral']
        
        plt.bar(metrics.keys(), metrics.values(), color=colors)
        plt.title(f'Model Performance Metrics - {self.language.upper()}')
        plt.ylim(0, 1)
        
        for i, v in enumerate(metrics.values()):
            plt.text(i, v + 0.01, f'{v:.3f}', ha='center')
            
        plt.tight_layout()
        plt.show()

    def plot_confusion_matrix(self, cm):
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
        plt.title(f"Confusion Matrix - {self.language.upper()}")
        plt.ylabel("True Label")
        plt.xlabel("Predicted Label")
        plt.show()

    def plot_roc_curve(self, y_true, y_prob):
        from sklearn.metrics import roc_curve, auc

        fpr, tpr, _ = roc_curve(y_true, y_prob[:, 1])
        roc_auc = auc(fpr, tpr)

        plt.figure(figsize=(8, 6))
        plt.plot(
            fpr, tpr, color="darkorange", lw=2, label=f"ROC curve (AUC = {roc_auc:.2f})"
        )
        plt.plot([0, 1], [0, 1], color="navy", lw=2, linestyle="--")
        plt.xlim([0.0, 1.0])
        plt.ylim([0.0, 1.05])
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.title(f"ROC Curve - {self.language.upper()}")
        plt.legend(loc="lower right")
        plt.show()

================
File: src/utils/logger.py
================
import logging
import sys
from logging.handlers import RotatingFileHandler

class Logger:
    def __init__(self, name, log_file='sentiment_analysis.log'):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.INFO)
        
        # Console handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        
        # File handler with utf-8 encoding
        file_handler = RotatingFileHandler(
            log_file, maxBytes=1024*1024, backupCount=5, encoding='utf-8'
        )
        file_handler.setLevel(logging.INFO)
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        
        # Add handlers
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)

================
File: src/utils/menu.py
================
import os
import sys
from typing import List, Dict, Callable
from datetime import datetime, timedelta
from rich.console import Console
from rich.table import Table
from rich.prompt import Prompt, IntPrompt
from rich.panel import Panel


class TerminalMenu:
    def __init__(self, config=None):
        """Initialize TerminalMenu with configuration"""
        from rich.console import Console

        self.console = Console()
        self.config = config  # Store config object
        self.default_data_dir = os.path.join(
            os.path.dirname(
                os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            ),
            "data",
        )
        os.makedirs(self.default_data_dir, exist_ok=True)
        self.menu_options = {
            "1": "Train new model",
            "2": "Analyze text",
            "3": "Evaluate model",
            "4": "Generate training data",
            "5": "View model metrics",
            "6": "Test model",
            "7": "Restore model from checkpoint",
            "8": "Data collection",
            "9": "Data preprocessing",
            "10": "Model optimization",
            "11": "Export results",
            "12": "API Server",
            "13": "Continue Training Model",
            "q": "Quit",
        }

    def clear_screen(self):
        os.system("cls" if os.name == "nt" else "clear")

    def display_header(self):
        self.clear_screen()
        self.console.print(
            Panel(
                "[bold blue]Sentiment Analysis System[/bold blue]\n"
                "[cyan]Vietnamese-English Text Analysis Tool[/cyan]",
                expand=False,
            )
        )

    def display_menu(self) -> str:
        table = Table(show_header=True, header_style="bold magenta")
        table.add_column("Option", style="dim")
        table.add_column("Description")
        table.add_column("Command Example", style="green")

        table.add_row(
            "1", "Train New Model", "python main.py --mode train --language vi"
        )
        table.add_row(
            "2",
            "Analyze Text (Predict)",
            "python main.py --mode predict --language vi --input data.csv --output results.csv",
        )
        table.add_row(
            "3",
            "Evaluate Model",
            "python main.py --mode evaluate --language vi --input test.csv",
        )
        table.add_row(
            "4", "Generate Training Data", "Generate synthetic samples (specify count)"
        )
        table.add_row("5", "View Model Performance", "Display current model metrics")
        table.add_row("6", "Test Model", "Test the model with custom text")
        table.add_row(
            "7", "Restore Model from Checkpoint", "Restore model from saved checkpoint"
        )
        table.add_row("8", "Data Collection", "Collect data from various sources")
        table.add_row("9", "Data Preprocessing", "Clean and prepare collected data")
        table.add_row("10", "Model Optimization", "Tune model parameters")
        table.add_row("11", "Export Results", "Export analysis results and reports")
        table.add_row("12", "API Server", "Start/Stop REST API Server")
        table.add_row("13", "Continue Training Model", "Continue training the model")
        table.add_row("q", "Quit", "Exit the application")

        self.console.print(table)

        choice = Prompt.ask(
            "\n[yellow]Choose an option[/yellow]",
            choices=list(self.menu_options.keys()),
            default="q",
        )
        return choice

    def get_language_choice(self) -> str:
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Language")
        table.add_column("Code")

        table.add_row("Vietnamese", "vi")
        table.add_row("English", "en")

        self.console.print(table)

        return Prompt.ask(
            "\n[yellow]Select language[/yellow]", choices=["vi", "en"], default="vi"
        )

    def get_file_path(self, file_type: str) -> str:
        """Get and validate file path"""
        default_path = os.path.join(self.default_data_dir, f"{file_type}.csv")
        while True:
            path = Prompt.ask(
                f"\n[yellow]Enter {file_type} file path[/yellow]", default=default_path
            )

            # Ensure directory exists
            directory = os.path.dirname(path)
            if directory and not os.path.exists(directory):
                try:
                    os.makedirs(directory)
                except Exception as e:
                    self.console.print(f"[red]Error creating directory: {e}[/red]")
                    continue

            return path

    def get_sample_count(self) -> int:
        """Get the number of samples to generate"""
        while True:
            try:
                count = IntPrompt.ask(
                    "\n[yellow]Enter number of samples to generate[/yellow]",
                    default=1000,
                    show_default=True,
                )
                if 100 <= count <= 50000:
                    return count
                self.console.print(
                    "[red]Please enter a number between 100 and 50000[/red]"
                )
            except ValueError:
                self.console.print("[red]Please enter a valid number[/red]")

    def get_custom_sample_count(self) -> dict:
        """Get custom sample counts for each sentiment category"""
        counts = {}

        self.console.print("\n[cyan]Enter number of samples for each category:[/cyan]")

        categories = {
            "positive": "Tích cực (Positive)",
            "neutral": "Trung tính (Neutral)",
            "negative": "Tiêu cực (Negative)",
        }

        for key, label in categories.items():
            while True:
                try:
                    count = IntPrompt.ask(
                        f"\n[yellow]Số mẫu {label}[/yellow]",
                        default=100,
                        show_default=True,
                    )
                    if 0 <= count <= 10000:
                        counts[key] = count
                        break
                    self.console.print("[red]Vui lòng nhập số từ 0 đến 10000[/red]")
                except ValueError:
                    self.console.print("[red]Vui lòng nhập số hợp lệ[/red]")

        return counts

    def display_progress(self, message: str):
        self.console.print(f"[bold blue]>>> {message}...[/bold blue]")

    def display_result(self, success: bool, message: str):
        style = "green" if success else "red"
        self.console.print(f"[{style}]{message}[/{style}]")

    def wait_for_user(self):
        self.console.print("\n[yellow]Press Enter to continue...[/yellow]")
        input()

    def get_test_text(self):
        """Get test text from user"""
        print("\nEnter text to test (or 'q' to quit):")
        return input("> ").strip()

    def display_sentiment_result(self, text, sentiment, confidence):
        """Display sentiment analysis result"""
        sentiment_map = {0: "Negative", 1: "Neutral", 2: "Positive"}
        print("\nResults:")
        print("-" * 50)
        print(f"Text: {text}")
        print(f"Sentiment: {sentiment_map[sentiment]}")
        print(f"Confidence: {confidence:.2f}")
        print("-" * 50)

    def display_emotion_result(self, text, emotion_result):
        """Display emotion analysis results with proper config access"""
        try:
            self.console.print("\n[bold cyan]Analysis Results:[/bold cyan]")
            self.console.print(f"Text: {text}")

            if emotion_result:
                # Get sentiment label
                sentiment = emotion_result.get("sentiment")
                sentiment_conf = emotion_result.get("sentiment_confidence", 0)

                sentiment_label = (
                    "Tích cực"
                    if sentiment == 2
                    else "Tiêu cực" if sentiment == 0 else "Trung tính"
                )
                self.console.print(f"\nCảm xúc chung: {sentiment_label}")
                self.console.print(f"Độ tin cậy: {sentiment_conf:.2f}")

                # Display detailed emotion
                emotion = emotion_result.get("emotion", "")
                emotion_vi = emotion_result.get("emotion_vi", "")
                emoji = emotion_result.get("emotion_emoji", "")
                emotion_conf = emotion_result.get("emotion_confidence", 0)

                self.console.print(f"\nBiểu cảm chi tiết: {emotion_vi} {emoji}")
                self.console.print(f"Độ tin cậy: {emotion_conf:.2f}")

                # Display emotion scores if available
                if emotion_result.get("emotion_scores"):
                    self.console.print("\nĐiểm số các biểu cảm:")
                    for emotion, score in emotion_result["emotion_scores"].items():
                        if score > 0:
                            self.console.print(f"{emotion}: {score:.2f}")
            else:
                self.console.print("[red]Không thể phân tích cảm xúc[/red]")

        except Exception as e:
            self.console.print(f"[red]Error displaying results: {str(e)}[/red]")

    def display_data_collection_menu(self):
        """Display data collection options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "Collect from Google Play")
        table.add_row("2", "Collect from Shopee")
        table.add_row("3", "Collect from Facebook")
        table.add_row("4", "Import from CSV/Excel")
        table.add_row("5", "Scrape from websites")
        table.add_row("b", "Back to main menu")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select data collection method[/yellow]",
            choices=["1", "2", "3", "4", "5", "b"],
            default="b",
        )

    def display_preprocessing_menu(self):
        """Display preprocessing options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "Clean text data")
        table.add_row("2", "Remove duplicates")
        table.add_row("3", "Balance dataset")
        table.add_row("4", "Filter by criteria")
        table.add_row("5", "Augment data")
        table.add_row("b", "Back to main menu")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select preprocessing action[/yellow]",
            choices=["1", "2", "3", "4", "5", "b"],
            default="b",
        )

    def display_optimization_menu(self):
        """Display model optimization options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "Hyperparameter tuning")
        table.add_row("2", "Feature selection")
        table.add_row("3", "Cross validation")
        table.add_row("4", "Model ensemble")
        table.add_row("5", "Performance analysis")
        table.add_row("b", "Back to main menu")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select optimization method[/yellow]",
            choices=["1", "2", "3", "4", "5", "b"],
            default="b",
        )

    def display_export_menu(self):
        """Display export options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "Export predictions")
        table.add_row("2", "Export model metrics")
        table.add_row("3", "Generate report")
        table.add_row("4", "Export visualizations")
        table.add_row("5", "Export model")
        table.add_row("b", "Back to main menu")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select export option[/yellow]",
            choices=["1", "2", "3", "4", "5", "b"],
            default="b",
        )

    def display_api_menu(self):
        """Display enhanced API server options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "Start API Server")
        table.add_row("2", "Stop API Server")
        table.add_row("3", "View API Status")
        table.add_row("4", "Configure API Settings")
        table.add_row("5", "Test API Endpoints")
        table.add_row("6", "View Server Logs")
        table.add_row("7", "Monitor Metrics")
        table.add_row("8", "Dashboard")
        table.add_row("9", "Export Data")
        table.add_row("b", "Back to main menu")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select API option[/yellow]",
            choices=["1", "2", "3", "4", "5", "6", "7", "8", "9", "b"],
            default="b",
        )

    def display_api_test_menu(self):
        """Display API testing options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "Test single text prediction")
        table.add_row("2", "Test batch prediction")
        table.add_row("3", "Test health check")
        table.add_row("b", "Back to API menu")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select test option[/yellow]",
            choices=["1", "2", "3", "b"],
            default="b",
        )

    def get_api_endpoint(self):
        """Get API endpoint from user"""
        return Prompt.ask(
            "\n[yellow]Enter API endpoint[/yellow]", default="http://localhost:8000"
        )

    def display_api_response(self, response_data):
        """Display API response in a formatted way"""
        if isinstance(response_data, dict):
            self.console.print("\n[cyan]API Response:[/cyan]")
            for key, value in response_data.items():
                self.console.print(f"[green]{key}:[/green] {value}")
        elif isinstance(response_data, list):
            self.console.print("\n[cyan]API Response (Batch):[/cyan]")
            for item in response_data:
                self.console.print("\n[green]Item:[/green]")
                for key, value in item.items():
                    self.console.print(f"[green]{key}:[/green] {value}")

    def display_detailed_test_menu(self):
        """Display detailed testing options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "Test với văn bản đơn lẻ")
        table.add_row("2", "Test với tập dữ liệu mẫu")
        table.add_row("3", "Test hiệu năng (Performance)")
        table.add_row("4", "Test độ chính xác (Accuracy)")
        table.add_row("5", "Test khả năng chịu tải (Load)")
        table.add_row("b", "Quay lại")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Chọn loại test[/yellow]",
            choices=["1", "2", "3", "4", "5", "b"],
            default="b",
        )

    def display_performance_metrics(self, metrics: dict):
        """Display detailed performance metrics"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Metric")
        table.add_column("Value")

        for key, value in metrics.items():
            if isinstance(value, float):
                table.add_row(key, f"{value:.4f}")
            else:
                table.add_row(key, str(value))

        self.console.print("\n[cyan]Performance Metrics:[/cyan]")
        self.console.print(table)

    def get_test_batch_size(self) -> int:
        """Get batch size for testing"""
        while True:
            try:
                size = IntPrompt.ask("\n[yellow]Enter batch size[/yellow]", default=10)
                if 1 <= size <= 1000:
                    return size
                self.console.print(
                    "[red]Please enter a number between 1 and 1000[/red]"
                )
            except ValueError:
                self.console.print("[red]Please enter a valid number[/red]")

    def display_dashboard_menu(self):
        """Display dashboard management options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "View Live Metrics")
        table.add_row("2", "View Historical Data")
        table.add_row("3", "Configure Alerts")
        table.add_row("4", "Export Metrics")
        table.add_row("5", "System Status")
        table.add_row("b", "Back to API menu")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select dashboard option[/yellow]",
            choices=["1", "2", "3", "4", "5", "b"],
            default="b",
        )

    def display_metrics_summary(self, metrics):
        """Display metrics summary in a formatted table"""
        table = Table(show_header=True, header_style="bold magenta")
        table.add_column("Metric")
        table.add_column("Value")

        # Add rows for each metric
        table.add_row("Uptime", metrics["uptime"])
        table.add_row("Total Requests", str(metrics["total_requests"]))
        table.add_row("Total Errors", str(metrics["total_errors"]))
        table.add_row("Memory Usage", f"{metrics['current_memory_usage']}%")
        table.add_row("CPU Usage", f"{metrics['current_cpu_usage']}%")

        # Model status
        for lang, status in metrics["active_models"].items():
            table.add_row(
                f"{lang.upper()} Model",
                "[green]Active[/green]" if status else "[red]Inactive[/red]",
            )

        self.console.print("\n[bold]API Metrics Summary[/bold]")
        self.console.print(table)

    def display_logs_menu(self):
        """Display enhanced log viewing options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "View latest logs")
        table.add_row("2", "View initialization logs")
        table.add_row("3", "View request logs")
        table.add_row("4", "Filter by path")
        table.add_row("5", "Filter by status code")
        table.add_row("6", "Export logs")
        table.add_row("b", "Back")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select option[/yellow]",
            choices=["1", "2", "3", "4", "5", "6", "b"],
            default="b",
        )

    def get_log_lines(self):
        """Get number of log lines to display"""
        return IntPrompt.ask("\n[yellow]Enter number of lines[/yellow]", default=50)

    def get_log_level(self):
        """Get log level to filter"""
        return Prompt.ask(
            "\n[yellow]Enter log level[/yellow]",
            choices=["DEBUG", "INFO", "WARNING", "ERROR", "all"],
            default="all",
        )

    def get_log_time(self):
        """Get time filter for logs"""
        hours = IntPrompt.ask(
            "\n[yellow]Show logs from last N hours[/yellow]", default=24
        )
        time_ago = datetime.now() - timedelta(hours=hours)
        return time_ago.isoformat()

    def display_logs(self, logs: List[str]):
        """Display log entries in a formatted table"""
        table = Table(
            show_header=True,
            header_style="bold magenta",
            wrap=True,
            width=self.console.width,
        )
        table.add_column("Time", style="cyan")
        table.add_column("Level", style="yellow")
        table.add_column("Message")

        for log in logs:
            try:
                parts = log.split(None, 2)
                if len(parts) >= 3:
                    time, level, msg = parts
                    table.add_row(time, level, msg.strip())
            except:
                table.add_row("", "", log.strip())

        self.console.print(table)

    def display_logs_menu(self):
        """Display enhanced log viewing options"""
        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Option")
        table.add_column("Description")

        table.add_row("1", "View Latest Logs")
        table.add_row("2", "View Init Logs")
        table.add_row("3", "View Request Logs")
        table.add_row("4", "Filter by Path")
        table.add_row("5", "Filter by Status Code")
        table.add_row("6", "Filter by Time")
        table.add_row("7", "Filter by Level")
        table.add_row("8", "Search Logs")
        table.add_row("9", "Export Logs")
        table.add_row("b", "Back")

        self.console.print(table)
        return Prompt.ask(
            "\n[yellow]Select option[/yellow]",
            choices=["1", "2", "3", "4", "5", "6", "7", "8", "9", "b"],
            default="b",
        )

    def get_log_filters(self):
        """Get log filter parameters"""
        filters = {}

        # Get log type
        filters["type"] = Prompt.ask(
            "Log type", choices=["all", "init", "request"], default="all"
        )

        # Get path filter if requested
        if Prompt.ask("Filter by path?", choices=["y", "n"], default="n") == "y":
            filters["path"] = self.console.input("Enter path (e.g., /predict): ")

        # Get status code if requested
        if Prompt.ask("Filter by status code?", choices=["y", "n"], default="n") == "y":
            filters["status_code"] = IntPrompt.ask("Enter status code (e.g., 200): ")

        # Get number of lines
        filters["lines"] = IntPrompt.ask("Number of lines to show", default=50)

        return filters

    def format_log_entry(self, log: str) -> str:
        """Format log entry for display"""
        try:
            # Parse log entry parts
            parts = log.split(" ", 3)
            timestamp = parts[0]
            level = parts[1]
            message = parts[2:]

            # Color based on log level
            level_colors = {
                "INFO": "green",
                "WARNING": "yellow",
                "ERROR": "red",
                "DEBUG": "blue",
            }
            color = level_colors.get(level.strip("[]"), "white")

            # Format with color
            return f"[cyan]{timestamp}[/cyan] [{color}]{level}[/{color}] {''.join(message)}"
        except:
            return log

    def display_filtered_logs(self, logs: List[str], filters: dict):
        """Display filtered logs with formatting"""
        if not logs:
            self.console.print("[yellow]No logs found matching filters[/yellow]")
            return

        # Show active filters
        self.console.print("\n[bold cyan]Active Filters:[/bold cyan]")
        for key, value in filters.items():
            if value is not None and value != "all":
                self.console.print(f"[green]{key}:[/green] {value}")

        # Show logs
        self.console.print("\n[bold cyan]Log Entries:[/bold cyan]")
        for log in logs:
            self.console.print(self.format_log_entry(log))

    def get_log_search_params(self):
        """Get log search parameters"""
        params = {}
        params["keyword"] = self.console.input(
            "[yellow]Enter search keyword: [/yellow]"
        )

        if Prompt.ask("Add date filter?", choices=["y", "n"], default="n") == "y":
            params["from_date"] = self.console.input(
                "[yellow]From date (YYYY-MM-DD): [/yellow]"
            )
            params["to_date"] = self.console.input(
                "[yellow]To date (YYYY-MM-DD): [/yellow]"
            )

        if Prompt.ask("Add more filters?", choices=["y", "n"], default="n") == "y":
            params["level"] = Prompt.ask(
                "Log level",
                choices=["ERROR", "WARNING", "INFO", "DEBUG", "all"],
                default="all",
            )
            params["path"] = self.console.input(
                "[yellow]Filter by path (optional): [/yellow]"
            )

        return params

    def get_metrics_filter(self):
        """Get metrics filter parameters"""
        filters = {}

        # Time range
        filters["time_range"] = Prompt.ask(
            "Time range", choices=["1h", "6h", "24h", "7d", "30d"], default="24h"
        )

        # Metrics type
        filters["type"] = Prompt.ask(
            "Metrics type",
            choices=["performance", "errors", "models", "all"],
            default="all",
        )

        # Aggregation
        if Prompt.ask("Add aggregation?", choices=["y", "n"], default="n") == "y":
            filters["aggregation"] = Prompt.ask(
                "Aggregation period", choices=["1min", "5min", "1h", "1d"], default="1h"
            )

        return filters

    def display_metrics_summary(self, metrics: dict):
        """Display metrics summary"""
        if not metrics:
            self.console.print("[yellow]No metrics data available[/yellow]")
            return

        table = Table(show_header=True, header_style="bold cyan")
        table.add_column("Metric")
        table.add_column("Value")

        for key, value in metrics.items():
            if isinstance(value, float):
                formatted_value = f"{value:.2f}"
            else:
                formatted_value = str(value)

            # Add color formatting based on thresholds
            if "error" in key.lower():
                color = "red" if value > 0 else "green"
                formatted_value = f"[{color}]{formatted_value}[/{color}]"
            elif "usage" in key.lower():
                if value > 90:
                    formatted_value = f"[red]{formatted_value}%[/red]"
                elif value > 70:
                    formatted_value = f"[yellow]{formatted_value}%[/yellow]"
                else:
                    formatted_value = f"[green]{formatted_value}%[/green]"

            table.add_row(key, formatted_value)

        self.console.print(table)


def get_more_test_samples():
    """Get additional test samples"""
    return [
        ("Sản phẩm rất chất lượng, đóng gói cẩn thận", 2),
        ("Giao hàng chậm, thái độ phục vụ kém", 0),
        ("Hàng tạm được, giá hơi cao", 1),
        ("Tuyệt vời, sẽ ủng hộ shop dài dài", 2),
        ("Thất vọng về chất lượng sản phẩm", 0),
        ("Hàng đúng như mô tả", 1),
    ]


def get_dashboard_config():
    """Get dashboard configuration options"""
    config = {}
    config["update_interval"] = IntPrompt.ask("Update interval (seconds)", default=5)
    config["chart_history"] = IntPrompt.ask("Number of data points to show", default=50)
    config["alert_threshold"] = IntPrompt.ask(
        "Error rate alert threshold (%)", default=10
    )
    return config


def get_log_export_format():
    """Get log export format"""
    return Prompt.ask("Export format", choices=["txt", "json", "csv"], default="txt")


# ...existing code...

================
File: src/utils/metrics_store.py
================
import os
import json
import time
from datetime import datetime, timedelta
from collections import deque
from threading import Lock
import atexit
from typing import Dict, Any

import psutil
from src.utils.server_utils import ConnectionManager
from src.utils.logger import Logger
import collections


def _convert_deque_to_list(obj):
    """Recursively convert deque objects to lists in the given object."""
    if isinstance(obj, collections.deque):
        return list(obj)
    elif isinstance(obj, dict):
        return {k: _convert_deque_to_list(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [_convert_deque_to_list(v) for v in obj]
    else:
        return obj


class MetricsStore:
    _instance = None
    _lock = Lock()

    def __new__(cls):
        with cls._lock:
            if cls._instance is None:
                cls._instance = super(MetricsStore, cls).__new__(cls)
                cls._instance._initialized = False
            return cls._instance

    def __init__(self):
        if self._initialized:
            return

        self.logger = Logger(__name__).logger
        self._data = {
            "requests": deque(maxlen=100),
            "response_times": deque(maxlen=100),
            "errors": deque(maxlen=100),
            "start_time": datetime.now().isoformat(),
            "total_requests": 0,
            "total_errors": 0,
            "model_performance": {
                "vi": {
                    "loading_time": 0.0,
                    "inference_times": deque(maxlen=1000),
                    "accuracy": 0.0,
                    "precision": 0.0,
                    "recall": 0.0,
                },
                "en": {
                    "loading_time": 0.0,
                    "inference_times": deque(maxlen=1000),
                    "accuracy": 0.0,
                    "precision": 0.0,
                    "recall": 0.0,
                },
            },
        }
        self._file_path = "metrics.json"
        self._lock = Lock()
        self._initialized = True
        self._load_metrics()
        atexit.register(self._save_metrics)
        self.requests = deque(maxlen=1000)
        self.response_times = deque(maxlen=1000)
        self.errors = deque(maxlen=1000)
        self.total_requests = 0
        self.total_errors = 0
        self.start_time = datetime.now()
        self.model_loading_times = {"vi": [], "en": []}
        self.inference_times = {"vi": [], "en": []}
        self.accuracy = {"vi": 0.0, "en": 0.0}
        self.precision = {"vi": 0.0, "en": 0.0}
        self.recall = {"vi": 0.0, "en": 0.0}

        self._metrics_update_interval = 1.0  # Update interval in seconds
        self._last_update = time.time()
        self._metrics_lock = Lock()

    def _load_metrics(self):
        """Load metrics from file if exists"""
        try:
            if os.path.exists(self._file_path):
                with open(self._file_path, "r") as f:
                    data = json.load(f)
                    # Convert lists back to deques
                    for key in ["requests", "response_times", "errors"]:
                        self._data[key] = deque(data[key], maxlen=100)
                    self._data["total_requests"] = data["total_requests"]
                    self._data["total_errors"] = data["total_errors"]
                    self._data["start_time"] = data["start_time"]
                    self._data["model_performance"] = data.get(
                        "model_performance", self._data["model_performance"]
                    )
        except json.JSONDecodeError as e:
            self.logger.error(f"Error loading metrics: {e}")
            # Reset metrics to default state
            self.requests = deque(maxlen=1000)
            self.response_times = deque(maxlen=1000)
            self.errors = deque(maxlen=1000)
            self.total_requests = 0
            self.total_errors = 0
            self.start_time = datetime.now()
        except Exception as e:
            self.logger.error(f"Unexpected error loading metrics: {e}")
            # Reset metrics to default state
            self.requests = deque(maxlen=1000)
            self.response_times = deque(maxlen=1000)
            self.errors = deque(maxlen=1000)
            self.total_requests = 0
            self.total_errors = 0
            self.start_time = datetime.now()

    def _save_metrics(self):
        """Save metrics to file"""
        try:
            metrics_to_save = _convert_deque_to_list(self._data)
            with open(self._file_path, "w") as f:
                json.dump(metrics_to_save, f)
        except Exception as e:
            self.logger.error(f"Error saving metrics: {e}")

    def update_metrics(self, processing_time, is_error=False):
        """Update metrics with thread safety"""
        with self._lock:
            self._data["total_requests"] += 1
            self._data["requests"].append(datetime.now().isoformat())
            self._data["response_times"].append(processing_time)

            if is_error:
                self._data["total_errors"] += 1
                self._data["errors"].append(datetime.now().isoformat())

            # Periodically save metrics
            if self._data["total_requests"] % 100 == 0:
                self._save_metrics()
        self.requests.append(datetime.now())
        self.response_times.append(processing_time)
        if is_error:
            self.errors.append(datetime.now())
            self.total_errors += 1
        self.total_requests += 1

    def get_metrics(self):
        """Get current metrics"""
        with self._lock:
            return {
                "total_requests": self._data["total_requests"],
                "total_errors": self._data["total_errors"],
                "recent_requests": len(self._data["requests"]),
                "avg_response_time": (
                    sum(self._data["response_times"])
                    / len(self._data["response_times"])
                    if self._data["response_times"]
                    else 0
                ),
                "start_time": self._data["start_time"],
            }
        return {
            "total_requests": self.total_requests,
            "total_errors": self.total_errors,
            "requests_last_period": len(self.requests),
            "average_response_time": (
                sum(self.response_times) / len(self.response_times)
                if self.response_times
                else 0
            ),
            "error_rate": (
                (self.total_errors / self.total_requests) * 100
                if self.total_requests
                else 0
            ),
        }

    def clear_metrics(self):
        """Clear all metrics"""
        with self._lock:
            self._data["requests"].clear()
            self._data["response_times"].clear()
            self._data["errors"].clear()
            self._data["total_requests"] = 0
            self._data["total_errors"] = 0
            self._data["start_time"] = datetime.now().isoformat()
            self._save_metrics()

    def clear_all(self):
        """Clear all metrics and reinitialize"""
        with self._lock:
            self._data = {
                "requests": deque(maxlen=100),
                "response_times": deque(maxlen=100),
                "errors": deque(maxlen=100),
                "start_time": datetime.now().isoformat(),
                "total_requests": 0,
                "total_errors": 0,
                "model_performance": {
                    "vi": {
                        "loading_time": 0.0,
                        "inference_times": deque(maxlen=1000),
                        "accuracy": 0.0,
                        "precision": 0.0,
                        "recall": 0.0,
                    },
                    "en": {
                        "loading_time": 0.0,
                        "inference_times": deque(maxlen=1000),
                        "accuracy": 0.0,
                        "precision": 0.0,
                        "recall": 0.0,
                    },
                },
            }
            self._save_metrics()
        self.requests.clear()
        self.response_times.clear()
        self.errors.clear()
        self.total_requests = 0
        self.total_errors = 0
        self.model_loading_times = {"vi": [], "en": []}
        self.inference_times = {"vi": [], "en": []}
        self.accuracy = {"vi": 0.0, "en": 0.0}
        self.precision = {"vi": 0.0, "en": 0.0}
        self.recall = {"vi": 0.0, "en": 0.0}
        self.start_time = datetime.now()
        self.logger.info("All metrics have been cleared.")

    def update_model_loading_time(self, language: str, loading_time: float):
        """Update model loading time for a specific language."""
        if language in self.model_loading_times:
            self.model_loading_times[language].append(loading_time)
            self.logger.debug(f"Model loading time for {language}: {loading_time}s")
        else:
            self.logger.warning(
                f"Attempted to update loading time for unsupported language: {language}"
            )

    def update_inference_time(self, language: str, inference_time: float):
        """Update inference time for a specific language."""
        if language in self.inference_times:
            self.inference_times[language].append(inference_time)
            self.logger.debug(f"Inference time for {language}: {inference_time}s")
        else:
            self.logger.warning(
                f"Attempted to update inference time for unsupported language: {language}"
            )

    def update_ml_metrics(
        self,
        language: str,
        accuracy_score: float,
        precision_score: float,
        recall_score: float,
    ):
        """Update ML performance metrics for a specific language."""
        if language in self.accuracy:
            self.accuracy[language] = accuracy_score
            self.precision[language] = precision_score
            self.recall[language] = recall_score
            self.logger.debug(
                f"ML Metrics for {language} - Accuracy: {accuracy_score}, Precision: {precision_score}, Recall: {recall_score}"
            )
        else:
            self.logger.warning(
                f"Attempted to update ML metrics for unsupported language: {language}"
            )

    def update_processing_time(self, processing_time: float):
        """Update processing time."""
        self.response_times.append(processing_time)
        self.logger.debug(f"Processing time updated: {processing_time}s")

    def increment_total_requests(self):
        """Increment total requests counter."""
        self.total_requests += 1
        self.logger.debug(f"Total requests incremented: {self.total_requests}")

    def add_request(self, timestamp: datetime):
        """Add a new request timestamp."""
        self.requests.append(timestamp)
        self.logger.debug(f"Request added at {timestamp}")

    def add_response_time(self, response_time: float):
        """Add a new response time."""
        self.response_times.append(response_time)
        self.logger.debug(f"Response time added: {response_time}s")

    def cleanup_old_metrics(self, cutoff: datetime):
        """Remove metrics older than the cutoff time."""
        while self.requests and self.requests[0] < cutoff:
            removed_request = self.requests.popleft()
            removed_response_time = self.response_times.popleft()
            self.logger.debug(f"Old request at {removed_request} removed")
            self.logger.debug(f"Old response time {removed_response_time}s removed")

    def get_requests_per_sec(self, interval: int) -> float:
        """Calculate requests per second over the given interval."""
        cutoff = datetime.now() - timedelta(seconds=interval)
        recent_requests = [req for req in self.requests if req >= cutoff]
        requests_per_sec = len(recent_requests) / interval
        self.logger.debug(f"Requests per second: {requests_per_sec}")
        return requests_per_sec

    def get_avg_response_time(self) -> float:
        """Calculate average response time."""
        if self.response_times:
            avg_time = sum(self.response_times) / len(self.response_times)
            self.logger.debug(f"Average response time: {avg_time}s")
            return avg_time
        return 0.0

    def get_error_rate(self) -> float:
        """Calculate error rate."""
        if self.requests:
            error_rate = len(self.errors) / len(self.requests)
            self.logger.debug(f"Error rate: {error_rate}")
            return error_rate
        return 0.0

    def get_model_performance(self) -> Dict[str, Any]:
        """Get current model performance metrics."""
        return {
            lang: {
                "loading_time_avg": sum(times) / len(times) if times else 0.0,
                "inference_time_avg": (
                    sum(self.inference_times[lang]) / len(self.inference_times[lang])
                    if self.inference_times[lang]
                    else 0.0
                ),
                "accuracy": self.accuracy.get(lang, 0.0),
                "precision": self.precision.get(lang, 0.0),
                "recall": self.recall.get(lang, 0.0),
            }
            for lang, times in self.model_loading_times.items()
        }

    def __getitem__(self, key):
        """Allow dictionary-like access to metrics"""
        return self._data[key]

    def __setitem__(self, key, value):
        """Allow dictionary-like setting of metrics"""
        with self._lock:
            self._data[key] = value

    async def send_metrics(self, manager: ConnectionManager, metrics: Dict[str, Any]):
        """Send metrics to all active WebSocket connections"""
        try:
            await manager.broadcast(json.dumps(metrics))
        except Exception as e:
            self.logger.error(f"Metrics update error: {e}")

    def update_system_metrics(self):
        """Update system metrics with rate limiting"""
        current_time = time.time()

        # Check if enough time has passed since last update
        with self._lock:
            if current_time - self._last_update < self._metrics_update_interval:
                return

            self._last_update = current_time

        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()

            with self._metrics_lock:
                self.metrics["system"]["cpu_usage"].append(
                    {"timestamp": datetime.now().isoformat(), "value": cpu_percent}
                )

                self.metrics["system"]["memory_usage"].append(
                    {"timestamp": datetime.now().isoformat(), "value": memory.percent}
                )

                # Calculate requests per second
                recent_requests = list(self.metrics["requests"]["rate"])
                if recent_requests:
                    requests_per_sec = len(recent_requests) / 60.0  # Last minute
                else:
                    requests_per_sec = 0

                self.metrics["system"]["requests_per_sec"] = requests_per_sec

        except Exception as e:
            self.logger.error(f"Error updating metrics: {e}")

    def get_current_metrics(self):
        """Get current metrics with proper locks"""
        with self._metrics_lock:
            try:
                latest_metrics = {
                    "system": {
                        "cpu_usage": self._get_latest("system", "cpu_usage"),
                        "memory_usage": self._get_latest("system", "memory_usage"),
                        "error_rate": self._get_latest("system", "error_rate"),
                        "requests_per_sec": self.metrics["system"].get(
                            "requests_per_sec", 0
                        ),
                    },
                    "model": {
                        "vi": self._get_model_metrics("vi"),
                        "en": self._get_model_metrics("en"),
                    },
                    "requests": {
                        "total": self.metrics["requests"]["total"],
                        "success_rate": self._calculate_success_rate(),
                    },
                    "uptime": self._calculate_uptime(),
                }
                return latest_metrics
            except Exception as e:
                self.logger.error(f"Error getting metrics: {e}")
                return {}

================
File: src/utils/report.py
================
import os
from datetime import datetime
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from ..models.model_predictor import SentimentPredictor
from ..utils.logger import Logger
import joblib


class ReportGenerator:
    """
    Generates detailed analysis reports for sentiment model performance
    """

    def __init__(self, language: str):
        self.language = language
        self.logger = Logger(__name__).logger

    def get_model_info(self):
        """Get current model information and metrics"""
        try:
            model_path = os.path.join(
                "data", "models", f"{self.language}_sentiment_model.pkl"
            )
            model_info = joblib.load(model_path)
            return model_info
        except Exception as e:
            self.logger.error(f"Error loading model info: {e}")
            return None

    def generate_metrics_plots(self, metrics, output_dir):
        """Generate performance metric visualizations"""
        plt.figure(figsize=(15, 10))

        # Confusion matrix
        plt.subplot(2, 2, 1)
        if "confusion_matrix" in metrics:
            sns.heatmap(metrics["confusion_matrix"], annot=True, fmt="d")
            plt.title("Confusion Matrix")

        # ROC curve
        plt.subplot(2, 2, 2)
        if "roc_curve" in metrics:
            fpr, tpr, _ = metrics["roc_curve"]
            plt.plot(fpr, tpr)
            plt.plot([0, 1], [0, 1], "k--")
            plt.title("ROC Curve")
            plt.xlabel("False Positive Rate")
            plt.ylabel("True Positive Rate")

        # Score distribution
        plt.subplot(2, 2, 3)
        if "score_distribution" in metrics:
            sns.histplot(data=metrics["score_distribution"])
            plt.title("Score Distribution")

        # Error analysis
        plt.subplot(2, 2, 4)
        if "error_analysis" in metrics:
            errors = pd.DataFrame(metrics["error_analysis"])
            sns.barplot(x="error_type", y="count", data=errors)
            plt.title("Error Analysis")
            plt.xticks(rotation=45)

        plt.tight_layout()
        plt.savefig(os.path.join(output_dir, "performance_metrics.png"))
        plt.close()

    def generate_html_report(self, model_info, metrics, output_file):
        """Generate HTML report with metrics and visualizations"""
        html = """
        <html>
        <head>
            <title>Sentiment Analysis Model Report</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 40px; }
                .metric { margin: 20px 0; }
                .visualization { margin: 30px 0; }
                table { border-collapse: collapse; width: 100%; }
                th, td { border: 1px solid #ddd; padding: 8px; }
                th { background-color: #f4f4f4; }
            </style>
        </head>
        <body>
            <h1>Sentiment Analysis Model Report</h1>
            <div class="metadata">
                <h2>Model Information</h2>
                <table>
                    <tr><th>Language</th><td>{language}</td></tr>
                    <tr><th>Generated</th><td>{timestamp}</td></tr>
                    <tr><th>Model Version</th><td>{version}</td></tr>
                </table>
            </div>

            <div class="metrics">
                <h2>Performance Metrics</h2>
                <table>
                    <tr><th>Metric</th><th>Value</th></tr>
                    {metrics_rows}
                </table>
            </div>

            <div class="visualization">
                <h2>Visualizations</h2>
                <img src="performance_metrics.png" alt="Performance Metrics">
            </div>
        </body>
        </html>
        """

        # Format metrics rows
        metrics_rows = ""
        if metrics:
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    metrics_rows += f"<tr><td>{key}</td><td>{value:.4f}</td></tr>"

        # Fill template
        report = html.format(
            language=self.language.upper(),
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            version=model_info.get("version", "N/A"),
            metrics_rows=metrics_rows,
        )

        with open(output_file, "w", encoding="utf-8") as f:
            f.write(report)

    def generate_report(self, output_file):
        """Generate complete model analysis report"""
        try:
            # Create output directory
            output_dir = os.path.dirname(output_file)
            os.makedirs(output_dir, exist_ok=True)

            # Get model info and metrics
            model_info = self.get_model_info()
            if not model_info:
                raise ValueError("Could not load model information")

            metrics = model_info.get("metrics", {})

            # Generate visualizations
            self.generate_metrics_plots(metrics, output_dir)

            # Generate HTML report
            self.generate_html_report(model_info, metrics, output_file)

            self.logger.info(f"Report generated successfully at {output_file}")
            return True

        except Exception as e:
            self.logger.error(f"Error generating report: {e}")
            return False

================
File: src/utils/server_utils.py
================
import psutil
import socket
import time
from typing import List, Optional, Any  # Add this import
import logging
from fastapi import WebSocket, WebSocketDisconnect
from starlette.websockets import WebSocketState
from src.utils.logger import Logger
import json  # Add this import at the top

logger = logging.getLogger(__name__)


def force_kill_port(port: int) -> bool:
    """Force kill any process using the specified port"""
    try:
        connections = psutil.net_connections()
        for conn in connections:
            try:
                if hasattr(conn, "laddr") and conn.laddr.port == port:
                    try:
                        proc = psutil.Process(conn.pid)
                        proc.kill()
                        return True
                    except (psutil.NoSuchProcess, psutil.AccessDenied):
                        continue
            except (AttributeError, TypeError):
                continue
        return False
    except Exception as e:
        logger.error(f"Error killing process on port {port}: {e}")
        return False


def is_port_in_use(port: int) -> bool:
    """Check if port is in use"""
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        try:
            s.bind(("", port))
            return False
        except OSError:
            return True


async def safe_send(websocket: WebSocket, message: str):
    """Safely send a message over WebSocket, handling disconnections."""
    try:
        await websocket.send_text(message)
    except WebSocketDisconnect:
        logger.warning("WebSocket disconnected before message could be sent.")
    except Exception as e:
        logger.error(f"Error sending message over WebSocket: {e}")


class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.keep_alive_interval = 10

    async def connect(self, websocket: WebSocket):
        try:
            await websocket.accept()
            self.active_connections.append(websocket)
            logger = Logger(__name__).logger
            logger.info(
                f"WebSocket client connected. Total connections: {len(self.active_connections)}"
            )
        except Exception as e:
            logger.error(f"Error accepting WebSocket connection: {e}")
            raise

    async def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        if websocket.client_state == WebSocketState.CONNECTED:
            await websocket.close()

    async def broadcast(self, message: Any):
        try:
            if isinstance(message, dict):
                message = json.dumps(message)
            elif not isinstance(message, str):
                message = str(message)

            disconnected = []
            for connection in self.active_connections:
                try:
                    if connection.client_state == WebSocketState.CONNECTED:
                        await connection.send_text(message)
                    else:
                        disconnected.append(connection)
                except Exception as e:
                    logger.error(f"Error sending message to WebSocket: {e}")
                    disconnected.append(connection)

            for connection in disconnected:
                await self.disconnect(connection)
                logger.info("WebSocket client disconnected during broadcast.")
        except Exception as e:
            logger.error(f"Broadcast failed: {e}")

    async def handle_message(self, websocket: WebSocket, message: str):
        """Handle incoming messages from WebSocket clients."""
        try:
            data = json.loads(message)
            if data.get("type") == "heartbeat":
                await websocket.send_text(json.dumps({"type": "heartbeat_ack"}))
                logger.debug("Heartbeat acknowledged.")
            # Handle other message types if necessary
        except json.JSONDecodeError:
            logger.error("Received invalid JSON message.")
        except Exception as e:
            logger.error(f"Error handling message: {e}")
            # Optionally, you can close the websocket here if needed
            # await websocket.close()

================
File: src/utils/templates.py
================
import random

class CommentTemplates:
    def __init__(self):
        self.vi_templates = {
            "product_review": {
                "positive": [
                    "Sản phẩm {quality} quá, {reason}",
                    "Mình rất {emotion} với {aspect}",
                    "Đóng gói {packaging}, giao hàng {delivery}",
                    "{aspect} tốt hơn mong đợi, {details}",
                    "Giá tiền {price_opinion}, {value_desc}",
                ],
                "negative": [
                    "{aspect} không được tốt, {issue}",
                    "Hơi thất vọng về {aspect}, {reason}",
                    "Chất lượng {quality_issue}, {details}",
                    "Giao hàng {delivery_issue}, {problem}",
                    "Không đáng giá tiền, {reason}",
                ],
                "neutral": [
                    "Sản phẩm tạm được, {details}",
                    "Cũng được, nhưng {suggestion}",
                    "Không có gì đặc biệt, {reason}",
                    "Dùng được, {opinion}",
                    "Tạm ổn, {details}",
                ],
            },
            "food_review": {
                "positive": [
                    "Món này {taste} thiệt luôn, {details}",
                    "Quán {service} chu đáo, {atmosphere}",
                    "Đồ ăn {quality} xuất sắc, {reason}",
                    "Giá cả {price_opinion}, {value}",
                    "Không gian {atmosphere}, {recommendation}",
                ],
                "negative": [
                    "Đồ ăn {taste_issue}, {reason}",
                    "Phục vụ {service_issue}, {problem}",
                    "Giá hơi {price_complaint}, {details}",
                    "Vệ sinh {cleanliness_issue}, {problem}",
                    "Thất vọng về {aspect}, {reason}",
                    "Đồ ăn {taste_issue} vl, {problem}",
                    "Quán này {slang_negative} thật, {reason}",
                    "Giá thì cắt cổ mà đồ ăn {taste_issue} vcl",
                    "Phục vụ như c*t, {service_issue}",
                    "Vệ sinh {cleanliness_issue} vl, éo bao giờ quay lại"
                ],
                "neutral": [
                    "Đồ ăn {taste} bình thường, {details}",
                    "Giá tương đối {price_opinion}, {value}",
                    "Phục vụ {service} tạm được, {details}",
                    "Không gian {atmosphere}, nhưng {suggestion}",
                    "Chất lượng trung bình, {opinion}"
                ],
            },
            "movie_review": {
                "positive": [
                    "Phim hay quá, {reason}",
                    "Diễn viên {acting}, kịch bản {script}",
                    "Cốt truyện {plot_opinion}, {details}",
                    "Xem mà {emotion}, {reason}",
                    "Đáng xem nha mọi người, {recommendation}",
                ],
                "negative": [
                    "Phim nhạt quá, {reason}",
                    "Diễn viên {acting_issue}, {problem}",
                    "Kịch bản {script_issue}, {details}",
                    "Thất vọng vì {aspect}, {reason}",
                    "Không đáng tiền vé, {details}",
                ],
                "neutral": [
                    "Phim cũng được, {reason}",
                    "Diễn viên {acting} tạm ổn, kịch bản {script}",
                    "Cốt truyện {plot_opinion}, {details}",
                    "Xem cũng được, {opinion}",
                    "Không quá tệ nhưng không xuất sắc, {details}"
                ],
            },
            "service_review": {
                "positive": [
                    "Nhân viên {staff_quality} và {staff_attitude}",
                    "Dịch vụ {service_quality}, {recommendation}",
                    "Được {good_point} và {another_point}",
                    "Rất {emotion} với {aspect}, {reason}",
                    "{service_type} ở đây {quality}, {details}",
                ],
                "negative": [
                    "Thái độ nhân viên {bad_attitude}, {issue}",
                    "Dịch vụ {service_issue}, {problem}",
                    "Không hài lòng về {aspect}, {reason}",
                    "Thất vọng về {issue_point}, {details}",
                    "{service_type} quá {negative_point}, {complaint}",
                ],
                "neutral": [
                    "Dịch vụ bình thường, {details}",
                    "Tạm được, nhưng {suggestion}",
                    "{aspect} có thể cải thiện thêm, {feedback}",
                    "Chưa có gì đặc sắc, {reason}",
                    "Cũng được, {opinion}",
                ],
            },
            "technology_review": {
                "positive": [
                    "{device} chạy {performance}, {details}",
                    "Cấu hình {spec_quality}, {feature_opinion}",
                    "Pin {battery_life}, {usage_experience}",
                    "Camera {camera_quality}, {photo_details}",
                    "Thiết kế {design_opinion}, {build_quality}",
                ],
                "negative": [
                    "{device} hay bị {tech_issue}, {problem}",
                    "Pin {battery_issue}, {complaint}",
                    "Giá quá {price_opinion} so với {comparison}",
                    "Cấu hình {spec_issue}, {performance_details}",
                    "Không đáng tiền vì {reason}, {details}",
                ],
                "neutral": [
                    "{device} dùng tạm được, {details}",
                    "Cấu hình {spec_quality} đủ dùng, {feature_opinion}",
                    "Pin {battery_life}, {usage_experience}",
                    "Camera {camera_quality}, {photo_details}",
                    "Thiết kế bình thường, {build_quality}"
                ],
            },
        }

        self.en_templates = {
            "product_review": {
                "positive": [
                    "This product is {quality}, {reason}",
                    "Really {emotion} with {aspect}",
                    "Great {packaging}, {delivery} shipping",
                    "{aspect} exceeded expectations, {details}",
                    "Price is {price_opinion}, {value_desc}",
                ],
                "negative": [
                    "{aspect} isn't good, {issue}",
                    "Disappointed with {aspect}, {reason}",
                    "Quality is {quality_issue}, {details}",
                    "Shipping was {delivery_issue}, {problem}",
                    "Not worth the money, {reason}",
                ],
                "neutral": [
                    "Product is okay, {details}",
                    "Decent but {suggestion}",
                    "Nothing special, {reason}",
                    "Usable product, {opinion}",
                    "Fairly standard, {details}"
                ]
            }
        }

        self.en_templates.update({
            "food_review": {
                "positive": [
                    "Food is {taste}, {details}",
                    "Service is {service_quality}, {atmosphere}",
                    "Quality is {quality}, {reason}",
                    "Great value for {price_opinion}, {value}",
                    "Ambiance is {atmosphere}, {recommendation}"
                ],
                "negative": [
                    "Food was {taste_issue}, {reason}",
                    "Poor service: {service_issue}, {problem}",
                    "Overpriced: {price_complaint}, {details}",
                    "Hygiene issues: {cleanliness_issue}, {problem}",
                    "Disappointed with {aspect}, {reason}"
                ],
                "neutral": [
                    "The food is average, {details}",
                    "Price is reasonable, {value}",
                    "Service is decent, {details}",
                    "Ambiance is okay but {suggestion}",
                    "Standard quality, {opinion}"
                ]
            },
            "movie_review": {
                "positive": [
                    "Great movie, {reason}",
                    "Actors were {acting}, script was {script}",
                    "Plot was {plot_opinion}, {details}",
                    "Felt {emotion} watching it, {reason}",
                    "Worth watching, {recommendation}"
                ],
                "negative": [
                    "Boring movie, {reason}",
                    "Actors were {acting_issue}, {problem}",
                    "Script was {script_issue}, {details}",
                    "Disappointed with {aspect}, {reason}",
                    "Not worth the ticket price, {details}"
                ],
                "neutral": [
                    "Movie is alright, {reason}",
                    "Acting is decent, script is {script}",
                    "Plot is {plot_opinion}, {details}",
                    "It's watchable, {opinion}",
                    "Neither great nor terrible, {details}"
                ]
            },
            "service_review": {
                "positive": [
                    "Staff were {staff_quality} and {staff_attitude}",
                    "Service was {service_quality}, {recommendation}",
                    "Had {good_point} and {another_point}",
                    "Very {emotion} with {aspect}, {reason}",
                    "{service_type} here is {quality}, {details}"
                ],
                "negative": [
                    "Staff attitude was {bad_attitude}, {issue}",
                    "Service was {service_issue}, {problem}",
                    "Not satisfied with {aspect}, {reason}",
                    "Disappointed with {issue_point}, {details}",
                    "{service_type} was too {negative_point}, {complaint}"
                ],
                "neutral": [
                    "Service was okay, {details}",
                    "Decent but {suggestion}",
                    "{aspect} could be improved, {feedback}",
                    "Nothing remarkable, {reason}",
                    "Standard service, {opinion}"
                ]
            }
        })

        self.vi_fillers = {
            "quality": ["tốt", "xuất sắc", "tuyệt vời", "đỉnh", "chất lượng"],
            "emotion": ["hài lòng", "thích", "ưng", "mê", "yêu"],
            "packaging": ["cẩn thận", "chắc chắn", "đẹp", "gọn gàng"],
            "delivery": ["nhanh", "đúng hẹn", "tốt", "chuyên nghiệp"],
            "price_opinion": ["hợp lý", "rẻ", "tốt", "phải chăng"],
            "value_desc": ["đáng đồng tiền", "chất lượng xứng đáng", "rất hời"],
            "acting": ["diễn xuất tốt", "nhập vai", "tự nhiên", "thuyết phục"],
            "script": ["hay", "cuốn", "logic", "hấp dẫn"],
            "taste": ["ngon", "tuyệt", "xuất sắc", "đúng vị", "đậm đà"],
            "service": ["phục vụ", "tận tình", "nhiệt tình", "chuyên nghiệp"],
            "atmosphere": ["thoải mái", "đẹp", "sang trọng", "ấm cúng"],
            "staff_quality": [
                "chuyên nghiệp",
                "được đào tạo bài bản",
                "có kinh nghiệm",
            ],
            "staff_attitude": ["rất thân thiện", "nhiệt tình", "vui vẻ", "chu đáo"],
            "service_quality": ["rất tốt", "chuyên nghiệp", "đúng giờ", "nhanh chóng"],
            "good_point": [
                "tư vấn tận tình",
                "giải đáp thắc mắc rõ ràng",
                "hỗ trợ nhiệt tình",
            ],
            "bad_attitude": [
                "cọc cằn",
                "thiếu chuyên nghiệp",
                "không nhiệt tình",
                "làm việc qua loa",
            ],
            "service_issue": ["chậm trễ", "thiếu chuyên nghiệp", "không đúng cam kết"],
            "performance": ["mượt mà", "nhanh", "ổn định", "tốt", "lag"],
            "spec_quality": ["khá ổn", "mạnh mẽ", "đủ dùng", "cao cấp"],
            "battery_life": ["trâu", "tốt", "dùng được lâu", "không tốt"],
            "camera_quality": ["chụp đẹp", "chi tiết", "sắc nét", "tạm được"],
            "design_opinion": ["sang trọng", "đẹp", "hiện đại", "cao cấp"],
            "tech_issue": ["lag", "đơ", "nóng", "lỗi phần mềm"],
            "recommendation": [
                "nên thử nhé",
                "recommend mọi người nên dùng",
                "sẽ ủng hộ dài dài",
                "sẽ quay lại lần sau",
            ],
            "suggestion": [
                "cần cải thiện thêm",
                "có thể tốt hơn nữa",
                "nên nâng cấp dịch vụ",
            ],
            "details": [
                "thấy rất worth",
                "đáng đồng tiền",
                "giá hơi cao",
                "cần cải thiện thêm",
            ],
            "neutral_opinion": [
                "tạm được",
                "không có gì đặc biệt",
                "bình thường",
                "trung bình",
                "không nổi bật"
            ],
            "neutral_suggestion": [
                "có thể cải thiện thêm",
                "còn nhiều điểm cần phát triển",
                "cần nâng cấp thêm",
                "nên cải tiến"
            ],
            "neutral_aspect": [
                "chất lượng tạm ổn",
                "giá cả chấp nhận được",
                "dịch vụ bình thường",
                "không có gì để khen hoặc chê"
            ]
        }

        self.vi_fillers.update({
            "quality": [
                "tốt", "xuất sắc", "tuyệt vời", "đỉnh", "chất lượng",
                "xịn xò", "đáng đồng tiền", "ưng cái bụng", "ngon lành", 
                "không phải dạng vừa đâu"
            ],
            "emotion": [
                "hài lòng", "thích", "ưng", "mê", "yêu",
                "phê quá trời", "sướng rớt nước miếng", "đê mê", 
                "mê tít thò lò", "phải lòng ngay cái nhìn đầu tiên"
            ],
        })

        self.en_fillers = {
            "quality": ["good", "excellent", "amazing", "great", "outstanding"],
            "emotion": ["happy", "satisfied", "pleased", "delighted", "impressed"],
            "packaging": ["careful", "secure", "nice", "neat", "professional"],
            "delivery": ["fast", "on-time", "efficient", "professional", "prompt"],
            "price_opinion": ["reasonable", "affordable", "fair", "good value"],
            "value_desc": ["worth the money", "great value", "excellent deal"],
            "reason": ["really love the quality", "exceeds expectations", "exactly what I needed"],
            "issue": ["not up to standard", "below expectations", "poor quality"],
            "problem": ["constant issues", "major flaws", "serious problems"],
            "details": ["highly recommend", "would buy again", "excellent purchase"],
            "suggestion": ["could be improved", "needs work", "should be better"],
            "recommendation": ["definitely recommend", "worth trying", "must buy"],
            "quality_issue": ["poor", "substandard", "disappointing", "terrible"],
            "delivery_issue": ["delayed", "late", "unprofessional", "problematic"],
            "aspect": ["quality", "design", "functionality", "performance", "features"],
            "neutral_opinion": [
                "decent", "average", "okay", "standard",
                "fair", "moderate", "acceptable", "passable"
            ],
            "neutral_suggestion": [
                "could be improved",
                "needs some work",
                "has room for improvement",
                "could be better"
            ],
            "neutral_quality": [
                "average quality",
                "acceptable standard",
                "middle-ground",
                "fair enough"
            ],
            "neutral_response": [
                "mixed feelings",
                "balanced view",
                "moderate opinion",
                "neutral stance"
            ]
        }

        missing_en_fillers = {
            "taste": ["delicious", "amazing", "excellent", "flavorful", "tasty"],
            "service": ["attentive", "professional", "friendly", "efficient"],
            "atmosphere": ["cozy", "elegant", "comfortable", "pleasant"],
            "staff_quality": ["well-trained", "experienced", "professional", "skilled"],
            "staff_attitude": ["friendly", "helpful", "courteous", "welcoming"],
            # ...add other missing categories
        }
        
        self.en_fillers.update(missing_en_fillers)

        self.vi_aspects = {
            "product": ["chất lượng", "mẫu mã", "đóng gói", "giao hàng", "giá cả"],
            "food": ["hương vị", "phục vụ", "không gian", "giá cả", "vệ sinh"],
            "movie": ["nội dung", "diễn xuất", "kịch bản", "âm thanh", "hình ảnh"],
        }

        self.en_aspects = {
            "product": ["quality", "design", "packaging", "shipping", "price"],
            "food": ["taste", "service", "ambiance", "pricing", "cleanliness"],
            "movie": ["content", "acting", "script", "sound", "visuals"],
            "service": ["staff", "efficiency", "value", "facilities", "experience"]
        }

        self.vi_expressions = {
            "positive": [
                "quá xịn luôn",
                "đỉnh thật sự",
                "không có gì để chê",
                "ưng cái bụng",
                "cực kỳ hài lòng",
                "xuất sắc",
            ],
            "negative": [
                "thất vọng quá",
                "chán thật sự",
                "không đáng tiền",
                "quá tệ",
                "không thể chấp nhận được",
            ],
            "neutral": [
                "tạm được",
                "không có gì đặc biệt",
                "bình thường",
                "cũng được",
                "tương đối ổn",
            ],
        }

        # Thêm từ lóng tiếng Việt
        self.vi_slangs = {
            "positive": {
                "xịn": ["xịn xò", "xịn sò", "đỉnh", "đỉnh cao", "cực phẩm"],
                "ngon": ["bá cháy", "bá đạo", "xuất sắc", "đỉnh của chóp"],
                "tốt": ["chất", "max good", "hết nước chấm", "không phải bàn"],
                "thích": ["khoái bá cháy", "ưng quá trời", "mê tít"],
                "hay": ["mãi đỉnh", "gút chóp", "max hay", "xịn sò"],
            },
            "negative": {
                "tệ": ["như cái bãi", "rác", "phèn", "dởm", "fail"],
                "kém": ["như hạch", "cùi bắp", "xác xơ"],
                "đắt": ["chát", "cắt cổ", "hút máu"],
                "chán": ["nhạt như nước ốc", "ngán ngẩm", "nản"],
                "dở": ["phế", "gà", "non", "trẻ trâu"],
            },
            "intensifiers": {
                "rất": ["đét", "quá xá", "dã man", "kinh hoàng"],
                "nhiều": ["ối dồi ôi", "vô số", "vô vàn"],
                "quá": ["vãi", "vl", "vcl", "xỉu up xỉu down"],
            },
            "internet_terms": {
                "ok": ["oce", "oke", "okela", "okê"],
                "không": ["kh", "hông", "khum", "hem"],
                "vậy": ["z", "dz", "v"],
                "được": ["đc", "dk", "dke"],
                "biết": ["bít", "bik", "bit"],
                "vui": ["zui", "zoui", "vkoj"],
                "buồn": ["bùn", "buon", "huhu"],
            },
            "neutral": {
                "bình thường": ["bt", "sương sương", "tàm tạm"],
                "tạm": ["tạm được", "được", "cũng được"],
                "trung bình": ["không đặc sắc", "không nổi bật"],
                "thường": ["bình bình", "không có gì đặc biệt"]
            },
            "informal_expressions": {
                "tức giận": ["tức ói", "điên tiết", "tức điên", "tức phát điên", "máu"],
                "thất vọng": ["chán đời", "nản vl", "chả buồn nói", "phát ngấy"],
                "phẫn nộ": ["đkm", "má nó", "dcm", "vkl", "ối dồi ôi"],
                "khen ngợi": ["đỉnh vl", "bá đạo vl", "max ngon", "xịn sò"],
                "chê bai": ["như c*t", "như sh*t", "như cức", "hãm vl", "tởm"],
                "bực mình": ["đ*o chịu nổi", "đ*o được", "quá mức chịu đựng"],
                "bất ngờ": ["đậu má", "vãi cả l*n", "vãi", "vcl"]
            }
        }

        # Add more slang variations to existing categories
        self.vi_slangs["positive"].update({
            "xịn": self.vi_slangs["positive"]["xịn"] + ["đỉnh vl", "xịn sò vl"],
            "ngon": self.vi_slangs["positive"]["ngon"] + ["ngon vl", "đỉnh của chóp vl"],
            "tốt": self.vi_slangs["positive"]["tốt"] + ["quá mẹ ngon", "đỉnh quá xá"],
            "thích": self.vi_slangs["positive"]["thích"] + ["phê vl", "sướng phát xỉu"]
        })

        self.vi_slangs["negative"].update({
            "tệ": self.vi_slangs["negative"]["tệ"] + ["như c*t", "như sh*t"],
            "kém": self.vi_slangs["negative"]["kém"] + ["như hạch vl", "dở ẹc"],
            "đắt": self.vi_slangs["negative"]["đắt"] + ["chém gió vl", "cướp tiền"],
            "dở": self.vi_slangs["negative"]["dở"] + ["ngu vl", "gà vl"]
        })

        # Add more internet terms
        self.vi_slangs["internet_terms"].update({
            "không": self.vi_slangs["internet_terms"]["không"] + ["éo", "đ*o", "đéo"],
            "vãi": ["v~", "vl", "vcl", "vloz"],
            "quá": ["vãi cả l", "vcl", "vl"],
            "được": ["đc", "dk", "được của l*"]
        })

        # Thêm từ lóng tiếng Anh
        self.en_slangs = {
            "positive": {
                "good": ["lit", "fire", "dope", "sick", "rad"],
                "great": ["goated", "bussin", "slaps", "hits different"],
                "amazing": ["baddie", "based", "poggers", "absolute unit"],
                "like": ["stan", "vibe with", "fuck with", "dig"],
                "perfect": ["no cap", "straight fire", "hits hard"],
            },
            "negative": {
                "bad": ["mid", "trash", "cap", "sus", "ain't it"],
                "terrible": ["wack", "garbage", "dead", "basic"],
                "expensive": ["pricey af", "costs a bag", "steep"],
                "boring": ["sleeping on it", "dry", "dead"],
                "fake": ["cap", "sus", "fugazi", "bogus"],
            },
            "intensifiers": {
                "very": ["af", "asf", "fr fr", "ong"],
                "really": ["deadass", "fr", "no cap", "straight up"],
                "absolutely": ["lowkey", "highkey", "straight up"],
            },
            "internet_terms": {
                "okay": ["k", "kk", "aight", "ight"],
                "thanks": ["ty", "thx", "thnx"],
                "please": ["pls", "plz", "plox"],
                "what": ["wat", "wut", "tf"],
                "lol": ["lmao", "lmfao", "rofl"],
                "omg": ["omfg", "bruh", "bruhhh"],
            },
            "neutral": {
                "okay": ["meh", "whatever", "so-so"],
                "average": ["decent", "fair", "normal"],
                "mediocre": ["basic", "standard", "regular"],
                "moderate": ["alright", "passable", "fine"]
            }
        }

        # Thêm template mới sử dụng từ lóng
        self.vi_templates["social_media_review"] = {
            "positive": [
                "Ẩm thực {location} {slang_positive} luôn, {intensifier} {good_point}",
                "Quán này {slang_positive} {intensifier}, {recommendation}",
                "Giá hơi chát nhưng mà {slang_positive} thật, {details}",
                "{aspect} thì {slang_positive} khỏi bàn, {intensifier} {opinion}",
                "Nhân viên {staff_quality} {intensifier}, {staff_attitude}",
            ],
            "negative": [
                "Đúng là {slang_negative} thật sự, {intensifier} {issue}",
                "Quán này {slang_negative} {intensifier}, {problem}",
                "Giá thì {price_complaint} mà {slang_negative}, {details}",
                "{aspect} thì {slang_negative} {intensifier}, {complaint}",
                "Thái độ nhân viên {bad_attitude}, {slang_negative} {intensifier}",
            ],
        }

        # Thêm từ điển emoji phù hợp với cảm xúc
        self.emojis = {
            "positive": ["😊", "🥰", "😍", "🤩", "👍", "💯", "🔥", "✨", "💪", "����"],
            "negative": ["😤", "😒", "😑", "👎", "😠", "😡", "🤬", "💢", "😫", "😩"],
            "neutral": ["🤔", "😐", "😶", "🤷", "😕", "😌", "🙂", "👀"]
        }

        # Thêm các cách diễn đạt tự nhiên
        self.natural_expressions = {
            "opening": [
                "Thật sự thì", "Nói thật là", "Theo mình thấy thì", 
                "Mình đánh giá là", "Cá nhân mình thấy",
                "Xin chia sẻ chút là", "Mình mới dùng thử và thấy",
                "Sau thời gian trải nghiệm thì"
            ],
            "closing": [
                "Đó là góc nhìn của mình ạ", "Mọi người thấy sao?",
                "Đánh giá chủ quan thôi nha", "Hy vọng review có ích",
                "Mình nghĩ vậy thôi", "Mọi người cân nhắc nha"
            ]
        }

        # Thêm mẫu câu ngắn
        self.short_templates = {
            "positive": [
                "Tuyệt vời 👍",
                "Quá ngon luôn",
                "Đỉnh thật sự",
                "Rất ưng ý",
                "Xứng đáng {score}/10",
                "Không có gì để chê",
                "Sẽ quay lại lần sau",
                "Recommend nha mọi người"
            ],
            "negative": [
                "Thất vọng quá",
                "Không đáng tiền",
                "Chán thật sự",
                "Tệ hết chỗ nói",
                "Không bao giờ quay lại",
                "Phí tiền",
                "Quá tệ {score}/10",
                "Không nên mua"
            ],
            "neutral": [
                "Tạm được",
                "Bình thường",
                "Cũng được",
                "Không có gì đặc biệt",
                "Tương đối ổn",
                "{score}/10 thôi",
                "Còn cải thiện được"
            ]
        }

        # Thêm mẫu câu dài, chi tiết
        self.long_templates = {
            "positive": [
                "Đây là lần thứ {count} mình {action} và vẫn rất {emotion}. {aspect} thì {quality}, đặc biệt là {highlight}. {recommendation}",
                "Thực sự {emotion} khi {action}. {details} Về {aspect} thì {quality}, còn {another_aspect} cũng {another_quality}. {conclusion}",
                "Mình đã {action} được {duration} rồi và phải nói là {quality}. {reason} Ngoài ra {additional_point}. {suggestion}",
                "Trải nghiệm {duration} với {product/service} này thì thấy {overall_feeling}. {aspect} thì {quality}, {another_aspect} thì {another_quality}. {detailed_review} {final_thought}"
            ],
            "negative": [
                "Thất vọng tột độ với {aspect}. {issue_details} Không những thế, {another_issue}. {complaint_details} Mình đã liên hệ {support_channel} nhưng {service_issue}. {conclusion}",
                "Đây là trải nghiệm tệ nhất từ trước đến nay với {product/service}. {main_issue} Thêm vào đó, {additional_issues}. {negative_impact} {warning}",
                "Mình đã cho cơ hội {count} lần nhưng {recurring_issue}. {details} Về {aspect} thì {quality_issue}, {service_complaint}. {final_warning}"
            ],
            "neutral": [
                "Sau {duration} sử dụng thì thấy {product/service} này {neutral_opinion}. {positive_points} nhưng {negative_points}. {improvement_suggestions}",
                "Không quá tệ nhưng cũng không xuất sắc. {aspect} thì {neutral_quality}, còn {another_aspect} thì {areas_for_improvement}. {balanced_conclusion}",
                "Mình thấy {product/service} này còn nhiều điểm cần cải thiện. {details} Tuy nhiên cũng có {positive_aspects}. {suggestions}"
            ]
        }

        # Thêm từ điển điểm số và thời lượng
        self.scores = {
            "positive": ["9", "9.5", "10", "8.5"],
            "negative": ["2", "3", "4", "1"],
            "neutral": ["5", "6", "7", "6.5"]
        }
        
        self.durations = [
            "một thời gian", "mấy tháng", "gần năm", 
            "một tuần", "vài ngày", "khá lâu",
            "hơn {number} tháng", "gần {number} năm",
            "được {number} lần"
        ]

        self.numbers = ["1", "2", "3", "4", "5", "nhiều"]

        self.en_ratings = {
            "positive": [
                "{score}/10 would recommend",
                "Solid {score}/10",
                "A strong {score} out of 10",
                "Definitely {score}/10"
            ],
            "negative": [
                "Unfortunately {score}/10",
                "Disappointing {score}/10",
                "A weak {score}/10",
                "Only {score}/10"
            ],
            "neutral": [
                "Average {score}/10",
                "Middle-of-the-road {score}/10",
                "Fair {score}/10",
                "Decent {score}/10"
            ]
        }

        self.en_durations = [
            "for a while", "for months", "nearly a year",
            "for a week", "several days", "quite some time",
            "over {number} months", "almost {number} years",
            "{number} times"
        ]

        # Add English expressions
        self.en_expressions = {
            "positive": [
                "absolutely fantastic",
                "really amazing",
                "nothing to complain about",
                "exceeded expectations",
                "extremely satisfied",
                "outstanding",
                "top notch",
                "brilliant"
            ],
            "negative": [
                "very disappointing",
                "really frustrating",
                "not worth the money",
                "terrible experience",
                "completely unacceptable",
                "worst ever",
                "absolute garbage"
            ],
            "neutral": [
                "fairly decent",
                "nothing special",
                "average",
                "okay",
                "relatively fine",
                "mediocre",
                "standard"
            ]
        }

        # Add English natural expressions
        self.en_natural_expressions = {
            "opening": [
                "To be honest,",
                "In my experience,",
                "From my perspective,",
                "After trying this,",
                "I have to say,",
                "Let me share that",
                "Based on my usage,",
                "After some time with this,"
            ],
            "closing": [
                "That's my take on it.",
                "What do you think?",
                "Just my personal opinion.",
                "Hope this helps!",
                "That's my perspective.",
                "Consider it before buying."
            ]
        }

        # Thêm mẫu bình luận tương tác
        self.interaction_templates = {
            "argument": {
                "aggressive": [
                    "Đ* biết gì mà {action}? {insult}",
                    "Ngu như {insult} mà cũng {action}",
                    "M là thằng {insult} à? Sao {action} v?",
                    "Làm như hay lắm í, {insult}",
                    "Ăn nói như {insult}, blocked!",
                ],
                "defensive": [
                    "Ai cho {subject} {action}? {counter_argument}",
                    "Mắc gì phải nghe {subject}? {dismissal}",
                    "Kệ tao, liên quan gì đến {subject}?",
                    "Đừng có mà {action}, {warning}",
                    "Nói nữa là {threat} đấy!",
                ],
                "dismissive": [
                    "Kệ người ta đi {subject} ơi",
                    "Thôi {subject} ạ, chả ai quan tâm đâu",
                    "Đ* ai thèm để ý {subject} nói gì",
                    "Lạ nhỉ? Ai hỏi {subject} không?",
                    "Không ai cần ý kiến của {subject} đâu",
                ]
            },
            "support": {
                "agreement": [
                    "+1 với {subject}, {reason}",
                    "Đồng ý với {subject} luôn, {explanation}",
                    "Chuẩn đấy {subject} ơi! {detail}",
                    "Như {subject} nói là đúng rồi",
                    "{subject} nói chuẩn quá! {agreement}"
                ],
                "praise": [
                    "Review hay quá {subject} ơi! {appreciation}",
                    "Tks {subject} đã chia sẻ nha! {gratitude}",
                    "Bài viết chất lượng {subject} ạ",
                    "Góp ý có tâm quá {subject}",
                    "Respect {subject}! {reason}"
                ]
            },
            "trolling": [
                "Ơ thế {subject} định nói gì? 🤡",
                "Nghe {subject} nói mà tức cười quá 😂",
                "Thím {subject} lại nổi hứng rồi",
                "Cao thủ {subject} lại xuất hiện kìa ae 🤣",
                "Đọc mà xỉu với {subject} luôn"
            ]
        }

        # Thêm từ vựng cho bình luận tương tác
        self.interaction_fillers = {
            "insult": [
                "ngu như bò", "óc chó", "đầu đất", "thiểu năng", 
                "ăn c*t", "ngu l*n", "mặt người óc lợn",
                "đần độn", "ngu si", "ngáo đá"
            ],
            "action": [
                "bô bô cái mồm", "phát biểu", "lên mặt dạy đời",
                "sủa", "gâu gâu", "hùa theo", "nói năng lung tung",
                "xàm xí", "thể hiện", "xen vào"
            ],
            "subject": [
                "bạn", "thím", "bác", "chế", "đồng chí",
                "cụ", "anh", "chị", "bợn", "đại ca"
            ],
            "threat": [
                "ăn block", "báo admin", "cho lên thớt",
                "cho ra đảo", "tay không bắt giặc", 
                "xử đẹp", "đập phát chết luôn"
            ],
            "counter_argument": [
                "nói cho biết nha", "nhớ đấy nhá",
                "cãi là ăn ban", "đừng có mà ngồi mơ",
                "tự soi gương đi"
            ],
            "dismissal": [
                "lo chuyện của mình đi", "đi ngủ sớm đi",
                "về mà hỏi google", "dứt ra cho nước nó trong",
                "lượn đi cho nước nó trong"
            ],
            "warning": [
                "đừng để tôi nóng", "cẩn thận cái mồm",
                "liệu mà giữ mồm", "coi chừng tay tôi",
                "cẩn thận kẻo đấm nhau"
            ],
            "appreciation": [
                "review có tâm quá", "chia sẻ xịn xò",
                "góp ý quá chuẩn", "phân tích rất hay",
                "đánh giá rất khách quan"
            ]
        }

        clean_vi_interaction = {
            "insult": [
                "không hiểu gì", "thiếu hiểu biết", "kém cỏi",
                "không có kiến thức", "thiếu kinh nghiệm"
            ],
            "action": [
                "lên tiếng", "phát biểu", "góp ý",
                "bình luận", "đánh giá", "phê bình"
            ],
            "warning": [
                "cẩn thận lời nói", "giữ ý một chút",
                "suy nghĩ kỹ hơn", "điều chỉnh cách nói",
                "xem lại cách ứng xử"
            ]
        }
        
        # Replace offensive terms with clean ones
        self.interaction_fillers.update(clean_vi_interaction)

        # Add English interaction templates
        self.en_interaction_templates = {
            "argument": {
                "aggressive": [
                    "What do you know about {action}?",
                    "You clearly don't understand {topic}",
                    "Stop talking nonsense about {topic}",
                    "Your opinion is totally wrong",
                    "You have no idea what you're saying"
                ],
                "defensive": [
                    "Who asked for your opinion?",
                    "Mind your own business",
                    "Whatever, I don't care what you think",
                    "Don't tell me what to do",
                    "You should know better"
                ],
                "dismissive": [
                    "Just ignore them",
                    "Nobody cares about that opinion",
                    "Why even bother responding?",
                    "Not worth discussing",
                    "Let's move on from this"
                ]
            },
            "support": {
                "agreement": [
                    "Totally agree with you about {topic}!",
                    "You're absolutely right, {reason}",
                    "Couldn't agree more! {detail}",
                    "That's exactly what I think",
                    "Well said! {agreement}"
                ],
                "praise": [
                    "Great review! {appreciation}",
                    "Thanks for sharing! {gratitude}",
                    "Very helpful review",
                    "Excellent feedback",
                    "Really appreciate your insights!"
                ]
            },
            "neutral": {
                "balanced": [
                    "I see both sides here, {topic}",
                    "There are pros and cons, {details}",
                    "It's not that simple, {explanation}",
                    "Let's be objective about {topic}",
                    "Consider both perspectives on {subject}"
                ],
                "moderate": [
                    "Maybe we should wait and see",
                    "Not jumping to conclusions about {topic}",
                    "Need more information about {subject}",
                    "Taking a balanced view on this",
                    "Looking at it objectively"
                ]
            }
        }

    def get_random_slang(
        self, sentiment: str, category: str, language: str = "vi"
    ) -> str:
        """Get random slang based on sentiment and category"""
        slang_dict = self.vi_slangs if language == "vi" else self.en_slangs
        if category in slang_dict and sentiment in slang_dict[category]:
            return random.choice(slang_dict[category][sentiment])
        return ""

    def get_random_intensifier(self, language: str = "vi") -> str:
        """Get random intensifier"""
        slang_dict = self.vi_slangs if language == "vi" else self.en_slangs
        return random.choice(
            slang_dict["intensifiers"]["rất" if language == "vi" else "very"]
        )

    def get_internet_term(self, word: str, language: str = "vi") -> str:
        """Get internet slang version of a word if available"""
        slang_dict = self.vi_slangs if language == "vi" else self.en_slangs
        if word.lower() in slang_dict["internet_terms"]:
            return random.choice(slang_dict["internet_terms"][word.lower()])
        return word

    def get_random_duration(self):
        """Get random duration with optional number"""
        duration = random.choice(self.durations)
        if "{number}" in duration:
            duration = duration.replace("{number}", random.choice(self.numbers))
        return duration

    def get_random_score(self, sentiment):
        """Get appropriate score based on sentiment"""
        return random.choice(self.scores[sentiment])

    def generate_varied_length_comment(self, sentiment, topic):
        """Generate comment with varied length"""
        if random.random() < 0.3:  # 30% chance for short comment
            template = random.choice(self.short_templates[sentiment])
            if "{score}" in template:
                template = template.replace("{score}", self.get_random_score(sentiment))
            return template
        elif random.random() < 0.7:  # 40% chance for normal comment
            return self.generate_normal_comment(sentiment, topic)
        else:  # 30% chance for long comment
            template = random.choice(self.long_templates[sentiment])
            return self.fill_long_template(template, sentiment, topic)

    def fill_long_template(self, template, sentiment, topic):
        """Fill in the placeholders for long templates with appropriate content"""
        replacements = {
            "{count}": random.choice(self.numbers),
            "{duration}": self.get_random_duration(),
            "{action}": self.get_random_action(topic),
            "{emotion}": self.get_random_emotion(sentiment),
        }
        
        for key, value in replacements.items():
            if key in template:
                template = template.replace(key, value)
        return template

    def get_random_action(self, topic: str, language: str = "vi") -> str:
        """Get random action based on topic and language"""
        actions = {
            "vi": {
                "general": ["dùng", "sử dụng", "trải nghiệm", "mua"],
                "food": ["ăn", "thử", "ghé quán", "đặt đồ"],
                "movie": ["xem", "ra rạp xem", "thưởng thức"],
                "service": ["sử dụng dịch vụ", "trải nghiệm", "thuê"]
            },
            "en": {
                "general": ["used", "tried", "experienced", "purchased"],
                "food": ["ate at", "tried", "visited", "ordered from"],
                "movie": ["watched", "saw", "experienced"],
                "service": ["used the service", "experienced", "hired"]
            }
        }
        
        topic_actions = actions[language].get(topic, actions[language]["general"])
        return random.choice(topic_actions)

    def get_random_emotion(self, sentiment: str, language: str = "vi") -> str:
        """Get random emotion based on sentiment and language"""
        emotions = {
            "vi": {
                "positive": self.vi_fillers["emotion"],
                "negative": ["thất vọng", "buồn", "không hài lòng", "bực mình"],
                "neutral": ["bình thường", "tạm được", "không đặc biệt"]
            },
            "en": {
                "positive": self.en_fillers["emotion"],
                "negative": ["disappointed", "upset", "dissatisfied", "frustrated"],
                "neutral": ["okay", "alright", "not special", "decent"]
            }
        }
        
        return random.choice(emotions[language][sentiment])

    def generate_interaction_comment(self, interaction_type: str, sub_type: str = None) -> str:
        """Generate an interaction comment"""
        if sub_type:
            template = random.choice(self.interaction_templates[interaction_type][sub_type])
        else:
            template = random.choice(self.interaction_templates[interaction_type])

        # Fill template with random fillers
        for key, values in self.interaction_fillers.items():
            if "{" + key + "}" in template:
                template = template.replace("{" + key + "}", random.choice(values))

        return template

================
File: src/visualization.py
================
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os
from typing import Dict, List
import numpy as np
from datetime import datetime
import joblib

class ModelVisualizer:
    def __init__(self, language: str):
        self.language = language
        self.plot_style = {
            'figure.figsize': (12, 8),
            'axes.grid': True,
            'grid.alpha': 0.3,
            'axes.labelsize': 12,
            'axes.titlesize': 14,
            'xtick.labelsize': 10,
            'ytick.labelsize': 10
        }
        plt.style.use('seaborn')
        for key, value in self.plot_style.items():
            plt.rcParams[key] = value

    def generate_plots(self, output_dir: str):
        """Generate and save all visualization plots"""
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # Load model metrics
        model_path = f"data/models/{self.language}_sentiment_model.pkl"
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")
        
        model_data = joblib.load(model_path)
        metrics = model_data.get('metrics', {})

        # Generate various plots
        self._plot_performance_metrics(metrics, output_dir, timestamp)
        self._plot_confusion_matrix(metrics, output_dir, timestamp)
        self._plot_training_history(metrics, output_dir, timestamp)
        self._plot_feature_importance(metrics, output_dir, timestamp)
        
        return True

    def _plot_performance_metrics(self, metrics: Dict, output_dir: str, timestamp: str):
        """Plot key performance metrics"""
        fig, ax = plt.subplots()
        
        metrics_to_plot = {
            'Accuracy': metrics.get('accuracy', 0),
            'Precision': metrics.get('precision', 0),
            'Recall': metrics.get('recall', 0),
            'F1 Score': metrics.get('f1_score', 0)
        }
        
        bars = ax.bar(metrics_to_plot.keys(), metrics_to_plot.values())
        ax.set_ylim(0, 1)
        ax.set_title(f'{self.language.upper()} Model Performance Metrics')
        
        # Add value labels on top of bars
        for bar in bars:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height,
                   f'{height:.3f}', ha='center', va='bottom')
        
        plt.savefig(os.path.join(output_dir, f'{timestamp}_performance_metrics.png'))
        plt.close()

    def _plot_confusion_matrix(self, metrics: Dict, output_dir: str, timestamp: str):
        """Plot confusion matrix heatmap"""
        if 'confusion_matrix' in metrics:
            cm = metrics['confusion_matrix']
            fig, ax = plt.subplots()
            
            sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues')
            ax.set_title(f'{self.language.upper()} Model Confusion Matrix')
            ax.set_xlabel('Predicted')
            ax.set_ylabel('Actual')
            
            plt.savefig(os.path.join(output_dir, f'{timestamp}_confusion_matrix.png'))
            plt.close()

    def _plot_training_history(self, metrics: Dict, output_dir: str, timestamp: str):
        """Plot training history"""
        if 'training_history' in metrics:
            history = metrics['training_history']
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
            
            # Plot accuracy
            if 'accuracy' in history:
                ax1.plot(history['accuracy'], label='Training')
                if 'val_accuracy' in history:
                    ax1.plot(history['val_accuracy'], label='Validation')
                ax1.set_title('Model Accuracy Over Time')
                ax1.set_xlabel('Epoch')
                ax1.set_ylabel('Accuracy')
                ax1.legend()
            
            # Plot loss
            if 'loss' in history:
                ax2.plot(history['loss'], label='Training')
                if 'val_loss' in history:
                    ax2.plot(history['val_loss'], label='Validation')
                ax2.set_title('Model Loss Over Time')
                ax2.set_xlabel('Epoch')
                ax2.set_ylabel('Loss')
                ax2.legend()
            
            plt.tight_layout()
            plt.savefig(os.path.join(output_dir, f'{timestamp}_training_history.png'))
            plt.close()

    def _plot_feature_importance(self, metrics: Dict, output_dir: str, timestamp: str):
        """Plot feature importance"""
        if 'feature_importance' in metrics and 'feature_names' in metrics:
            importance = metrics['feature_importance']
            features = metrics['feature_names']
            
            # Sort features by importance
            indices = np.argsort(importance)[::-1]
            
            # Plot top 20 features
            plt.figure(figsize=(10, 6))
            plt.title(f'Top 20 Most Important Features ({self.language.upper()})')
            plt.bar(range(20), importance[indices[:20]])
            plt.xticks(range(20), [features[i] for i in indices[:20]], rotation=45, ha='right')
            plt.tight_layout()
            
            plt.savefig(os.path.join(output_dir, f'{timestamp}_feature_importance.png'))
            plt.close()

    def visualize_prediction(self, text: str, prediction: Dict, output_file: str = None):
        """Create visualization for a single prediction"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # Plot sentiment scores
        sentiment_scores = prediction.get('sentiment_scores', {})
        if sentiment_scores:
            ax1.bar(sentiment_scores.keys(), sentiment_scores.values())
            ax1.set_title('Sentiment Scores')
            ax1.set_ylim(0, 1)
            
        # Plot emotion scores
        emotion_scores = prediction.get('emotion_scores', {})
        if emotion_scores:
            emotions = list(emotion_scores.keys())
            scores = list(emotion_scores.values())
            ax2.bar(emotions, scores)
            ax2.set_title('Emotion Scores')
            ax2.set_ylim(0, 1)
            plt.xticks(rotation=45)
        
        plt.suptitle(f'Analysis Results for: "{text[:50]}..."')
        plt.tight_layout()
        
        if output_file:
            plt.savefig(output_file)
        else:
            plt.show()
        plt.close()

================
File: tests/test_model.py
================
import pytest
import numpy as np
from src.models.model_trainer import EnhancedModelTrainer
from src.config import Config

@pytest.fixture
def trainer():
    config = Config()
    return EnhancedModelTrainer('vi', config)

def test_model_creation():
    config = Config()
    trainer = EnhancedModelTrainer('vi', config)
    model = trainer.create_ensemble_model()
    assert model is not None

def test_model_training():
    config = Config()
    trainer = EnhancedModelTrainer('vi', config)
    
    # Create dummy data
    X = np.random.rand(100, 10)
    y = np.random.randint(0, 2, 100)
    
    model = trainer.train_with_grid_search(X, y)
    assert model is not None

================
File: tests/test_preprocessor.py
================
import pytest
import pandas as pd
from src.data.preprocessor import DataPreprocessor
from src.config import Config

@pytest.fixture
def preprocessor():
    config = Config()
    return DataPreprocessor('vi', config)

def test_text_cleaning():
    config = Config()
    preprocessor = DataPreprocessor('vi', config)
    
    test_data = pd.DataFrame({
        'text': ['Đây là một bài test!!!', 'This is a test!!!'],
        'label': ['positive', 'negative']
    })
    
    processed_df = preprocessor.preprocess(test_data)
    assert len(processed_df) == 2
    assert 'cleaned_text' in processed_df.columns
    assert processed_df['label'].dtype == 'int64'
